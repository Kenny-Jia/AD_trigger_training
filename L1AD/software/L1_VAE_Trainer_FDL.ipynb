{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2406db2a-9fbf-450e-9968-a31ec6d51c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 01:54:53.669156: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-14 01:54:53.884281: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import sklearn\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pylab\n",
    "import tensorflow as tf                                        \n",
    "import tensorflow.math as tfmath\n",
    "import tensorflow.keras as keras\n",
    "from scipy.optimize import curve_fit\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ecd26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import PReLU, Input, LSTM, Flatten, Concatenate, Dense, Conv2D, TimeDistributed, MaxPooling2D, ReLU, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from qkeras import QActivation, QDense, QConv2D, QBatchNormalization, QConv2DBatchnorm\n",
    "from qkeras import quantized_relu, quantized_bits\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635e3dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.371832715762604\n"
     ]
    }
   ],
   "source": [
    "# Import math Library\n",
    "import math\n",
    "phi_res = 128/(2*math.pi)\n",
    "print(phi_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5231575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 62.22539425   0.          16.00000045]\n",
      " [ 56.88584805   0.           3.59988338]\n",
      " [120.           0.          13.10929682]\n",
      " ...\n",
      " [418.69319916   0.          25.5684422 ]\n",
      " [ 95.01579285   0.         -14.48252669]\n",
      " [114.1577816    0.          62.92878527]]\n",
      "Percentage of rows where both second and third components are zero: 100.00%\n",
      "Shape of Topo_2A: (2104833, 44)\n",
      "Shape of Topo_2B: (2104833, 44)\n",
      "Shape of Topo_3A: (2104833, 44)\n",
      "Shape of Topo_2A: (2104833, 44)\n",
      "Shape of Topo_2B: (2104833, 44)\n",
      "Shape of Topo_3A: (2104833, 44)\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        # Define object counts\n",
    "        nmuon, nLRjet, nSRjet, negamma, netau, njtau = 4, 6, 6, 4, 4, 4\n",
    "\n",
    "        # Load and reshape datasets with scaling\n",
    "        def load_and_scale(dataset, n_objects, scale_factor=10, eta_factor=10, phi_factor = phi_res):\n",
    "            data = hf[dataset][:, 0:n_objects, :]\n",
    "            data[:, :, 0] *= scale_factor  # Scale the pT value\n",
    "            data[:, :, 1] *= eta_factor  # Scale the angle value\n",
    "            data[:, :, 2] *= phi_factor  # Scale the angle value\n",
    "            return data.reshape(-1, 3 * n_objects)\n",
    "\n",
    "        L1_jFexSR_jets = load_and_scale('L1_jFexSR_jets', nSRjet)\n",
    "        L1_jFexLR_jets = load_and_scale('L1_jFexLR_jets', nLRjet)\n",
    "        L1_egammas = load_and_scale('L1_egammas', negamma)\n",
    "        L1_muons = load_and_scale('L1_muons', nmuon, scale_factor=10000)\n",
    "        L1_eFex_taus = load_and_scale('L1_eFex_taus', netau)\n",
    "        L1_jFex_taus = load_and_scale('L1_jFex_taus', njtau)\n",
    "\n",
    "        # Load and process MET\n",
    "        L1_MET = hf['L1_MET'][:]\n",
    "        L1_MET[:, 0] *= 10\n",
    "        L1_MET[:, 2] *= phi_res\n",
    "        print(L1_MET)\n",
    "        percentage_zeros = np.mean(L1_MET[:, 1] == 0) * 100\n",
    "        print(f\"Percentage of rows where both second and third components are zero: {percentage_zeros:.2f}%\")\n",
    "\n",
    "        L1_MET_fixed = np.zeros((L1_MET.shape[0], 2))\n",
    "        L1_MET_fixed[:, 0] = L1_MET[:, 0]\n",
    "        L1_MET_fixed[:, 1] = L1_MET[:, 2]\n",
    "        L1_MET = L1_MET_fixed\n",
    "\n",
    "        pass_L1_unprescaled = hf[\"pass_L1_unprescaled\"][:]\n",
    "        # Combine arrays into Topo groups\n",
    "        Topo_2A = np.concatenate([L1_jFexSR_jets, L1_eFex_taus, L1_muons, L1_MET], axis=1)\n",
    "        Topo_2B = np.concatenate([L1_jFexSR_jets, L1_egammas, L1_jFex_taus, L1_MET], axis=1)\n",
    "        Topo_3A = np.concatenate([L1_jFexSR_jets, L1_egammas, L1_eFex_taus, L1_MET], axis=1)\n",
    "\n",
    "        Topo_2A_labels = ['L1_jFexSR_jets', 'L1_eFex_taus', 'L1_muons', 'L1_MET']\n",
    "        Topo_2B_labels = ['L1_jFexSR_jets', 'L1_egammas', 'L1_jFex_taus', 'L1_MET']\n",
    "        Topo_3A_labels = ['L1_jFexSR_jets', 'L1_egammas', 'L1_eFex_taus', 'L1_MET']\n",
    "\n",
    "        # Print shapes\n",
    "        print(\"Shape of Topo_2A:\", Topo_2A.shape)\n",
    "        print(\"Shape of Topo_2B:\", Topo_2B.shape)\n",
    "        print(\"Shape of Topo_3A:\", Topo_3A.shape)\n",
    "\n",
    "        return Topo_2A, Topo_2B, Topo_3A, Topo_2A_labels, Topo_2B_labels, Topo_3A_labels, pass_L1_unprescaled\n",
    "\n",
    "# Usage\n",
    "file_path = '/eos/home-m/mmcohen/ntuples/EB_ntuples_08-13-2024.h5'\n",
    "Topo_2A, Topo_2B, Topo_3A, Topo_2A_labels, Topo_2B_labels, Topo_3A_labels, pass_L1_unprescaled = load_and_preprocess_data(file_path)\n",
    "\n",
    "# Print the shapes of the combined datasets to verify\n",
    "print(\"Shape of Topo_2A:\", Topo_2A.shape)\n",
    "print(\"Shape of Topo_2B:\", Topo_2B.shape)\n",
    "print(\"Shape of Topo_3A:\", Topo_3A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42f87da-74a5-4427-80b7-7c657f6aafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topo_2A_test=Topo_2A[0:450000,:]\n",
    "Topo_2B_test=Topo_2B[0:450000,:]\n",
    "Topo_3A_test=Topo_3A[0:450000,:]\n",
    "\n",
    "def replace_nan_with_median(data):\n",
    "    # Ensure the input is a numpy array\n",
    "    data = np.asarray(data)\n",
    "    \n",
    "    # Number of variables (columns)\n",
    "    num_variables = data.shape[1]\n",
    "    \n",
    "    # Iterate over each variable\n",
    "    for i in range(num_variables):\n",
    "        # Compute the median of the i-th variable, ignoring NaNs\n",
    "        median = np.nanmedian(data[:, i])\n",
    "        \n",
    "        # Find NaN indices in the column\n",
    "        nan_indices = np.where(np.isnan(data[:, i]))[0]\n",
    "        \n",
    "        for index in nan_indices:\n",
    "            print(f\"NaN found at index {index}, variable {i}\")\n",
    "        \n",
    "        # Replace NaNs with the median of the respective variable\n",
    "        data[nan_indices, i] = 0 #median\n",
    "    \n",
    "    return data\n",
    "Topo_2A_test = replace_nan_with_median(Topo_2A_test)\n",
    "Topo_2B_test = replace_nan_with_median(Topo_2B_test)\n",
    "Topo_3A_test = replace_nan_with_median(Topo_3A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c6792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_pass_test = pass_L1_unprescaled[0:450000]\n",
    "Topo_2A_test_L1failed = Topo_2A_test[L1_pass_test==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bcb4b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Topo_2A_test_L1failed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e3d4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a471d317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (bias): [ 1.37059273e+02 -4.86769911e+00 -9.46810177e+00  4.85459573e+01\n",
      " -3.24937547e-01 -1.16911069e-01  1.75623307e+01 -2.10871678e-01\n",
      " -1.68209852e-02  6.51239141e+00 -1.43792254e-01 -2.19732727e-02\n",
      "  2.77885690e+00 -7.28731674e-02 -1.04450144e-02  1.27396794e+00\n",
      " -4.36500536e-02 -5.94211477e-04  7.40582360e+01 -3.37643003e+00\n",
      " -7.17464982e+00  1.69404890e+01  2.01246246e-02  1.69780653e-02\n",
      "  5.19381558e+00  5.17336679e-03  2.70554901e-02  1.72618046e+00\n",
      "  4.32557310e-03  2.97953787e-02  8.64337910e+00  4.28261578e-01\n",
      "  2.50242003e-01  9.89359217e-01  4.15462038e-02  1.37360196e-01\n",
      "  1.52054791e-01  2.68545224e-03  7.58716854e-03  8.27191250e-03\n",
      "  8.73627822e-06  2.66059417e-03  1.11481399e+02 -1.63352904e+00]\n",
      "Standard deviation (scale): [211.51534862  13.25633925  28.70625018 134.06044535   7.45020399\n",
      "  14.63370363  64.31877996   5.75199839  10.34238344  35.28293775\n",
      "   4.1423674    6.92113264  22.52426842   2.93402333   4.6775563\n",
      "  15.07186591   2.1279519    3.20552072  94.27868464  13.2413024\n",
      "  32.83530664  48.97224028   5.21721576  14.2761296   20.77282917\n",
      "   3.46555355   9.61915876  10.76721356   2.13289616   6.0063107\n",
      "  23.81490758   5.23403959  14.10747132   6.62875576   2.17993591\n",
      "   5.81898416   2.36628542   1.00691169   2.38225226   0.53787648\n",
      "   0.24781804   0.61687563  76.27188974  31.97772319]\n",
      "[8, 4, 5, 7, 3, 4, 6, 3, 3, 5, 2, 3, 4, 2, 2, 4, 1, 2, 7, 4, 5, 6, 2, 4, 4, 2, 3, 3, 1, 3, 5, 2, 4, 3, 1, 3, 1, 0, 1, -1, -2, -1, 6, 5]\n"
     ]
    }
   ],
   "source": [
    "mean = scaler.mean_\n",
    "std = scaler.scale_\n",
    "print(\"Mean (bias):\", mean)\n",
    "print(\"Standard deviation (scale):\", std)\n",
    "def closest_power_of_2(arr):\n",
    "    return [int(round(math.log2(max(abs(x), 1e-10)))) for x in arr]\n",
    "result = closest_power_of_2(std)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b815cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_power_of_2_scaling(X, result):\n",
    "    \n",
    "    # Apply the scaling using 2 raised to the power of the result\n",
    "    X_scaled = X / (2.0 ** np.array(result))\n",
    "    \n",
    "    return X_scaled\n",
    "Topo_2A_test_L1failed = apply_power_of_2_scaling(Topo_2A_test_L1failed, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "534042f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Topo_2A: (2104833, 44)\n",
      "Shape of Topo_2B: (2104833, 44)\n",
      "Shape of Topo_3A: (2104833, 44)\n",
      "[[ 0.625      -1.46874994 -1.59374997 ...  0.          0.97227179\n",
      "   0.50000001]\n",
      " [ 0.625      -1.46874994 -1.59374997 ...  0.          0.88884138\n",
      "   0.11249636]\n",
      " [ 0.625      -1.46874994 -1.59374997 ...  0.          1.875\n",
      "   0.40966553]\n",
      " ...\n",
      " [ 1.42968744 -0.21875     0.28125    ...  0.          0.88884138\n",
      "  -1.11249635]\n",
      " [ 0.9375     -0.21875    -0.40625001 ...  0.          0.72146222\n",
      "   1.80388757]\n",
      " [ 0.          0.          0.         ...  0.          0.98126993\n",
      "   1.58627956]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Topo_2A:\", Topo_2A.shape)\n",
    "print(\"Shape of Topo_2B:\", Topo_2B.shape)\n",
    "print(\"Shape of Topo_3A:\", Topo_3A.shape)\n",
    "print(Topo_2A_test_L1failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd108b6-f2b4-4b39-9cee-ba8faa7bc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def Qmake_encoder_set_weights(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    l2_factor = 1e-3\n",
    "    inputs = keras.Input(shape=(input_dim))\n",
    "    x = QDense(h_dim_1,\n",
    "             kernel_quantizer=quantized_bits(10,5,0,alpha=1),\n",
    "             bias_quantizer=quantized_bits(10,5,0,alpha=1),\n",
    "             kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "             bias_initializer=keras.initializers.Zeros(),\n",
    "             kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(inputs)\n",
    "    x = QBatchNormalization(name=\"BN1\")(x)\n",
    "    x = QActivation(quantized_relu(15, negative_slope=1/1024))(x)\n",
    "    x = QDense(h_dim_2,\n",
    "             kernel_quantizer=quantized_bits(10,5,0,alpha=1),\n",
    "             bias_quantizer=quantized_bits(10,5,0,alpha=1),\n",
    "             kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "             bias_initializer=keras.initializers.Zeros(),\n",
    "             kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)    \n",
    "    x = QBatchNormalization(name=\"BN2\")(x)\n",
    "    x = QActivation(quantized_relu(15, negative_slope=1/1024))(x)\n",
    "    z_mean=QDense(latent_dim, name='z_mean',\n",
    "                  kernel_quantizer=quantized_bits(10,5,0,alpha=1),\n",
    "                  bias_quantizer=quantized_bits(10,5,0,alpha=1),\n",
    "                  kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "                  bias_initializer=keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    z_logvar=Dense(latent_dim, name='z_log_var',\n",
    "                          kernel_initializer=keras.initializers.Zeros(),\n",
    "                          bias_initializer=keras.initializers.Zeros(),\n",
    "                          kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    z=Sampling()([z_mean,z_logvar])\n",
    "    encoder = keras.Model(inputs,[z_mean,z_logvar,z],name='encoder')\n",
    "    return encoder\n",
    "\n",
    "def Qmake_decoder_set_weights(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    l2_factor = 1e-3\n",
    "    inputs=keras.Input(shape=(latent_dim))\n",
    "    x=layers.Dense(h_dim_2,\n",
    "                   activation='relu',\n",
    "                   kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "                   bias_initializer=keras.initializers.Zeros(),\n",
    "                   kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(inputs)\n",
    "    x=layers.Dense(h_dim_1,\n",
    "                   activation='relu',\n",
    "                   kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "                   bias_initializer=keras.initializers.Zeros(),\n",
    "                   kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    z=layers.Dense(input_dim,\n",
    "                   kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "                   bias_initializer=keras.initializers.Zeros(),\n",
    "                   kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    decoder=keras.Model(inputs,z,name='decoder')\n",
    "    return decoder\n",
    "def custom_mse_loss_with_multi_index_scaling(masked_data, masked_reconstruction):\n",
    "#     jet_scale = 1024/800\n",
    "#     tau_scale = 1024/800\n",
    "#     muon_sacle = 64/800\n",
    "#     met_scale = 8192/800\n",
    "    jet_scale = 1\n",
    "    tau_scale = 1\n",
    "    muon_sacle = 1\n",
    "    met_scale = 1\n",
    "\n",
    "    # Define the indices and their corresponding scale factors\n",
    "    scale_dict = {\n",
    "        0: jet_scale,\n",
    "        3: jet_scale,\n",
    "        6: jet_scale,\n",
    "        9: jet_scale,\n",
    "        12: jet_scale,\n",
    "        15: jet_scale,\n",
    "        18: tau_scale,\n",
    "        21: tau_scale,\n",
    "        24: tau_scale,\n",
    "        27: tau_scale,\n",
    "        30: muon_sacle,\n",
    "        33: muon_sacle,\n",
    "        36: muon_sacle,\n",
    "        39: muon_sacle,\n",
    "        42: met_scale\n",
    "    }\n",
    "    \n",
    "    # Create the scaling tensor\n",
    "    scale_tensor = tf.ones_like(masked_data)\n",
    "    \n",
    "    for index, factor in scale_dict.items():\n",
    "        # Create a mask for the current index\n",
    "        index_mask = tf.one_hot(index, depth=tf.shape(masked_data)[-1])\n",
    "        # Update the scale tensor for this index\n",
    "        scale_tensor += index_mask * (factor - 1)\n",
    "    \n",
    "    # Apply scaling\n",
    "    scaled_data = masked_data * scale_tensor\n",
    "    scaled_reconstruction = masked_reconstruction * scale_tensor\n",
    "    \n",
    "#     # Hardcoded lists for eta and phi indices\n",
    "#     eta_indices = [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40]\n",
    "#     phi_indices = [2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 43]\n",
    "\n",
    "#     batch_size = tf.shape(scaled_reconstruction)[0]\n",
    "    \n",
    "#     # Apply constraints to eta\n",
    "#     for i in eta_indices:\n",
    "#         indices = tf.stack([tf.range(batch_size), tf.fill([batch_size], i)], axis=1)\n",
    "#         updates = 3 * tf.tanh(scaled_reconstruction[:, i] / 3)\n",
    "#         scaled_reconstruction = tf.tensor_scatter_nd_update(scaled_reconstruction, indices, updates)\n",
    "    \n",
    "#     # Apply constraints to phi\n",
    "#     for i in phi_indices:\n",
    "#         indices = tf.stack([tf.range(batch_size), tf.fill([batch_size], i)], axis=1)\n",
    "#         updates = 3.14159265258979*(10/8) * tf.tanh(scaled_reconstruction[:, i] / (3.14159265258979*(10/8)))\n",
    "#         scaled_reconstruction = tf.tensor_scatter_nd_update(scaled_reconstruction, indices, updates)\n",
    "    # Calculate MSE using keras.losses.mse\n",
    "    mse = keras.losses.mse(scaled_data, scaled_reconstruction)\n",
    "    \n",
    "    # Take the mean across all dimensions\n",
    "    return tf.reduce_mean(mse)\n",
    "\n",
    "class VAE_Model(keras.Model):\n",
    "    def __init__(self, encoder, decoder, steps_per_epoch, cycle_length=10, min_beta=0.1, max_beta=0.85, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.beta_tracker = keras.metrics.Mean(name=\"beta\")\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.cycle_length = tf.cast(cycle_length, tf.float32)\n",
    "        self.min_beta = tf.cast(min_beta, tf.float32)\n",
    "        self.max_beta = tf.cast(max_beta, tf.float32)\n",
    "        self.beta = tf.Variable(min_beta, dtype=tf.float32)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.beta_tracker,\n",
    "        ]\n",
    "\n",
    "    def cyclical_annealing_beta(self, epoch):\n",
    "        cycle = tf.floor(1.0 + epoch / self.cycle_length)\n",
    "        x = tf.abs(epoch / self.cycle_length - cycle + 1)\n",
    "        return self.min_beta + (self.max_beta - self.min_beta) * tf.minimum(x, 1.0)\n",
    "#     def set_beta(self,beta):\n",
    "#         self.beta=beta\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Get the current epoch number\n",
    "        epoch = tf.cast(self.optimizer.iterations / self.steps_per_epoch, tf.float32)\n",
    "        \n",
    "        # Update beta\n",
    "        self.beta.assign(self.cyclical_annealing_beta(epoch))\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "#             reconstruction_loss = tf.reduce_mean(keras.losses.mse(mask*data, mask*reconstruction))\n",
    "            reconstruction_loss = custom_mse_loss_with_multi_index_scaling(mask*data, mask*reconstruction)\n",
    "            reconstruction_loss *=(1-self.beta)\n",
    "\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *=self.beta\n",
    "\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reco_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"beta\": self.beta,\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "        reconstruction_loss = custom_mse_loss_with_multi_index_scaling(mask*data, mask*reconstruction)\n",
    "#         reconstruction_loss = tf.reduce_mean(keras.losses.mse(mask*data, mask*reconstruction))\n",
    "        reconstruction_loss*=(1-self.beta)\n",
    "\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)        \n",
    "        kl_loss *=self.beta\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        \n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reco_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "            \"beta\": self.beta,\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        z_mean,z_log_var,x = self.encoder(data)\n",
    "        reconstruction = self.decoder(x)\n",
    "        return {\n",
    "            \"z_mean\": z_mean,\n",
    "            \"z_log_var\": z_log_var,\n",
    "            \"reconstruction\": reconstruction\n",
    "        }\n",
    "\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffb0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(y_true, y_pred, sample_weight):\n",
    "    return tf.reduce_mean(tf.multiply(sample_weight, tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc8cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 1024\n",
    "STOP_PATIENCE = 30\n",
    "LR_PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "306b66b6-96f3-4e7d-ac72-d24cd1002dea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 44)]                 0         []                            \n",
      "                                                                                                  \n",
      " q_dense (QDense)            (None, 32)                   1440      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " BN1 (QBatchNormalization)   (None, 32)                   128       ['q_dense[0][0]']             \n",
      "                                                                                                  \n",
      " q_activation (QActivation)  (None, 32)                   0         ['BN1[0][0]']                 \n",
      "                                                                                                  \n",
      " q_dense_1 (QDense)          (None, 16)                   528       ['q_activation[0][0]']        \n",
      "                                                                                                  \n",
      " BN2 (QBatchNormalization)   (None, 16)                   64        ['q_dense_1[0][0]']           \n",
      "                                                                                                  \n",
      " q_activation_1 (QActivatio  (None, 16)                   0         ['BN2[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " z_mean (QDense)             (None, 3)                    51        ['q_activation_1[0][0]']      \n",
      "                                                                                                  \n",
      " z_log_var (Dense)           (None, 3)                    51        ['q_activation_1[0][0]']      \n",
      "                                                                                                  \n",
      " sampling (Sampling)         (None, 3)                    0         ['z_mean[0][0]',              \n",
      "                                                                     'z_log_var[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2262 (8.84 KB)\n",
      "Trainable params: 2166 (8.46 KB)\n",
      "Non-trainable params: 96 (384.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                64        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 44)                1452      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2060 (8.05 KB)\n",
      "Trainable params: 2060 (8.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#TOPO 2A Trainer\n",
    "\n",
    "T2A_enc = Qmake_encoder_set_weights(Topo_2A.shape[1],32,16,3)\n",
    "T2A_dec = Qmake_decoder_set_weights(Topo_2A.shape[1],32,16,3)\n",
    "steps_per_epoch = Topo_2A_test_L1failed.shape[0] // BATCH_SIZE\n",
    "T2A = VAE_Model(T2A_enc, T2A_dec, steps_per_epoch=steps_per_epoch, min_beta=0.1, max_beta=0.7)\n",
    "# T2A.set_beta(beta)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "T2A.compile(optimizer=opt,weighted_metrics=[weighted_mse]) #,weighted_metrics=[weighted_mse]\n",
    "# T2A.build(input_shape=(997315, 110))\n",
    "T2A_enc.summary()\n",
    "T2A_dec.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5f91caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450000, 44)\n"
     ]
    }
   ],
   "source": [
    "print(Topo_2A_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6fbfc6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.8737 - reco_loss: 0.8563 - kl_loss: 0.0279 - beta: 0.1544 - val_loss: 0.6165 - val_reco_loss: 0.5616 - val_kl_loss: 0.0549 - val_beta: 0.1544 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5703 - reco_loss: 0.5171 - kl_loss: 0.0561 - beta: 0.2085 - val_loss: 0.5264 - val_reco_loss: 0.4567 - val_kl_loss: 0.0696 - val_beta: 0.2085 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4814 - reco_loss: 0.4224 - kl_loss: 0.0580 - beta: 0.2627 - val_loss: 0.4455 - val_reco_loss: 0.3836 - val_kl_loss: 0.0620 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4207 - reco_loss: 0.3662 - kl_loss: 0.0534 - beta: 0.3170 - val_loss: 0.3944 - val_reco_loss: 0.3371 - val_kl_loss: 0.0573 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3872 - reco_loss: 0.3383 - kl_loss: 0.0475 - beta: 0.3713 - val_loss: 0.3726 - val_reco_loss: 0.3186 - val_kl_loss: 0.0539 - val_beta: 0.3713 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3611 - reco_loss: 0.3161 - kl_loss: 0.0438 - beta: 0.4254 - val_loss: 0.3342 - val_reco_loss: 0.2838 - val_kl_loss: 0.0504 - val_beta: 0.4254 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3247 - reco_loss: 0.2837 - kl_loss: 0.0400 - beta: 0.4795 - val_loss: 0.3133 - val_reco_loss: 0.2693 - val_kl_loss: 0.0440 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2937 - reco_loss: 0.2563 - kl_loss: 0.0367 - beta: 0.5336 - val_loss: 0.2823 - val_reco_loss: 0.2396 - val_kl_loss: 0.0427 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2689 - reco_loss: 0.2358 - kl_loss: 0.0317 - beta: 0.5877 - val_loss: 0.2543 - val_reco_loss: 0.2148 - val_kl_loss: 0.0394 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2403 - reco_loss: 0.2124 - kl_loss: 0.0268 - beta: 0.6418 - val_loss: 0.2261 - val_reco_loss: 0.1935 - val_kl_loss: 0.0326 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2147 - reco_loss: 0.1907 - kl_loss: 0.0227 - beta: 0.6958 - val_loss: 0.1960 - val_reco_loss: 0.1686 - val_kl_loss: 0.0274 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3430 - reco_loss: 0.3163 - kl_loss: 0.0374 - beta: 0.1489 - val_loss: 0.3820 - val_reco_loss: 0.3274 - val_kl_loss: 0.0546 - val_beta: 0.1489 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3753 - reco_loss: 0.3236 - kl_loss: 0.0529 - beta: 0.2033 - val_loss: 0.3814 - val_reco_loss: 0.3189 - val_kl_loss: 0.0625 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3707 - reco_loss: 0.3163 - kl_loss: 0.0543 - beta: 0.2577 - val_loss: 0.3631 - val_reco_loss: 0.3007 - val_kl_loss: 0.0624 - val_beta: 0.2577 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3548 - reco_loss: 0.3015 - kl_loss: 0.0522 - beta: 0.3120 - val_loss: 0.3506 - val_reco_loss: 0.2916 - val_kl_loss: 0.0590 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3349 - reco_loss: 0.2851 - kl_loss: 0.0490 - beta: 0.3662 - val_loss: 0.3360 - val_reco_loss: 0.2843 - val_kl_loss: 0.0517 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3192 - reco_loss: 0.2728 - kl_loss: 0.0455 - beta: 0.4204 - val_loss: 0.3186 - val_reco_loss: 0.2662 - val_kl_loss: 0.0523 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2995 - reco_loss: 0.2565 - kl_loss: 0.0423 - beta: 0.4745 - val_loss: 0.3048 - val_reco_loss: 0.2522 - val_kl_loss: 0.0527 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2765 - reco_loss: 0.2367 - kl_loss: 0.0390 - beta: 0.5286 - val_loss: 0.2783 - val_reco_loss: 0.2314 - val_kl_loss: 0.0469 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2526 - reco_loss: 0.2169 - kl_loss: 0.0349 - beta: 0.5828 - val_loss: 0.2459 - val_reco_loss: 0.2041 - val_kl_loss: 0.0418 - val_beta: 0.5828 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2303 - reco_loss: 0.1992 - kl_loss: 0.0298 - beta: 0.6362\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2302 - reco_loss: 0.1991 - kl_loss: 0.0297 - beta: 0.6368 - val_loss: 0.2264 - val_reco_loss: 0.1971 - val_kl_loss: 0.0293 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2039 - reco_loss: 0.1781 - kl_loss: 0.0250 - beta: 0.6905 - val_loss: 0.1988 - val_reco_loss: 0.1735 - val_kl_loss: 0.0254 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2903 - reco_loss: 0.2656 - kl_loss: 0.0340 - beta: 0.1438 - val_loss: 0.3673 - val_reco_loss: 0.3138 - val_kl_loss: 0.0534 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3541 - reco_loss: 0.3029 - kl_loss: 0.0524 - beta: 0.1981 - val_loss: 0.3672 - val_reco_loss: 0.3030 - val_kl_loss: 0.0641 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3511 - reco_loss: 0.2962 - kl_loss: 0.0549 - beta: 0.2523 - val_loss: 0.3627 - val_reco_loss: 0.3015 - val_kl_loss: 0.0612 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3403 - reco_loss: 0.2866 - kl_loss: 0.0529 - beta: 0.3067 - val_loss: 0.3467 - val_reco_loss: 0.2816 - val_kl_loss: 0.0651 - val_beta: 0.3067 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3280 - reco_loss: 0.2772 - kl_loss: 0.0499 - beta: 0.3609 - val_loss: 0.3354 - val_reco_loss: 0.2768 - val_kl_loss: 0.0586 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3127 - reco_loss: 0.2651 - kl_loss: 0.0470 - beta: 0.4150 - val_loss: 0.3120 - val_reco_loss: 0.2578 - val_kl_loss: 0.0542 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2958 - reco_loss: 0.2507 - kl_loss: 0.0444 - beta: 0.4691 - val_loss: 0.2852 - val_reco_loss: 0.2304 - val_kl_loss: 0.0548 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2758 - reco_loss: 0.2338 - kl_loss: 0.0407 - beta: 0.5232 - val_loss: 0.2755 - val_reco_loss: 0.2271 - val_kl_loss: 0.0485 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2548 - reco_loss: 0.2169 - kl_loss: 0.0366 - beta: 0.5766\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2547 - reco_loss: 0.2168 - kl_loss: 0.0366 - beta: 0.5773 - val_loss: 0.2473 - val_reco_loss: 0.2050 - val_kl_loss: 0.0424 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2316 - reco_loss: 0.1979 - kl_loss: 0.0322 - beta: 0.6311 - val_loss: 0.2225 - val_reco_loss: 0.1852 - val_kl_loss: 0.0374 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2066 - reco_loss: 0.1782 - kl_loss: 0.0272 - beta: 0.6852 - val_loss: 0.1939 - val_reco_loss: 0.1600 - val_kl_loss: 0.0339 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2592 - reco_loss: 0.2347 - kl_loss: 0.0306 - beta: 0.1387 - val_loss: 0.3671 - val_reco_loss: 0.3180 - val_kl_loss: 0.0491 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3507 - reco_loss: 0.3012 - kl_loss: 0.0516 - beta: 0.1929 - val_loss: 0.3638 - val_reco_loss: 0.3051 - val_kl_loss: 0.0587 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3429 - reco_loss: 0.2889 - kl_loss: 0.0543 - beta: 0.2472 - val_loss: 0.3542 - val_reco_loss: 0.2911 - val_kl_loss: 0.0631 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3371 - reco_loss: 0.2833 - kl_loss: 0.0533 - beta: 0.3014 - val_loss: 0.3489 - val_reco_loss: 0.2838 - val_kl_loss: 0.0650 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3229 - reco_loss: 0.2715 - kl_loss: 0.0508 - beta: 0.3556 - val_loss: 0.3327 - val_reco_loss: 0.2754 - val_kl_loss: 0.0573 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3109 - reco_loss: 0.2622 - kl_loss: 0.0482 - beta: 0.4097 - val_loss: 0.3142 - val_reco_loss: 0.2603 - val_kl_loss: 0.0539 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2960 - reco_loss: 0.2496 - kl_loss: 0.0454 - beta: 0.4638 - val_loss: 0.2968 - val_reco_loss: 0.2428 - val_kl_loss: 0.0540 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2748 - reco_loss: 0.2314 - kl_loss: 0.0423 - beta: 0.5179 - val_loss: 0.2848 - val_reco_loss: 0.2332 - val_kl_loss: 0.0516 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2550 - reco_loss: 0.2154 - kl_loss: 0.0384 - beta: 0.5720 - val_loss: 0.2522 - val_reco_loss: 0.2057 - val_kl_loss: 0.0465 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2343 - reco_loss: 0.1992 - kl_loss: 0.0338 - beta: 0.6256\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2342 - reco_loss: 0.1991 - kl_loss: 0.0337 - beta: 0.6260 - val_loss: 0.2296 - val_reco_loss: 0.1894 - val_kl_loss: 0.0402 - val_beta: 0.6260 - lr: 4.9000e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2091 - reco_loss: 0.1785 - kl_loss: 0.0293 - beta: 0.6800 - val_loss: 0.2051 - val_reco_loss: 0.1681 - val_kl_loss: 0.0370 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2428 - reco_loss: 0.2172 - kl_loss: 0.0277 - beta: 0.1337 - val_loss: 0.3693 - val_reco_loss: 0.3212 - val_kl_loss: 0.0481 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3557 - reco_loss: 0.3095 - kl_loss: 0.0486 - beta: 0.1878 - val_loss: 0.3608 - val_reco_loss: 0.3038 - val_kl_loss: 0.0570 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3458 - reco_loss: 0.2930 - kl_loss: 0.0533 - beta: 0.2420 - val_loss: 0.3538 - val_reco_loss: 0.2917 - val_kl_loss: 0.0621 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3382 - reco_loss: 0.2846 - kl_loss: 0.0536 - beta: 0.2962 - val_loss: 0.3430 - val_reco_loss: 0.2821 - val_kl_loss: 0.0608 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3232 - reco_loss: 0.2709 - kl_loss: 0.0520 - beta: 0.3503 - val_loss: 0.3302 - val_reco_loss: 0.2705 - val_kl_loss: 0.0598 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3125 - reco_loss: 0.2620 - kl_loss: 0.0494 - beta: 0.4044 - val_loss: 0.3217 - val_reco_loss: 0.2641 - val_kl_loss: 0.0576 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2962 - reco_loss: 0.2485 - kl_loss: 0.0471 - beta: 0.4586 - val_loss: 0.2938 - val_reco_loss: 0.2374 - val_kl_loss: 0.0564 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2777 - reco_loss: 0.2327 - kl_loss: 0.0437 - beta: 0.5126 - val_loss: 0.2703 - val_reco_loss: 0.2229 - val_kl_loss: 0.0474 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2541 - reco_loss: 0.2131 - kl_loss: 0.0403 - beta: 0.5667\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2540 - reco_loss: 0.2131 - kl_loss: 0.0403 - beta: 0.5667 - val_loss: 0.2546 - val_reco_loss: 0.2094 - val_kl_loss: 0.0452 - val_beta: 0.5667 - lr: 3.4300e-04\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2345 - reco_loss: 0.1979 - kl_loss: 0.0357 - beta: 0.6207 - val_loss: 0.2354 - val_reco_loss: 0.1964 - val_kl_loss: 0.0390 - val_beta: 0.6207 - lr: 2.4010e-04\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2117 - reco_loss: 0.1795 - kl_loss: 0.0304 - beta: 0.6748 - val_loss: 0.2027 - val_reco_loss: 0.1659 - val_kl_loss: 0.0368 - val_beta: 0.6748 - lr: 2.4010e-04\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2248 - reco_loss: 0.1995 - kl_loss: 0.0247 - beta: 0.1286 - val_loss: 0.3674 - val_reco_loss: 0.3247 - val_kl_loss: 0.0428 - val_beta: 0.1286 - lr: 2.4010e-04\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3560 - reco_loss: 0.3131 - kl_loss: 0.0459 - beta: 0.1827 - val_loss: 0.3634 - val_reco_loss: 0.3070 - val_kl_loss: 0.0564 - val_beta: 0.1827 - lr: 2.4010e-04\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3461 - reco_loss: 0.2943 - kl_loss: 0.0524 - beta: 0.2368 - val_loss: 0.3502 - val_reco_loss: 0.2899 - val_kl_loss: 0.0604 - val_beta: 0.2368 - lr: 2.4010e-04\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3362 - reco_loss: 0.2826 - kl_loss: 0.0532 - beta: 0.2910 - val_loss: 0.3369 - val_reco_loss: 0.2772 - val_kl_loss: 0.0597 - val_beta: 0.2910 - lr: 2.4010e-04\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3265 - reco_loss: 0.2741 - kl_loss: 0.0519 - beta: 0.3451 - val_loss: 0.3323 - val_reco_loss: 0.2709 - val_kl_loss: 0.0614 - val_beta: 0.3451 - lr: 2.4010e-04\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3097 - reco_loss: 0.2594 - kl_loss: 0.0499 - beta: 0.3993 - val_loss: 0.3237 - val_reco_loss: 0.2641 - val_kl_loss: 0.0596 - val_beta: 0.3993 - lr: 2.4010e-04\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2956 - reco_loss: 0.2473 - kl_loss: 0.0476 - beta: 0.4533 - val_loss: 0.3013 - val_reco_loss: 0.2497 - val_kl_loss: 0.0516 - val_beta: 0.4533 - lr: 2.4010e-04\n",
      "Epoch 63/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.2776 - reco_loss: 0.2322 - kl_loss: 0.0446 - beta: 0.5063\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2775 - reco_loss: 0.2321 - kl_loss: 0.0445 - beta: 0.5074 - val_loss: 0.2771 - val_reco_loss: 0.2276 - val_kl_loss: 0.0494 - val_beta: 0.5074 - lr: 2.4010e-04\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_reco_loss', factor=0.7, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "history = T2A.fit(x=Topo_2A_test_L1failed, validation_split=0.1, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, shuffle=True)#, sample_weight=Topo_t_weights\n",
    "T2A.save_weights(filepath='/eos/user/h/hjia/AnomalyDetection/trained_models/L1_models/Topo_2A/versionFDL/', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "141e7a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtkAAAHwCAYAAABzBnP9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAAsTAAALEwEAmpwYAAD9V0lEQVR4nOyddVhVWReHf4dLp4SKigHYNGIrdufYLero2O04znwq2GPL2N3dHSgoNoqgYoAKFoqIgnTcu74/NlxAQeoG4H59eMATe69z9z3nrL32CoGIwOFwOBwOh8PhcGSHirIF4HA4HA6Hw+FwihtcyeZwOBwOh8PhcGQMV7I5HA6Hw+FwOBwZw5VsDofD4XA4HA5HxnAlm8PhcDgcDofDkTFcyeZwOBwOh8PhcGQMV7I5HM4vgSAI5wRBGCzrY5WJIAghgiC0lEO7XoIg/J76d39BEC7m5th89FNBEIQYQRBE+ZWVw+FwCitcyeZwOIWWVAUs7UciCEJ8hv/3z0tbRNSOiHbI+tjCiCAIMwRBuJbFdhNBEJIEQbDObVtEtIeIWstIrkyTAiJ6Q0S6RCSWRfvf9UWCIFSWdbscDoeTW7iSzeFwCi2pCpguEekCeAOgU4Zte9KOEwRBVXlSFkp2AWggCIL5d9v7AHhERI+VIBOHw+H8UnAlm8PhFDkEQWgqCMI7QRCmC4LwEcA2QRAMBUE4LQhCuCAIX1P/NstwTkYXCBdBEK4LgrA09dhgQRDa5fNYc0EQrgmCEC0IgocgCGsEQdidjdy5kXGuIAg3Utu7KAiCSYb9AwVBeC0IQoQgCP9k9/kQ0TsAVwAM/G7XIAA7cpLjO5ldBEG4nuH/rQRBeCYIQpQgCKsBCBn2WQqCcCVVvs+CIOwRBKFE6r5dACoAOJW6EvGnIAiVUi3OqqnHlBUE4aQgCF8EQXghCMLwDG27CoJwUBCEnamfTYAgCE7ZfQbZIQiCQWob4amf5f8EQVBJ3VdZEISrqdf2WRCEA6nbBUEQVgiC8Cl138O01QBBEDRSvxtvBEEIEwRhvSAIWqn7TFI/28jUa/JO64vD4RR/+M3O4XCKKqYAjABUBDAC7Hm2LfX/FQDEA1j9k/PrAngOwATAYgBbBEEQ8nHsXgB3ARgDcMWPim1GciNjPwBDAJQCoA5gKgAIglATwLrU9sum9pelYpzKjoyyCIJQDYA9gH25lOMHUhX+IwD+B/ZZvATQMOMhABamylcDQHmwzwRENBCZVyMWZ9HFPgDvUs/vAWCBIAgtMuzvDGA/gBIATuZG5iz4D4ABAAsATcAmHkNS980FcBGAIdhn+1/q9tYAnAFUTe27N4CI1H3/pm63B1AZQDkAs1L3TUm9npIASgP4GwDlQ2YOh1ME4Uo2h8MpqkgAzCaiRCKKJ6IIIjpCRHFEFA1gPpgSlR2viWhTqj/wDgBlwBShXB8rCEIFALUBzCKiJCK6Dqb8ZUkuZdxGRIFEFA/gIJjyBjCl8zQRXSOiRAAzUz+D7DiWKmOD1P8PAnCOiMLz8Vml0R7AEyI6TETJAFYC+Jjh+l4Q0aXUMQkHsDyX7UIQhPIAGgGYTkQJROQHYDMyT1quE9HZ1HHYBcAuN21n6EMEpiDPIKJoIgoBsCxDH8lgE4+yqTJcz7BdD0B1AAIRPSWiD6kTreEAJhHRl9TPcgGYW07aeWUAVCSiZCLyJiKuZHM4vwhcyeZwOEWVcCJKSPuPIAjagiBsSHUB+AbgGoASQvaZKzIqh3Gpf+rm8diyAL5k2AYAb7MTOJcyfszwd1wGmcpmbJuIYpFuTf2BVJkOARiUqgz2B5sg5OezSuN7GSjj/wVBKCUIwn5BEN6ntrsbzOKdG9I+y+gM216DWYbT+P6z0RTy5o9vArY68DqbPv4Es8bfTXVHGQoARHQFzGq+BkCYIAgbBUHQB7NQawO4n+oSEgngfOp2AFgC4AWAi4IgvBIE4a88yMrhcIo4XMnmcDhFle8tglMAVANQl4j0wZb3gQw+w3LgAwAjQRC0M2wr/5PjCyLjh4xtp/ZpnMM5OwD0AtAKzBJ7uoByfC+DgMzXuxBsXGxT2x3wXZs/s+KGgn2Wehm2VQDwPgeZ8sJnpFurf+iDiD4S0XAiKgvgDwBrhdQMJUTkTkS1AFiBuYdMS20vHoAVEZVI/TFIDdRFqrV8ChFZAOgEYPJ37i8cDqcYw5VsDodTXNADU3giBUEwAjBb3h0S0WsA9wC4CoKgLghCfTBlSh4yHgbQURCERoIgqAOYg5yf4d4AIgFsBLCfiJIKKMcZAFaCIHRLtSCPB/ONT0MPQExqu+XAFNGMhIH5Qv8AEb0FcBPAQkEQNAVBsAUwDMCerI7PJeqpbWkKgqCZuu0ggPmCIOgJglARwGQwizsEQegppAeAfgWbFIgFQagtCEJdQRDUAMQCSAAgJiIJgE0AVgiCUCq1jXKCILRJ/btjajClAOAbAHHqD4fD+QXgSjaHwykurASgBWZdvA22bK8I+gOoD+a6MQ/AAQCJ2Ry7EvmUkYgCAIwBC7T8AKYEvsvhHAKwE8xyu7OgchDRZwA9ASwCu94qAG5kOMQNgCOAKDCF/Oh3TSwE8L9U14qpWXTRF0AlMKv2MTCf+0u5kS0bAsAmE2k/QwCMA1OUXwG4DvZ5bk09vjaAO4IgxID51k8gomAA+mDK9Fcw95IIAEtTz5kO5hJyO9VFxgNslQBgn48H2MTjFoC1RORVgOvhcDhFCIHHYHA4HI7sSE379oyI5G5J53A4HE7hhVuyORwOpwCkuhJYCoKgIghCWwBdABxXslgcDofDUTK8ShqHw+EUDFMwtwhjMPeNUUT0QLkicTgcDkfZcHcRDofD4XA4HA5HxnB3EQ6Hw+FwOBwOR8ZwJZvD4XA4HA6Hw5ExxdIn28TEhCpVqqTwfmNjY6Gjo6PwfjmZ4eNQOODjUHjgY1E44ONQOODjUDgoLuNw//79z0RUMqt9xVLJrlSpEu7du6fwfr28vNC0aVOF98vJDB+HwgEfh8IDH4vCAR+HwgEfh8JBcRkHQRBeZ7ePu4twOBwOh8PhcDgyhivZHA6Hw+FwOByOjOFKNofD4XA4HA6HI2OKpU82h8PhcDicX4fk5GS8e/cOCQkJOR5rYGCAp0+fKkAqzs8oauOgqakJMzMzqKmp5focrmRzOBwOh8Mp0rx79w56enqoVKkSBEH46bHR0dHQ09NTkGSc7ChK40BEiIiIwLt372Bubp7r87i7CIfD4XA4nCJNQkICjI2Nc1SwOZz8IAgCjI2Nc7VSkhGuZHM4HA6HwynycAWbI0/y8/3iSjaHw+FwOBxOAYiIiIC9vT3s7e1hamqKcuXKSf+flJSU6diVK1ciLi4uxzabNm2aZc2P7LZzCh/cJ5vD4XA4HA6nABgbG8PPzw8A4OrqCl1dXUydOjXLY1euXIkBAwZAW1tbgRJylAG3ZHM4HA6Hw+HImMuXL8PBwQE2NjYYOnQoEhMT4e7ujtDQUDRr1gzNmjUDAIwaNQpOTk6wsrLC7Nmz89XXly9f0LVrV9ja2qJevXp4+PAhAODq1atSi7qDgwOio6Px4cMHODs7w97eHtbW1vD29pbZNXMyU6ws2YIgdALQqXLlysoWhcPhcDgcjhKYOBFINSpniVisBZEob23a2wMrV+b++ISEBLi4uODy5cuoWrUqBg0ahHXr1mHixIlYvnw5PD09YWJiAgCYP38+jIyMIBaL0aJFCzx8+BC2trZ5km/27NlwcHDA8ePHceXKFQwaNAh+fn5YunQp1qxZg4YNGyImJgaamprYuHEj2rRpg3/++QdisThXriuc/FGsLNlEdIqIRhgYGChbFA6Hw+FwOL8oYrEY5ubmqFq1KgBg8ODBuHbtWpbHHjx4EI6OjnBwcEBAQACePHmS5/6uX7+OgQMHAgCaN2+OiIgIREVFoWHDhpg8eTLc3d0RGRkJVVVV1K5dG9u2bYOrqysePXpUZNLoFUWKlSWbw+FwOBzOr01OFufo6Hi5K5Y6Ojq5Oi44OBhLly6Fj48PDA0N4eLikuc0cQDL4/w9giDgr7/+QocOHXD27FnUq1cPHh4ecHZ2xrVr13DmzBkMHDgQ06ZNw6BBg/LcJydnipUlm8PhcDgcDkfZJCQkICQkBC9evAAA7Nq1C02aNAEA6OnpITo6GgDw7ds36OjowMDAAGFhYTh37ly++nN2dsaePXsAAF5eXjAxMYG+vj5evnwJGxsbTJ8+HU5OTnj27Blev36NUqVKYfjw4Rg2bBh8fX1lcMWcrOCWbA6Hw+FwOBwZoqmpiW3btqFnz55ISUlB7dq1MXLkSADAiBEj0K5dO5QpUwaenp5wcHCAlZUVLCws0LBhw1y136FDB2l57/r162PDhg0YMmQIbG1toa2tjR07dgBgmUw8PT0hEolQs2ZNtGvXDvv378eSJUugpqYGXV1d7Ny5Uz4fAocr2RwOh8PhcDiywtXVVfr3gwcPftg/btw4jBs3Tvr/7du3Z9mOl5dXnrafOHHih23//fffD9sGDx6MwYMHZ9kGR7ZwdxEZIZEA4eHqyhaDw+FwOBwOh1MI4Eq2jOjfH5g82V7ZYnA4HA6Hw+FwCgFcyZYR9eoB795p4/VrZUvC4XA4HA6Hw1E2XMmWEa1asd8eHsqVg8PhcDgcDoejfLiSLSNq1ABMTBJx6ZKyJeFwOBwOh8PhKBuuZMuIBd7zodK3Gy5fZkGQHA6Hw+FwOJxfF65ky4jopGh8NrqIz5Hx8PNTtjQcDofD4XAUiUgkgr29PaytrdGpUydERkYqTRYvLy/cvHlTZu0dP348U7n3WbNmwUMG/rFeXl7o2LFjgdsprHAlW0bUN6sPiZAClHnA/bI5HA6Hw/nF0NLSgp+fHx4/fgwjIyOsWbNGabL8TMlOSUnJc3vfK9lz5sxBy5Yt8y3frwJXsmVEXbO6AADT2re4XzaHw+FwOL8w9evXx/v37wEAL1++RNu2bVGrVi00btwYz549AwCEhYXht99+g52dHezs7KRK8fLly2FtbQ1ra2usXLkSABASEoIaNWpg+PDhsLKyQuvWrREfHw8AcHd3R82aNWFra4s+ffogJCQE69evx4oVK2Bvbw9vb2+4uLhg8uTJaNasGaZPnw5XV1csXbpUKq+1tTVCQkIAADt37oStrS3s7OwwcOBA3Lx5EydPnsS0adNgb2+Ply9fwsXFBYcPHwYAXL58GQ4ODrCxscHQoUORmJgIAKhUqRJmz54NR0dH2NjYSK87N+zbtw82NjawtrbG9OnTAQBisRguLi6wtraGjY0NVqxYkeX1FyaKVcVHQRA6AehUuXJlhfdtqmsKU01T6NW4De+lQHw8oKWlcDE4HA6Hw/mlmXh+Ivw++mW7XywWQyQS5alNe1N7rGy7MlfHisViXL58GcOGDQPAyqivX78eVapUwZ07dzB69GhcuXIF48ePR5MmTXDs2DGIxWLExMTg/v372LZtG+7cuQMiQt26ddGkSRMYGhoiKCgI+/btw6ZNm9CrVy8cOXIEAwYMwKJFixAcHAwNDQ1ERkaiRIkSGDlyJHR1dTF16lQAwJYtWxAYGAgPDw+IRKJMVSkzEhAQgPnz5+PGjRswMTHBly9fYGRkhM6dO6Njx47o0aNHpuMTEhLg4uKCy5cvo2rVqhg0aBDWrVuHiRMnAgBMTEzg6+uLtWvXYunSpdi8eXOOn19oaCimT5+O+/fvw9DQEK1bt8bx48dRvnx5vH//Ho8fPwYAqTvO99dfmChWlmwiOkVEIwwMDJTSf039mviqcxuJicCNG0oRgcPhcDgcjhKIj4+Hvb09jI2N8eXLF7Rq1QoxMTG4efMmevbsCXt7e/zxxx/48OEDAODKlSsYNWoUAObPbWBggOvXr+O3336Djo4OdHV10a1bN3h7ewMAzM3NYW9vDwCoVauW1PJsa2uL/v37Y/fu3VBVzd522rNnzxwnF1euXEGPHj1gYmICADAyMvrp8c+fP4e5uTmqVq0KgJVsv3btmnR/t27dfpA3J3x8fNC0aVOULFkSqqqq6N+/P65duwYLCwu8evUK48aNw/nz56Gvrw8g99evDAqXNEWcmno1ceXTFagavcOlS2bg7kocDofD4SiWnCzO0dHR0NPTk3m/aT7ZUVFR6NixI9asWQMXFxeUKFECfrnMiEBE2e7T0NCQ/i0SiaTuImfOnMG1a9dw8uRJzJ07FwEBAVmer6OjI/1bVVUVkgyp0BISEqT9C4KQK1lzkjejzCKRKNe+4Nm1aWhoCH9/f1y4cAFr1qzBwYMHsXXr1iyvv7Ao28XKkq1saurXBABUbX6b+2VzOBwOh/MLYmBgAHd3dyxduhRaWlowNzfHoUOHADAF0t/fHwDQokULrFu3DgBzMfn27RucnZ1x/PhxxMXFITY2FseOHUPjxo2z7UsikeDt27do1qwZFi9ejMjISMTExEBPTw/R0dHZnlepUiX4+voCAHx9fREcHCyV6eDBg4iIiAAAfPnyBQCyba969eoICQnBixcvAAC7du1CkyZN8vR5fU/dunVx9epVfP78GWKxGPv27UOTJk3w+fNnSCQSdO/eHXPnzoWvr2+2119Y4Eq2DKmsWxkaIg0Y2tzGgwdAeLiyJeJwOBwOh6NoHBwcYGdnh/3792PPnj3YsmUL7OzsYGVlhRMnTgAAVq1aBU9PT9jY2KBWrVoICAiAo6MjXFxcUKdOHdStWxe///47HBwcsu1HLBZjwIABsLGxgYODAyZNmoQSJUqgU6dOOHbsmDTw8Xu6d++OL1++wN7eHuvWrZO6e1hZWeGff/5BkyZNYGdnh8mTJwMA+vTpgyVLlsDBwQEvX76UtqOpqYlt27ahZ8+esLGxgYqKCkaOHJmnz+ry5cswMzOT/oSEhGDhwoVo1qwZ7Ozs4OjoiC5duuD9+/do2rQp7O3t4eLigoULF2Z7/YUFISdTf1HEycmJ7t27p/B+vby88M+rfxATI+DhhOvYvx/o3VvhYvzyeHl5oWnTpsoW45eHj0PhgY9F4YCPg/x4+vQpatSokatj5eUuwskbRXEcsvqeCYJwn4icsjqeW7JlTL1y9fD82z0YGCVxlxEOh8PhcDicXxSuZMuY+uXrI1GcCId2/rh0CSiGCwUcDofD4XA4nBzgSraMqWdWDwBQyvE23rwBUmMBOBwOh8PhcDi/EFzJljFm+mYop1cO8ca3AIC7jHA4HA6Hw+H8gnAlWw7UM6uHx5G3UakSV7I5HA6Hw+FwfkW4ki0H6pvVR3BkMBq2CcOVK0Au869zOBwOh8PhcIoJXMmWA2l+2WXr3Ma3b4ASsglyOBwOh8NRILq6utK/z549iypVquDNmzdwdXXF0qVLf3pupUqV8PnzZ3mLyFEwXMmWA45lHKGqooqkkrchCNxlhMPhcDicX4XLly9j3LhxOH/+PCpUqKBscThKhCvZMuLTJ2DTJnMkJABaalpwMHWA/5fbcHTkSjaHw+FwOL8C3t7eGD58OM6cOQNLS8sCtfX69Wu0aNECtra2aNGiBd68eQMAOHToEKytrWFnZwdnZ2cAQEBAAOrUqQN7e3vY2toiKCiowNfCKTiqyhaguBAQAOzdWxF2dsCffzKXka0PtmJMqxQsX6qKmBggw0oSh8PhcDgceTBxIuDnl+1uLbEYEIny1qa9PbBy5U8PSUxMRJcuXeDl5YXq1avnrf0sGDt2LAYNGoTBgwdj69atGD9+PI4fP445c+bgwoULKFeuHCIjIwEA69evx4QJE9C/f38kJSVBLBYXuH9OweGWbBnRrBlQr14EFiwAIiKYkh2bHAvL+o+RkgJcvapsCTkcDofD4cgLNTU1NGjQAFu2bJFJe7du3UK/fv0AAAMHDsT169cBAA0bNoSLiws2bdokVabr16+PBQsW4N9//8Xr16+hpaUlExk4BYNbsmXIiBEv8fvvxpg3Dxg/qz4AILHkbWhq2uPSJaBDByULyOFwOBxOcScHi3N8dDT09PRk3q2KigoOHjyIli1bYsGCBfj7779l2r4gCACY1frOnTs4c+YM7O3t4efnh379+qFu3bo4c+YM2rRpg82bN6N58+Yy7Z+Td4qVJVsQhE6CIGyMiopSSv/m5nEYOhRYswYQR1RCKZ1SuB92G87OgIeHUkTicDgcDoejILS1tXH69Gns2bOnwBbtBg0aYP/+/QCAPXv2oFGjRgCAly9fom7dupgzZw5MTEzw9u1bvHr1ChYWFhg/fjw6d+6Mhw8fFvhaOAWnWFmyiegUgFNOTk7DlSWDmxuQkABoaAioZ1YPt97dwvBWwLRpQGgoULassiTjcDgcDocjb4yMjHD+/Hk4OzvDxMQEADBv3jyszGBhf/fu3Q/n2draQkWF2T579eoFd3d3DB06FEuWLEHJkiWxbds2AMC0adMQFBQEIkKLFi1gZ2eHRYsWYffu3VBTU4OpqSlmzZol/wvl5EixUrILA2XLArt2sb/rlauHk89PwqldBABjeHgAgwYpVTwOh8PhcDhyICYmRvp3+fLlERwcDADo0qULXF1df3puSEhIltuvXLnyw7ajR4/+sG3GjBmYMWNG7oXlKIRi5S5SmAgIAB7v7wcQEFviLkqW5Kn8OBwOh8PhcH4VuJItJ65eBfaurQghqDPuvL+Fli2ZXzaRsiXjcDgcDofD4cgbrmTLieHDgapVAfUrK3Dz9V20bAl8/Mgs3BwOh8PhcDic4g1XsmWImNKTv6upAYsWAYkfLXDjZDW0aCkBwF1GOBwOh8PhcH4FuJItI04+P4met3riQ/QH6bauXYEq9mFIuDgDn8TPUa0aT+XH4XA4HA6H8yvAlWwZUcOkBr4mf8Um303SbYIAzF2YANhvx913PmjZkvlqJyUpUVAOh8PhcDgcjtzhSraMqGJcBbUNa2PD/Q1IFidLt/dqUwGGnRbD76s3WrUCYmOBW7eUKCiHw+FwOByZ0rRpU1y4cCHTtpUrV2L06NE/PefevXuZtv3222+wt7dH5cqVYWBgAHt7e9jb2+PmzZs/nH/8+HE8efIkR9lcXV2xdOnSXG/nyA6uZMuQ38r9htDoUBx/dly6TRBYUZpLl1Tw4AEgEnG/bA6Hw+FwihN9+/aVVmdMY//+/ejbt2+e2jl27Bj8/PywefNmNG7cGH5+fvDz80ODBg1+ODa3SjZHeXAlW4bUMaqDSiUqYY3Pmkzb65nVw+u7Npg3j+DkBGzbBmTIWc/hcDgcDqcI06NHD5w+fRqJiYkAWHGZ0NBQNGrUCKNGjYKTkxOsrKwwe/bsPLf9+vVrtGjRAra2tmjRogXevHmDmzdv4uTJk5g2bRrs7e3x8uVLbNq0CbVr14adnR26d++OuLi4PPdFRJg2bRqsra1hY2ODAwcOAAA+fPgAZ2dn2Nvbw9raGt7e3hCLxXBxcZEeu2LFijz3V9zhFR9liEgQYU37NTDWMs60vb5ZfaBJP2g8GQl1dVWEhgL//gvMnaskQTkcDofDKcY0bfrjtl69gNGjgbg4oFOnH/e7uLCfz5+BHj0y7/Py+nl/xsbGqFOnDs6fP48uXbpg//796N27NwRBwPz582FkZASxWIwWLVrg4cOHsLW1zfW1jB07FoMGDcLgwYOxdetWjB8/HsePH0fnzp3RsWNH9EgVtkSJEhg+fDgA4H//+x+2bNmCcePG5bofgFWT9PPzg7+/Pz5//ozatWvD2dkZe/fuRZs2bfDPP/9ALBYjLi4Ofn5+eP/+PR4/fgwAiIyMzFNfvwLcki1j2ldpj7pmdTNtq1OuDgSdCDToew3e3kDLlsDSpcDr10oSksPhcDgcjkzJ6DKS0VXk4MGDcHR0hIODAwICAvLs4nHr1i3069cPADBw4EBcv349y+MeP36Mxo0bw8bGBnv27EFAPgpzXL9+HX379oVIJELp0qXRpEkT+Pj4oHbt2ti2bRtcXV3x6NEj6OnpwcLCAq9evcK4ceNw/vx56Ovr57m/4g63ZMuBl19eYunNpVjUchEMNA1goGmAGiVrQFRhNcqdbY6ICHbc9OnAdy5cHA6Hw+FwCsjPLM/a2j/fb2KSs+U6K7p27YrJkyfD19cX8fHxcHR0RHBwMJYuXQofHx8YGhrCxcUFCQkJeW88A4IgZLndxcUFx48fh52dHbZv3w6vfFwEZVOW2tnZGdeuXcOZM2cwcOBATJs2DYMGDYK/vz8uXLiANWvW4ODBg9i6dWue+yzOcEu2HIhKjML6++uxw3+HdFu9cvXgE34VS5cSRowApk0DDhwAspmQcjgcDofDKULo6uqiadOmGDp0qNSK/e3bN+jo6MDAwABhYWE4d+5cnttt0KCB1EK+Z88eNGrUCACgp6eH6Oho6XHR0dEoU6YMkpOTsWfPnnxdg7OzMw4cOACxWIzw8HBcu3YNderUwevXr1GqVCkMHz4cw4YNg6+vLz5//gyJRILu3btj7ty58PX1zVefxRluyZYDjmUcUc+sHtb4rMHYOmOhIqigfvn62Oq3FbVavUAV4yqIi2MBkBMnAnfvAip8usPhcDgcTpGmb9++6Natm1QptrOzg4ODA6ysrGBhYYGGDRvmuU13d3cMHToUS5YsQcmSJbFt2zYAQJ8+fTB8+HC4u7vj8OHDmDt3LurWrYuKFSvCxsYmkwKeHfPmzcPKlSul/3/79i1u3boFOzs7CIKAxYsXw9TUFDt27MCSJUugpqYGXV1d7Ny5E+/fv8eQIUMgkbCK1gsXLszztRV3hOyWBooyTk5O9H3uSUXg5eWFpqnRFnse7sGAYwNwccBFtLJshcefHsNmnQ12dt2JvlYDsWkT8OIFsHw5U7ZdXBQubrEl4zhwlAcfh8IDH4vCAR8H+fH06VPUqFEjV8dGR0dDT09PzhJxcqIojkNW3zNBEO4TkVNWx3P7qZzoUbMHSmqXxGqf1QBYRUg9dT3cencLggCsWQOcPg3UrQvMmAHkYsLJ4XA4HA6HwykicCVbTmioamBy/cmoZFAJRASRigh1zeri9rvbEIlY+r7AQJZp5ONHYNEiZUvM4XA4HA6Hw5EVxUrJFgShkyAIG6OiopQtCgDgr0Z/YVW7VdJI4Hrl6uFh2EPEJsWia1fAyQnYtQvo2xdYtgwIDlauvBwOh8PhcDgc2VCslGwiOkVEIwwMDJQtihQiwrXX15CQkoB6ZvUgJjHuhd6DIADz5wNv3gA1a7Jy63/+qWxpORwOh8PhcDiyoFgp2YWRm29vosn2Jjjw+ADqmdUDANx+dxsA0KoVqz5Vvz7LmX34MHDtmjKl5XA4HA6Hw+HIAq5ky5kG5RughkkNrPFZA2NtY1Q1roqLry4CgDQAskULYOpUoHx5ltJPLFauzBwOh8PhcDicgsGVbDkjCALG1B4Dn1Af3H1/F0Pth+JK8BXceXdHesyXLyzw0dUVePAA2LEj+/Y4HA6Hw+EULpo2bYoLFy5k2rZy5UqMHj36p+dklW64adOmqFatGuzs7FC7dm34+fnJWtxcExISgr1798qsPT8/P5w9e1b6/5MnT2KRjDI/6OrqyqQdWcKVbAUw0G4gdNV1scZnDcbUGQNjLWPMuTZHuj8khGUbCQkBGjQA/v4b+PZNaeJyOBwOh8PJA3379pUWoElj//790sqPeWXPnj3w9/fH6NGjMW3aNFmImC9+pmSnpKTkub3vlezOnTvjr7/+yrd8hR2uZCsAfQ19DLYbDM9gT6iL1DG5/mScDToLn/c+AABHR6BHD2DFCmbNDgsDFixQrswcDofD4XByR48ePXD69GkkJiYCYMppaGgoGjVqhFGjRsHJyQlWVlaYPXt2ntqtX78+3r9/DwCIjY3F0KFDUbt2bTg4OODEiRMAALFYjKlTp8LGxga2trb477//AACXL1+Gg4MDbGxsMHToUKlslSpVwuzZs+Ho6AgbGxs8e/YMAHD16lXY29vD3t4eDg4OiI6Oxl9//QVvb2/Y29tjxYoV2L59O3r27IlOnTqhdevW8PLyQseOHaXyjh07Ftu3bwcA+Pj4oEGDBrCzs0OdOnUQFRWFWbNm4cCBA7C3t8eRI0ewfft2jB07FgDw+vVrtGjRAra2tmjRogXevHkDAHBxccH48ePRoEEDWFhY4PDhw7n+/Pz8/FCvXj3Y2trit99+w9evXwGwKpo1a9aEra0t+vTpk+31FxSuZCuIOc3mIGhcENRF6hhbZywMNQ0x99rc9P1zgLg44OJFYNAgpnC/eqVEgTkcDofDKaI03d70h5+1PmsBAHHJcVnu3+63HQDwOe7zD/tywtjYGHXq1MH58+cBMCt27969IQgC5s+fj3v37uHhw4e4evUqHj58mOvrOH/+PLp27QoAmD9/Ppo3bw4fHx94enpi2rRpiI2NxcaNGxEcHIwHDx7g4cOH6N+/PxISEuDi4oIDBw7g0aNHSElJwbp166TtmpiYwNfXF6NGjcLSpUsBAEuXLsWaNWvg5+cHb29vaGlpYdGiRWjcuDH8/PwwadIkAMCtW7ewY8cOXLlyJVu5k5KS0Lt3b6xatQr+/v7w8PCAjo4O5syZg969e8PPzw/du3fPdM7YsWMxaNAg6TWMHz9euu/Dhw+4fv06Tp8+nSfL96BBg/Dvv//i4cOHsLGxgZubGwBg0aJF0s9r/fr12V5/QeFKtoIw0jKChqoGxBIxdNV1Mbn+ZJwKPAXfD74AgBo1gAEDgNWrgQkTADU1YMQIQCJRsuAcDofD4XByJKPLSEZXkYMHD8LR0REODg4ICAjAkydPcmyrf//+MDMzw7///otx48YBAC5evIhFixbB3t4eTZs2RUJCAt68eQMPDw+MHDkSqqqqAAAjIyM8f/4c5ubmqFq1KgBg8ODBuJYhfVm3bt0AALVq1UJISAgAoGHDhpg8eTLc3d0RGRkpbe97WrVqBSMjo5/K//z5c5QpUwa1a9cGAOjr62fbXhq3bt1Cv379AAADBw7E9evXpfu6du0KFRUV1KxZE2FhYT9tJ42oqChERkaiSZMmADJ/Bra2tujfvz92794tlSu3158XCt4CJ9e8+PICrXa1wso2KzGuzjgsu7UMc67OwfE+xwEwV5GYGMDICFi+HPjjD6Z0Z5jMcTgcDofDyQEvF69s92mraf90v4m2yU/3Z0fXrl0xefJk+Pr6Ij4+Ho6OjggODsbSpUvh4+MDQ0NDuLi4ICEhIce29uzZAzs7O/z1118YM2YMjh49CiLCkSNHUK1atUzHEpG06F3GbT9DQ0MDACASiaS+1X/99Rc6dOiAs2fPol69evDw8MjyXB0dHenfqqqqkGSwBqZdW1Yy5ZWM56fJm9Z2QTlz5gyuXbuGkydPYu7cuQgICMjy+qtXr16gfrglW4FUKlEJYokYy28vh4GmASbWnYgTz0/A76MfAMDcHDhyBKhUCRg+HOjQgeXPfvpUqWJzOBwOh8PJAV1dXTRt2hRDhw6VWrG/ffsGHR0dGBgYICwsDOfOnct1e2pqapg3bx5u376Np0+fok2bNvjvv/+kSuaDBw8AAK1bt8b69eulyvKXL19QvXp1hISE4MWLFwCAXbt2SS262fHy5UvY2Nhg+vTpcHJywrNnz6Cnp/dT3+SKFSviyZMnSExMRFRUFC5fvgwAqF69OkJDQ+Hjw2LPoqOjkZKS8tP2GjRoIF0J2LNnDxo1apTbjypLDAwMYGhoCG9vbwDpn4FEIsHbt2/RrFkzLF68GJGRkYiJicny+gsKV7IViKqKKqY2mIprr6/hashVTKg3AQYaBpl8swEgMBDYuBHYvBnQ1WVuJElJShKaw+FwOBxOrujbty/8/f2lwXR2dnZwcHCAlZUVhg4dioYNG+apPS0tLUyZMgVLly7FzJkzkZycDFtbW1hbW2PmzJkAgN9//x0VKlSAra0t7OzssHfvXmhqamLbtm3o2bMnbGxsoKKigpEjR/60r5UrV8La2hp2dnbQ0tJCu3btYGtrC1VVVdjZ2WHFihU/nFO+fHn06tVL6n7h4OAAAFBXV8eBAwcwbtw42NnZoVWrVkhISECzZs3w5MkTaeBjRtzd3bFt2zbY2tpi165dWLVqVZ4+q7i4OJiZmUl/li9fjh07dmDatGmwtbWFn58fZs2aBbFYjAEDBsDGxgYODg6YNGkSSpQokeX1FxRBFmb3woaTkxNllXtS3nh5eaFp06Y/PSY+OR4W7haoYVIDVwZfwWzP2ZhzbQ78R/rDtrQtAFaYZsUK4NEj4PlzoFs34H//Y2n+ODmTm3HgyB8+DoUHPhaFAz4O8uPp06eoUaNGro6Njo6Gnp6enCXi5ERRHIesvmeCINwnIqesjueWbAWjpaaF6Q2nwzPEE3fe3cHEehOhp66HedfmSY/56y9ARwcYORLo3BlwcWEp/W7dUp7cHA6Hw+FwOJzcw5VsJfBHrT9wos8J1ClXB4ZahhhfdzwOPzmMgE8BAAATExbw6O0N/PsvsGoVK7k+cCALjORwOBwOh8PhFG64kq0EtNS00LlaZ2nk7KR6k6CjrpPJN3vgQKB3b2D2bCAoCNi5k+XNnjJFWVJzOBwOh8PhcHILV7KVyIpbK9DjYA8YaxtjXJ1xOBhwEE/CWf5MQQDWrWNKdfXqgLMzMG0aC4g8fVrJgnM4HA6Hw+FwfgpXspWImMQ48vQIbr69icn1J0NbTRvzvedL9xsaAosWMf/spCRWFdLWFhg2DAgPV6LgHA6Hw+FwOJyfwpVsJTLKaRRKapeE21U3mGibYEztMdj/eD+ef36e6bg3b5hyffo0sHs3EBnJqkEWw8QwHA6Hw+FwOMUCrmQrER11HUxtMBUXX17E7Xe3MbXBVGiqamKe97xMx5UpA+jpsQI1hobA/PnA8ePAjh3KkZvD4XA4HE46TZs2xYULFzJtW7lyJUaPHv3Tc7JKN5xxe0hICKpUqYILFy7Ay8sLHTt2/KkcLi4uOHz4cD6ugCMPuJKtZEbXHg0TbRO4XXVDSZ2SGO00Gnsf7UVQRJD0GDU1YO9eIDERGDQImDABaNKElVsPDlai8BwOh8PhcNC3b19ptcI09u/fL638mB/evXuHNm3aYNmyZWjTpk1BReQoAa5kKxlddV1s6LgBc5uxzCJTG0yFhkgjk282AFSpAri7A56ewMqV6VbswYMBsVjBQnM4HA6Hw5HSo0cPnD59GomJiQCYBTo0NBSNGjXCqFGj4OTkBCsrK8yePTtX7X38+BGtW7fGvHnz0Llz5wLJlpCQgCFDhkgrHHp6egIAAgICUKdOHdjb28PW1hZBQUGIjY1Fhw4dYGdnB2traxw4cKBAff/qqCpbAA7QrUY36d+ldUtjpNNIuN9xx0znmbA0spTuGzoUOHeO+WZPmcJyaQ8eDEycyBTw1IyAHA6Hw+H82mRVWbNXL2D0aCAuDujU6cf9Li7s5/NnoEePzPu8vH7anbGxMerUqYPz58+jS5cu2L9/P3r37g1BEDB//nwYGRlBLBajRYsWePjwIWxtbX/a3qBBgzBv3jz07Nnzp8flhjVr1gAAHj16hGfPnqF169YIDAzE+vXrMWHCBPTv3x9JSUkQi8U4e/YsypYtizNnzgAAoqKiCtz/rwy3ZBcSwmPDMfTEUNx9fxd/NvwT6iJ1TL00FRnL3gsCsG0b4OEBqKiwXNppyvY//yhReA6Hw+FwfnEyuoxkdBU5ePAgHB0d4eDggICAADx58iTHtlq2bIldu3YhLi6uwHJdv34dAwcOBABUr14dFStWRGBgIOrXr48FCxbg33//xevXr6GlpQUbGxt4eHhg+vTp8Pb2hoGBQYH7/5XhluxCgqaqJk48P4Gw2DCc6XcGc5rNwbRL03Ag4AD6WPeRHqenx35HRABHjwJLlrAqkAsXArq6wN9/K+kCOBwOh8MpLPzM8qyt/fP9JiY5Wq6zomvXrpg8eTJ8fX0RHx8PR0dHBAcHY+nSpfDx8YGhoSFcXFyQkJCQY1t//vkndu/ejZ49e+LEiRNQVc2/ukbZpCLr168f6tatizNnzqBNmzbYvHkzmjdvjvv37+Ps2bOYMWMGWrdujVmzZuW7718dbskuJOhp6GFK/Sk4G3QWPu99MKneJNQtVxdjz45FWEzYD8evWcPS+J04AaxdCwwYwKzZ7u5KEJ7D4XA4nF8cXV1dNG3aFEOHDpVasb99+wYdHR0YGBggLCwM586dy3V7K1asgL6+PoYNG5atopwbnJ2dsWfPHgBAYGAg3rx5g2rVquHVq1ewsLDA+PHj0blzZzx8+BChoaHQ1tbGgAEDMHXqVPj6+ua7X04xU7IFQegkCMLGoupDNLbOWBhqGmLOtTkQqYiwrcs2xCTFYOy5sT8c+9dfgKMj8PvvQGAgcyP57TeWeWTrViUIz+FwOBzOL07fvn3h7++PPn3YCrSdnR0cHBxgZWWFoUOHomHDhrluSxAE7NixAx8+fMCff/4JALh8+TLMzMykP7du3frhvD/++EO6v379+hg9ejTEYjFsbGzQu3dvbN++HRoaGjhw4ACsra1hb2+PZ8+eYdCgQXj06JE0GHL+/Pn43//+J5sP5leFiIrdT61atUgZeHp6FriNeVfnEVxB997fIyKihd4LCa6gg48P/nDss2dERkZEGhpEixYRxcQQtWlDJAhE+/cXWJQiiyzGgVNw+DgUHvhYFA74OMiPJ0+e5PrYb9++yVESTm4piuOQ1fcMwD3KRh8tVpbs4sC4uuMwse5EmOqaAmAp/ZzKOmHM2TEIj81cS71aNSAgAGjfHjh4EFBXZ37ajRox95FTp5RxBRwOh8PhcDgcrmQXMvQ19LGi7QqU0y8HAFBVUcW2LtsQmRCJcefG/XC8qSlw5Ahw5QorWpOQALRsCdjZAT17ApcvK/oKig68LD2Hw+FwOBx5wZXsQor/R38MPzkcYokY1qWsMbvJbBwIOICjT4/+cKwgAGlZdg4dAmbPZsp2+fJA587AzZsKFr4I0K4dS4Oopgbo6AC9ewOhoUBsLFC1KlCzJmBry/zex4wBPn1StsQcDofD4XCKElzJLqQEhAdg84PNWH5rOQDgz4Z/wsHUAaPOjEJEXES25/3xB3D8OPDlCyu5rqHBFEoeIJyZu3eZkm1kxCYkBw8C5coxBTshgSnfJUoAxsbAxo1s8sLhcDicwgvx5UmOHMnP94sr2YWUvtZ98Vv13zDTcyaehD+BmkgN27tux5f4L5hwfsJPz+3ShflqDxoEfP3K3CJatwbu3VOQ8EWA2FigQgUgLIz9ffMmsGIF4OwMqKoCDx8C3t6sjL2tLZCcDHz8yFxzjh7lriYcDodTmNDU1ERERARXtDlygYgQEREBTU3NPJ3Hi9EUUgRBwLoO62C11goux11wc9hN2Ja2xf8a/w+uV13Ry6oXOlfrnO35hoYslV/v3qxIzYABrMrsoUPMsv0rk5gIJCWxkvQAoKkJ1K/PftIIDwfu3AFu3wZOngQmTWLVNQ0M2MSlQQNWadPBQTnXwOFwOLJCLGaVxtOKnRVFzMzM8O7dO4SHh+d4bEJCQp6VJY7sKWrjoKmpCTMzszydw5XsQkxp3dJY22Eteh/ujc2+mzHSaSRmNJ6BY8+O4Y/Tf6BRhUYw0jL6aRtt2rDf584xJbJjR+b+MGyYAi6gkBIczCzRVapkf0zJkuyz6tgRmDePrQwcOADs28eU7Js3mb9248bA5s3MzYQjPx4/Zi49AItBEAT23a5fn1U/XbcufZ+REVC5MpsAmZgoT+ZfmaAg4OJFoEwZoFs3to2IjQ+n8DFtGrByJXum/fdfZoNDUUFNTQ3m5ua5OtbLywsORdhCcv8+cwt1dQVEIvZO0tZm7qFFiaI+DrmBK9mFnF5WvSAhCbrVYG8qdZE6tnXZhjqb62DShUnY0XVHrtpRV2e/tbVZAZu3b1mA5K/40ksruCUS5f4cKytgzhzAzQ3w8wN27GArBd7ebF+nTqwCZ5s2v+ZnKm/mzPnRL15fnykDnz8DM2f+eM6mTey7/vQpW4WoXPnHHxXuMCcXZs0C9u9nk5w0Jbt3b+DaNaBsWRb/UK4cUL06MHGiUkXlAPDxAczM2PvBKNVuc+gQe8a1asV+rK35s62wsGABc1ucO5f9f9QoZoQoWxYwNwcqVWLvpb/+UqqYHHCf7CJBH+s+UBepIyohCsniZDiUccCMRjOw038nzgSeyVUbFhbMEhsXx25ANzdg+HAgJUW+shdGfHzY71waPTIhCMxCunIlEBXFytqPHg3cusXccEqWBBYt+jU/V3nSty+wZQuzhhIBEglz4QHYKkJyMnMBSkwE3r0DvLxY/niAjdPHj8D27awiaocOLMc8D2aVH0FBQJMmwPXr6dvatmWT0TJl2CT/yBFg5870/a6uTKnjmXwUT2AgMxBcu8buDYDdSyEhbIJqa8sUuIED2XaOcgkMZKusaQwaxIxmLVsy45G3d+bn29y5rG6GWKx4WX95sqtSU5R/inLFx+wIjw0ns+VmNMdrDhERJaYkkvVaayq7rCx9ifuS63b+/ZepKS1asN/t2xNFR8tLauWQ0zjUrs2uPT5edn0mJrLPVBBY2xoaRAMGEH3+LLs+ihqFrbqdREIUFkZ08ybRli1ESUls+5EjRFeuKFc2eaPosShRgmjUqJyPS0lhv5OSiCwt2b0jCEQNGxItXkz06pV85VQ0he2eICKKjSUqWZJ93lnx5g27X/r0IWrQIH37kCFEbdsSzZlDdOkSUVSUYuSVBYVxHHKLWEykqUk0ZUrOxxGx8a1Qgd1bFhZES5cSfcm9yiBXivI4ZAS84mPRx0TbBM4VnTHn2hz4ffSTuo2Ex4aj3Z52iEqIylU706YBvXqxmbC7O3D+PNCsGcuy8avw/j1L0SfLeAt1dcDDg32OQ4cyi/fu3WwJdu5c5jfMyR9xcYC/P0ut+DMkElZ86eRJlvP8ewQBKFWKuZgMHcq+A0TAwoVA8+ZsSfzuXflcw69EVBTL2GNpmfOxaS5bamrM+u3ry1xNYmOBP/9kq28AEBPDLHEhITyzj6zR1marB1OmZL2/fHl2v+zbB9y4kb69dGm2ajR7Nrt3SpRgAfZpxMbKVexflnfv2LPwZzFFQLornLY28OJFepraqVPZe+n0afnLyuHuIkUK97buMNE2gctxFySJk+BU1gmHeh7C/Q/30XZPW3xL/JZjG4LAlmTv3gXGjWPBEwEBLFtGYKD8r6Ew8OULeyHIg5IlmVtDXBywahVQty5TGszM2M/q1cy1gZN7HjwA7O2ZC0hWfPvGJozVq7Pl0i5d0n1+u3RhgavnzzPf7e8RBLa0umIFU+Tr1mXnPH0qzysq3hgYAPHxrIhTXkhzxXJ1ZWMeEpIeoH3uHCusZW7O2m/QgMVAvHzJ9ksksryCX5PcxCfcugUcPswmsQsXAo8esaC7CxeYsu3szI6Lj2fKebt2wJ49XOGWJRERzP2zevWcj/38mY2VmhqrAH3tGosp6tcPcHJix1y9yly3uIujfOBKdhHCWNsYGzpugH+YP+Zfmw8A6FK9Cw72OIh7offQdndbRCdG59iOjg4rx56SwhTrc+eYotKgAUtZV5xJSWE+hRYW8u1HEIDx45li+OgR+2zfv2cTGxMTptRx38bcERTEfleunHn78+fs8yxXjvlaGxuzF/qNG2yC07w5+37PmpXuL29uzlZylixhSjURW9GYOBF49Yop5FevMp9hgFtN84tIlPNKUWQks4CWLw907Zo+GUrLwFaxIhszgPlz37gBrF/P/E/V1TMrBuvXM5/hdu2YxZuPW+7ZtIkpXTl9Zm/esPHq2ZPdcxYWbCz272f/nzmTTXwA9mwbNYpNVgcMYFbvgQOZQYdTMBwc2OSySZOfHycWAw0bsrGpWZM9486cYStMmzYxHQBg906PHuz5umIF0wU4MiQ7P5Ki/FMcfbIzMujYIGq/pz2JJWLptiNPjpDITUQNtzSkbwnfctXO7dtEKipEvXoRBQYyn0htbSIPD3lJrhh+Ng4vXzLftJWbPtHjsMeKE4qIgoOZD2Na+F6ZMul+wcURWd0P//xDJBKxz0osJjp1iqh1a/YZqqsTDRxIdPdu9udHRRF5ejKf0169iMzN08egWjWimTOJHj1iPttpx6f9PX06UefORMePF+2xUqTv4759RCNHpvuEZsWXL0ROTkRqakQ9ehBVrZo+JgBRxYpE3bsTLVhAdPEiUUTEj21IJOnjdOkS0eDBRJUqsfOdnYnu3JHH1RWMwuiD2rcvuyd+hkRC1LEjez+cPk20fDlRt25EpUqlj5mhIVGHDkQLFxJdu8biVMRi9veIEcxP38eHtffsGfs7bfwUTWEcB1lz+DAbl99/Z89LTU32fzU1oiZNiObNY/dIYiLRsWNEjRuz/fr6zG9bERSXccBPfLKVrhDL46e4K9nxyfEkyeLpdCjgEIncRNRoayOKTsxdNOOiRexb8O+/RB8/Ellbs5vx3DlZS604fjYOFy6w622/YQgJrgLN8ZqTabKiCHx9iWxsmBy2tizobvt2FqBSnJDV/dC7NwvYWb48PTiuTBkWcPXxY/7a/PiRaMMGFqyqosLarFGDaPZsooCA9ONcXYlMTdn+UqVYsFHG/UUFRb7Mhg0jKl06+/1fvhDVqsUmSKdOpW+PjGSToSVL2JinjXXaj4MDG48HD7JXzpKSiNauZWPVsKHylLjsKIxKRa1aRG3a/PyYQ4fYGHyvfEkkREFBRNu2sXGvXj19vPT0mCK+dSvRhw9ECQnp4zF8ODumenWilSsVHzRZGMcht4wcSTRmzM+PkUiI6tYlqlw5Pbg4Pp4Z0P78k91LGSdHPXqw4NZz59ika80adk5cXPrESB4U5XHICFeyFYSivzBvIt/QDr8dmbYdfHyQRG4ict7mTDGJMTm2IZEw656KClNAw8OJ7O3ZC/DkSXlJLl9+Ng7jxqUqVDN7k8ZcDYIrqMOeDnnK0CILJBL24qpYMf1hZ2LCXmIxOQ9bkUBW90OtWunR8Q0aEO3fL1ur8sePTDFr2jQ9O4y1NVPinz0jSk5myuBvvxGpqjJlgoiNYVHJqKDIZ1PTppmzUGQkIoLI0ZE9X06fzrmtiAhmpZ43j7WZNj4VKxKNH090+XLW34Vv39Izk3z4QDRpEtGnT/m+JJlR2JQKiYRZLseOzf6Yr1/ZRNPBgd0LOREeziyjI0YQlSuX/nyrXZtNku7dY1mXNm4kql8/XSGfOVNWV5UzhW0c8kK1amzy8jOuXWOf69q12R/z6RNbdRoyJH2cBIEp5/PmEfn7szECmJX7+PF0hV1WFOVxyAhXshWEor8wY86MIRU3FdrquzWTZXv/o/2k4qZCTbc3zZWiHRPDLKtly7LZ7pcv7IGoqsqWnIoaPxuH5s3Zt97wHysacXIErbm7htTmqJH5SnPyDfVVnJCpxMURzZ3LUv6lKRDGxmyFQZYpBpWBrO6Hy5fZi6VZM5k091NCQ4n++4+9VNLGo0ULpuilpQB884Yde/cuW/Xp359ZYAszinw2lS/PXHi+JyKCKWrq6kRnzuSv7Y8fiTZvJurUKX35u0QJNgYHDzLl+nv27GFGBH195n6izBWjwqZUfPzIPkN39+yP+eMP9vndu5f39iUStvIwbx5RvXrp95SpKZusHjtGdP06G7/p09PP8faW7ypEYRuH3JKczN7Lf/318+M6d2ZGm9x+1yUSIj8/9i6qUyd9YmRmxlaE0tyCLC2ZJT2NiIiCKd5FdRy+hyvZCkLRX5jI+EhqtLURwRXUZlcbCvkaIt235+EeUnFToWbbm1FsUs532suXmZeFoqKY5UgkYi+posTPxsHSkkgQJIRZAv17/V8iIrr19haVW1aONOdp0vYH2xUkZWbeviXq14+kObZNTIq+RVtW94NEwixdP7O2yYN379hkJ81dpFYtpsilvVRevGC5oA0M2P5Jk2Rv6ZEVino2JSQwRcrVNfP2z5/ZCpmGBtHZs7LpKyaGKWkuLmximuajP2gQU+wyEhDAFA+AWe22blWOK0lhUyqePmUTn8uXs97v7c0+s8mTZdPfp09EO3aw1VN9fdZ26dJEbm7prl+XLrHtNjbMhUEexobCNg655cUL9tls2ZL9MU+fsmNmz85/Px8+sMlsly7MDz/tvVSqFFvlS1s9ataMbbe1ZS5erq55m0AX1XH4Hq5kKwhlfGHEEjH9d+c/0pmvQ7oLdOnuu/QIsN3+u0nFTYWa72ieK0U7jQUL2JJ8dDQLkBAE5jNcVPjZOOjpEWnrxxNcQYcD0s30YTFh1Gx7M4Ir6I9Tf1BCcoICJP2R69eZMgcwP8nnz9my+Lt3ShGnQMjifnj/nvl7Aul+goomPp4tm1apwuSoXJn5c6e9/OPi2BgBLFivMKKoZ9ObN8yVI+PEPKOCLa9Yj5QUtkQ+ZgyRjg4biyZNflzivnqVWer69pWPHDlRlJSKhAQWp1CxonwKliUlsQlXu3bpEyQXFxaQv2ULU9zS3OhmzJDtCkRRGoeMnDvHPpNr17I/5vff2SqPrNyj4uKY4jxyJIuFSVuJmDGDrYBMncoCXi0smK7QunX6uQsXMpmzmygV1XH4Hq5kKwhlfmGCvwbT6NOjKTElkYhI+nun304SXAVqubNlrlxHkpLY8hDAlgk/fyZq1YrdPBs2yPUSZEZ24yAWs+soZRFKcAVte7Atk/U/WZxM0y9NJ7iCam+sTa8jXytI4h/ldHdnFgQtLRYNrqdHtGJF7nwiCwuyuB927iTp0mV21jZFkZLC3KecnNJfNIsWsYA9InZ/HDigXBmzQ1nPpvBwIjs7pmCfP6+YPr9+ZbENaX78lpZEq1alu5JIJOkK2+PH7L5S1ApEUVIq3NzY55df15688OwZ0ejR6VZTZ2dWifXSJbYCUbp0+hjt38/8+ePi8t9fURqHjHh4sMljdgHfHz6wyUpGlw5ZkpzMYrU6dUoPGG/Zkj33EhPZmISGsmOjooh0ddkxOjospmXr1szKf1Edh+/hSraCKCxfmMj4SLJcZUmLvBdRsjiZdvjtIBU3FXLa6EQfo3NOx5CUxCKQ07Jf+Puz8usA81ct7GQ3Dm/esGuw6exBcAVVdq9McAXZrrOlfy7/Q7ff3iaxRExHnxwlvQV6ZPyvMV16eUmxwmfg5Uu2HJfmpw0wi+CtW0oTKU/I4n6YNSvdjzPt4a1sJBL2smvViqQpr/76K13ZJiLatYvIy0t5Mn6PMp5N4eHs+aFIBTsjycnMvSctuE5fn7k9BAenHzN9OkkDap8+lb9MheUdkcbQocwf+nuePmXKWp8+ipUnbYKUFhBeqRLRsmVsRSsNKyu2T1ubKeCbNuX92VDYxiGv+H3wo833N1NSSuao33/+Yc/LwED5y/D2LQsOTxsrExNm1X7+PP2Y+Hi2WjFqFPPvzhiM+fUr0c6dt+UvqALgSraCKCw3bnhsOHU70I3gCnLc4Eh+H/zoxLMTpDVPi8xXmtPzz89zboSYBcPYmMjIiM0+u3ShLNM4FTayGwdPTyZ/+3XDqeTikvT883NaemMpNdnWhERuIoIraPjJ4URE9Pzzc6qxugapuKnQlAtT6P2391m2KW/EYqJ165glQEODBXnVr1/4UpNlhSzuh759mRXfwKBwXvO9e8y/VBCYv+LWrcyiY2fHApQ2blS2hAxFPZsWLmSfR5qCranJshYpm9u3mcIoEjELXM+ezHoqkbDVEkNDdn8tWiTf1aLC8o5Iw8qKPdczIhazwN8SJfKfIrOgJCczS3Za7mY9PaL585mlNCGBTdrGjElfrXBxyVv7hW0cckvaM7D7ge4EV5D9envpuyk6mn2Pf/tNsTKlpDCXkG7d2DMPYBmGvl95TAuC/fyZ/X/zZiJVVTFt3qxYeeUBV7IVRGG7cQ8FHKJSS0qR6hxVmnllJt16e4tKLi5Jxv8a0403N3LVxtu36RlGkpKYzynA/LYLK9mNw4YNTPYGG5pT+eXl6eabm9J9EXERtOfhHrr++joRMSVbY64GlVtWjgRXgdTmqNHgY4Pp4ceHiriEHwgJSbec1q3LAmA+fWJKXWF1IZHF/VC7Nntx1KtXcHnkyf37zBqaNj5XrqQXHpo4UfljpKhnU8eOTLkeMiKW1A2+0MWLCuk217x5w6zXenpMIRg3jr30P3xgygnA8jbLi8L0jkhJYROLadOIHoc9lrrHrduYSAAVGuXH15eoa1c2NuXLM3//tEJHEgnRw4dET56w/9+7x6yrOU3IC9M45IWaNZm12GG9A1V2r0wd93akZDF7uKxaxT6jmzdzaESOfPjAJtppKQFbtsy+UNj790ROThEEEE2YoPxnZEHgSraCKIw37ufYzzTg6ADqsKcDRSdG04uIF1TZvTJpztOkI0+O5Kmtw4eZ5aNjR/bNWbRITkIXkOzGIe1BbfqXM8EV0uwiWRHyNYQmnZ9E5ivNCa6gqu5VSWueljSTy6WXl7IsCCRPJBK2NKqvz5ZKO3QgadXCvXsLX2YLWdwPhobML33IkILLI2/SrKJp2UhcXFiuYIAFdynzJaKoZ1ONGuw+Mxk4jhz7sEozaUpAYSIsjC1hq6gwi+2yZcxCevx4uq/vixeyr/JZmN4RwcHsu7lpE1G9zfWo+Y7mdNb/DgmTy5NV92OFbuXIy4vlWAdY8Or16z8eM2UK2z937s/bKkzjkFsSEtj3deZMohKLStCo06Ok+z5GfSaNUQ3JuqOn8gTMQHw8Kx5mYsLG47ffsi7i5eHhRRMnsmNat2YuJEWRnynZKkqq5s5REMbaxtjZdSdO9j0JXXVdWBpZ4ubQm7A3tUePgz3gfsc9120ZGADh4cCVK0CDBsBffwHLlslReBnz8iX7/VF4AACwMLTI9tiKJSpieZvleD72OdyauuFV5CuY6ppiTtM58Pvoh1a7WsF+gz12+e9CkjhJEeJDEIDffwcePwaaNAHOnAFq1gRUVIB+/QBbW+DIEYWIohCIgNOngfh4QKXqeYw+Mxq33t5i1oFCiCAAAwcCz58DU6cCu3cDBw4AvXsDtWsDqqrKllC+SCTAq1dApUpAhOgxwqssBQAMPDYQnfZ1wq23t5QrYAZKlQLWrgUePgTq1QOmTAGsrACxGNDUBBITgVatgDp1gAcPlC2tfAgKYr+rVAFefX0FS0NLrFymDsQbIcDmN/Q81AMfoj8oV8gMNGkC+PgAO3YA794BjRoBvXqx71waixcDgwYBM2cCK1YoT1Z58OoVu8csq6RgiP0QtLZsLd2349h7JKp9wGOnZhhxagQiEyKVJyjYPTRpEnvnurkBHh6AjQ0weDAQEpJ+nEhEWLEC2LQJuHkTePZMaSLLj+y076L8wy3ZWfM68jX9tv83CosJo9ikWOq6vyvBFTT5/ORclxYPDWWR3yIR+y3v5dX8kN04mJgQqaqlEFxBcAXde5/76gr3Q+/T3od7iYgoPime1t1dRzXX1CS4gsotK0f/Xv+XIuMjZSF+rpBIWGo7bW0WeT9nDrMiDhiQ+RhlIov74cYN9h2rvaKjdNzqb66f6++rMnn6lFlnALYCdOUKcyt59Ejxsiji2fT2LbvWf/4hwsQK1GjZQJJIJDT/2nwy+teI4Apqtr2ZUlaBcuLcufSAOmdn5nZw9Ci7t1RVif73P2ZJLCiF6R1x/TrLEvHybTTBFTR400ICiFznJNFC74WkMVeDDBYaKK12wM+IiWHZT7S1WYDmtGnpVtDkZFYmHMg+I1ZhGofccuIEu6bb38UKSiQs7WvlGrE05cJUUnFToTJLy9Cxp8eUImdWhIezVQYNDZYta+xY5lqScRzCw9OPf/lS8TIWBHB3EcVQ2G9cvw9+pDFXg1rvak1iiZhSxCk09sxYgiuo58GeFJ+cu6z/376xQgElSqRnHVm9Ws7C54GsxkEiYRMDg1KRUmUtv6XU9zzcQxVWVCCPlx50NvAsNd/RnOAK0l+oT39e/JNCvykuDcajRyxvs6oqS/uX9qJ58IAtrZ48qTxlu6D3w717LPMBQFRhqSXV2ViHlt1cRvOvzZce4+blRj7vfX7SinKRSFjBlEqVSJrholSpzBH4ikARz6bnz4kaNSKa/ncSYZYKjTyQXic7OjGalt9cTmWXlSW4gpbfXC53efJKcjLR+vVEJUuysRo0iPn7DhrE/l+zZsEz3BTGd4T/R3+CK8i4yQGqWZMF7hIRBX4OpCbbmtCCa4U3AOf9e+ZKJgjMiLJ2LXObS0xk76YuXbJ+/hXGcciJpUvZ9/DNx5hM7+q0gP60CYXPex+yXWdLnfd1LnST2bdvmQudSMQmSAMGhPyQ//zECfY+++8/5RuKcgtXshVEUbhxN9zbQHCFVFGRSCS05MYSgiuo0dZGFBEXkat2goNZ1ouEhPSsI+vWyU/uvJDVOKSVDy5nE0RwBRksNMh3+7fe3qIq7lUIrqBxZ8dRbFIs3Q+9T70P9SYVNxVSn6tOv5/4PddZXArK16/pfvKDBjGf0itXWHEAgOV1vnpVIaJkoqD3g6srk19NXSL1jYcryGKVBfU+1Jv+d/l/pDlPk+AKqrWhFm28t5GiE+VQNUMGxMWx61FVZX6VJiZEr14prn9FPpuGTX1JcAVturf1h30JyQm04d4G6UTU+7U37X+0v1CtTERFseBIdXWW1WfNGqJTp1imm4wBd/mhML0j0mIEjj09xu6tsj5047t4eLFELPWpP/70OC30XvhD2rjCgK8vy2gBsOxLAQHsnkubMIi/+3oVpnHILadPs0IzS28sJbiCvsZ/JSI2mShZMnPe8KSUJPoS94Wef35OHq88aLf/7kKlcAcFsfsJYO+pSxky5X77xlZYAKaQp41hYYYr2QqiKNy4EomE+h7uSypuKuQV7CXdvv/RflKfq041Vtegd1F5Ky/46FG6RXvTJllLnHeyGofr15l8tYbsIq15WhQeE/7jiXkgNimWxp8dT3AFVXGvQrfesuTVLyJe0KjTo0hzniYJrgJ1O9CN7ry7U6C+coNYzJZPBYGVSQ4OZkFbW7awPKbq6qTwTA8FvR8GDGAp4GxsiGptqEWOGxxpkfci6n6gO1VYUUGqdAuuAmnM1SC4gjTnadL5IJaU2TPYkyadn0Sunq604tYK2uK7hQ4HHM5VUSZ5cf9+el5ZAwMWXKcIFPlsqtXtGmG2QFdeXcnx2CHHh0gnSR4vPRQgXe559Srd3adZs/RJUWgoy3aTVeBdThSmd4SlJQv+DP0WSpW77KcGTX8+QR11ehTBFVR6SWla57NOaVVxs0MiYfnpjY2ZS4KrK1PQPn1igZJnz6YfW5jGIa+MOTNGaiR6/Jh9P+fM+fG4TzGfyOhfIxJcBWnAvrJS0WbHihUPpJV0Bw9OT+8nFrPaAwArvhNesNe13OFKtoIoKjfut4RvVMW9CjXb3izTdq9gL9JdoEsWqywo+Gtwrtp6945VdRoxgmVQEASWVk6ZZDUOO3awb3uLTZ3Jeq21zPq68uoKVVxRUZqpJTI+khJTEiksJoz+ufwPlVhUguAKarq9KZ0LOid3a8Lp00x5MzJKV6q/fGF5mxWddrGg90O9ekzJ7tFLTLoLdGnc2XGZ9n+M/kinnp+iWVdmUdtdbUl/gb5U8bZbZ0ed9nYinfk60m1pPxmtqMqo6hkbm54K08Sk+BRBGTYs3ao2eGhCriyeYomYdvrtlE6a2uxqQ34f/OQua25Jy+ijp5du1fbxYe4/gkA0fjzzD84theUdkZiYnqkiMZFNwqdO/fk5867Oy3Qf6S3Qo3U+hWT5MgNhYelWUisr9hx0cGDPkrQCUYVlHPLC58/s+9h+T3uyX29PRMxVRksrXTnNyOBjg0l1jioNPDpQqmhrzdOizfc3FxqrtqenJ8XFEf39N1vlK1mSpWhME2/XLubHvX27cuXMiV9GyQbQCcDGypUry+zDywtF6cYNigiibwnffth+590dKrGoBJVfXp4CP+eubNS0aeybtGJFegn2nTtlLHAeyGocpk9nL5Ua/9WkiisqyrSSY1xS+jrdX5f+IsNFhjTi5AjyCvaiyPhIWnZzGZVbVk6q/J16fkquD7mgICJra3a9CxeyB1bGpURFpZIr6P2Qlv6p6Ww3gito8fXFPz1eIpHQyy8vaeWtlVR/c32pMuC0wYnmes2lm29ukv9Hf0oWJ1NSShKZrzQnk8UmubK4ygN3dzYZ0tJivsDyfO8p4tlUu3Z68ZBVq7I/TiKR0P3Q+zTzykyyX29P9TfXpyXXl9DMKzPJcJFhofTXfv2aqE0bkhbaePiQ5dgGiMzNc1/RsrC8I54+ZbLv2kW0+uxFQpn7dPBg1sdKJBKa4TGD4AoaeHQgXXpxiepsqkNwBanNUaPRp0fTgw8PKCwmTLEXkQOnT7O82oJANHw4UfXqzCB0+3bhGYfcEhvLxmvhQqIaq2vQb/t/o/fvmcV+zJgfj7/y6grBFTTDYwYRsTzoDbc0lD4TR54aWSgU7Yzj4O/PVhwAVmMgrTJrxmqfhS1NbRq/jJKd9sMt2bknNimWTj8/nWnbgw8PyGSxCZkuNaXHYY9zbCMlhflQiUTMd7F5c6bg7dkjL6l/TlbjUK8e+7arT6pGcAWtubtGLn17BXtR/yP9SXu+NsEVVH55eXL1dKXElETa9mAbVf2vqtSynZfsJnklJoZVuANYJa5vqfOpe/eIqlRRTIaLgtwPkZFMdoDIaWkXgivo4ou8+buEfA2hxdcXU60NtaQvlwZbGtCq26so9FsoPQt/RjXX1CQVNxVacmOJUl46oaFsOTQtl7a8lkUV8WwyNk51G6u3nIZsd8u0LykliS6/ukzjzo6j8svLE1xBKm4q5LzNmezW2UndfhpuaUj/3f6PwmPDabf/bpp8fjJ9js3CTKcEJBJWoEVfn1m1V69mltEqVTJXHPzZ16iwvCPSMlXcuUNUam5VQs8eFBLy43FiiVjqFjfy1MhMvvOPwx7TkGNDSH2uunQ8ux3oRq++KDDYIAe+fWNKqCCwAillyrCA/U2bsqmQUkjx92fjtW+fhLTmadHk85OlhqPvM3EkJCdQ1f+qksUqC4pNSo8qlEgkdOr5KTJdakpwBbXc2ZI8X3kqVdn+/n5ISWETdB0dFhi5bFm6UejGDTZRUnTQeG7gSraCKCwP0Lwww2MGqbipkGewZ6btTz49oTJLy5Dxv8Z0P/R+ju2kZRwxMGB+Yk2bsgfAoUPykftnZDUOZcsSARLC/1QJrqCzgWd/PFGGxCTG0J6He6j9nvY04Gh6Xr31Putp5pWZZPyvMcEVNODoALm5LEgkrCCASMSWTUNCmF9p2bIsNVlg7hYq8k1B74ctW9gTynxZDYIr6E3km3y3FRQRRPOvzSfbdbZSha7x1sa00Hshtd/dXpphRxl+ppcvszESBDYu8vCdl/ezKW1S1K4dEYY2pIabmlBMYgwdeXKEBh4dSIaLDKU+8132daFtD7ZReGz6jOLJpyc023O2dBKqOkeVLFdZkuAqkP5CfVrovVChKTJ/xps36dU8mzRh1QbTlut9fFgWkp07sy5kU1jeEUuWMPnDP6eQymw10u48/YfJQYo4hYadGCZN85qdMhb6LZRGnBwhVbbhCnLe6iyNUykMXL/OFDSAFYsqakr2oUOpk6J7SbTs5jI69+QqGRgQ9ez547Gunq4EV0hjU74nKSWJ3G+7U4mFJaQpaOVp8PkZ2d0Pr1+nF1urVYvIz49NNEqWZM/Ixznb/hQKV7IVRGF5gOaF6MRoqvZfNTJdakofoz9m2hcUEUQVVlQgg4UGmUqQZ0dwMNGkSczHLyaGlZnW1GTWEkWS1TioqxNp6iRIXwLPwp8pTJ60l1Pw12Bp/xVXVCTHDY6kNkeN1Oeo0/RL0+WmRFy+zCY/pqYs8O7JE+aKUb48ZWm9khUFvR9mzWITNf0F+iRyE8ksA8WTT0/I1dNVqnCnvWjs1tlRQFgWZckUQFraKi0t9lT+80/ZLo3K+9l0/z6Tu1EjItG0clR/c31p5hejf41o8LHBdOzpsRyDTiUSCT348ICmX5pOFVdUZBZSVxWCK0jkJqI/L/6Z6VhlIZGwSWBa9dV169i2a9eYqxbA/LbXrmXV79IoLO8IDw+Wt/h15GuCK8jGJXNC6aSUJOp7uC/BFTTryqxcfdbRidHk5uVG+gtZbITmXE2adnEa+X/0p6iEKHldSq5JSGA+6KqqRMbGCXTtWtZVCAsjCxaw71TaiuSKFSRdicjIs/BnpD5Xnfoc7pNjm+Gx4dR0W1PpM7DJtiYKj4f42f0gkRDt389Snqqrs3iIgAC2GmFiwtLUFha4kq0gCssDNK/4f/QnzXma1HJnS0oRZ36zv458TZXdK5POfJ0frN0/IyKC+VKZm7OZ55v8GyHzzPfjEBHBvukmlT5KHyi5zQkua15HvqZ1Puuo095OUpeSNF85w0WGNPvKbLmkyAoIYFktdHSYr6KvL1O8LS1ZekN5UJD74cgRVlynUuV4aUYDeRAUEUSLry/O5MNtscqCeh7oST7vfRSqyB08yCYVbNWFWXKiZKSbyPvZ9PgxCzazqJJAmC2Q+UpzslhlQZ7Bnvkuqy6RSOjW21s04dwE6cqP6hxV6ryvMy2/uZwqrqhIY86MoTOBZzLFRSiSt2/TfbXT0meKxSw/fZqLWrVq6SnkCts74tQjT1aIxi09s0tCcgJ12deF4Apa5L0oz20mi5Npp99OarGjBanOUZWuHFmvsabtD7bn+/sgKx48ICpbNo5UVFhQ3eXLShUnVwwZwowkH6I/UFBEEDVqLCYHh8zHSCQSara9GRksNKAP0R9y3bbHSw+pCwlcQU4bnWiH345MribyIjf3Q3h46goZiHr3Zu+u8uWZ209hcR3hSraCKGwP0Lyw6f6mTPmzMxL6LZRqrqlJmvM06VzQuRzbiopiuS9HjmS+v/r6LLtFtIJSGH8/Dnfvsm96xbq+JLgKZLHSQjGC5EB8cjxdeHGBvsR9ofuh96W5t9XnqFO3/d1kbtn+8IEtvamoMAvbzZtMMYqX03yjIPfD4MHM4tSmSyQZLDSgptubykyu7HgX9Y7W3F2T6YVTfnl5muM154dVHnmxaxdTyhYsYC4kNWvKJp+2Ip5N8fFEKiUDWWGmBfrkctxFZm2niFPI+7U3TTg3gcyWm0kVN5GbSJo1ocOeDgpdoUojq/SZRMwS5+mZOTPC7t23s2pC4bx8yXxdp+7ZQnAFbT/OvmSxSbHUZlcbgivovzv/Fbif8Nhwmn9tPpVZWkZ6T6nPVaf2u9vTiwgF5a/MghMnvKV5tUUiouPHlSZKrjhzhq2WzL06lwWcasf+kA1mh98Ogitovc/6fPVx/OlxctroRJarLAmuIJ35OjT8xHC5Ghty+1wSi1nQp0jEYiDOnCGaOFFxQfw5wZVsBVGUlWyJREJuXm4UFBEk/X9GPsV8Ivv19qQ2Ry1X5Vr//JN9u9zdWcliFRVWtOb7ogDy4Ptx2LuXyVJ78nwyX2leKKKqsyL4SzANPzlcmnZOe742nXl+RqZ9REenF66ZNi19PCIimF+tLCnI/VC/PlNaJk9LJBU3Ffrf5f/JTrAciE+Op36H+xFcQSb/mkizKAw8OpDuvpO/L2da+e7Tp9lnoKlZ8LSY8n42xcezoFqUu0MGc0sRXEFLbiyRS19iiZhuv71N0y5Oo0orK0kVbq15WrTIexF9iftC54LO0RbfLdKCHYogLX2msXHWfvVLlxJpaKTQkycKEylLoqPZ/T9/PtHsBZGE8jcoLDyZviV8I+dtzqTipkJbfWWfh/XJpyfU+1Bv6QqexlwN6n2oN514euKHFVR54+npSSkpzL0RYPdZdiXYCxNDjw8lowWmBLDvWxqfYz+TyWITqr+5foHd6iQSCZ0NPEvqc9Wlqf9s19qS+233XBeryy15fS5du8ZW+jQ00jMyvX+vnGJrGeFKtoIoykp2RiQSCbXf055me87OtAz7Je4L1d1Ul0RuItr7cO9P28iYceTiRRYxnOZrKm++H4e5c1nfThvqUIsdLeQvQAFJFifTuDPjSHAVSMVNhRZfXyxTF5LkZKLRo9ln0rMn8593ciJq2DBvOX9zoiD3g7Exk2/G2psEV9Au/12yEywXSCQSWu+zXhrM1WFPB9JdoEtwBZktN6OpF6ZSyNcQucrw4QNR585MAUjz8d24MX8rQvJ+NjVvzqzuANGe61cVElxMxMbJN9SX/rn8D1X7r5rUql3ZvbLUatplXxfa/2i/Qpa/M6bPXLQoc6aR0FAiA4NEsrNLn0gpA19fNk6HDhH99htR5crs2V5nUx1SnaNK+x/tl2v/EomELr28RGPOjJEGxGrN06IJ5yYoLPA44/2waxcbL0Fg2bEKG/HxLOYhNpao2fZmZDa7PqmoZDaKDD0+lFTnqNLDjw9l0meaop2W+Set2Jf6HHUaeHQg3Xp7SybGqvw8lz59SnfR6tePqGtXpnSflf/jJlu4kq0giouSHZsUKw16sVhlQWcC062pGa0dOT2Mv31jL5wSJYiePWPuIwDRtm3ylf/7cejdmwVPGM4vReWWlaOTz07KVwAZ4RvqK126rbm6Jnm+8pRZ2xJJeoaBBg1YEJeKCiuSIitDf37vh6gokqbvq+3ekuAKhViQs5QlIYo8gz3pa/xXikqIoj6H+mQqyKG7QJda7mwp10pqL18SVa2a/pncTI1Bjo/P/VjJ+9lUsSJzc9HRIVpzdx3BFQov9JOmcP9+4nfSnMuCLssuKytV5Jy3OUuPlWcZ95gY9swB2P2UFqxGRLRgwUMCWNChsti/n8nm709k2GITNR92mf449Qepz1WnE89OKFSWmMQYcjnmQmpz1KQrRv2P9KcvcV/k2u/398O9e0QVKjCj0MqV8s1Zn1d8fNh4HT1KVGllJSo5sh9lVHGuhrBJ7fRL02Xet0QioWNPj5H1WmuCK6j7/u5SY4PDegfafH9zgSav+X0uicVE8+axd5alJcsco6bGJrnKgCvZCqK4KNlpXH51maqvrk5wBXXd31VabCA6MZoab21MIjcRHQ44/NM2Xr1iM82wMJbSqkULdjPIc3nn+3GwsEhVUKaUJriCdvjtkF/nMkYikdCRgCNSi2rfw31lGql/8CCzAlSpkl5USFaToPzeD0+fMpkAoorLLQiuKDTp24hYVc/F1xdTjdU1pMp2v8P96NWXV3JzRUpKYiWwAebu8+0b0e+/s0qruelSns+mtOqBFSoQlR34N9mstSHdBbpKdcuKiIugpTeWksUq9v0xWmREA48MpNBvoRSVEEUVV1SknX475SajRMJy/IpELID3WaqruKenp3QVSR6pGnND2sreixdE+NOYGiz4g+zX21Pb3W2VIxCxbCZTL0xNd5Wbp00zPGZIq7PKmqzuh6go9q4C2MperPwXPnJFmrvjA/9kErmJSNTqH+kkLSE5gaqvrk6VVlaS60qNWCImj5csOPZbwjeqvbE2qbipSFchhhwfQs/D8x6FWNDnkqcnCwjV0GBxPMp65PxMyVYBh5MNzc2bw3+kPxa1WISn4U+hraYNANBV18WZfmdQ16wu+hzpgxPPTmTbhrk5cOwYUKoU+/++fWxbt27Ay5eKuAogLAxQUZEAOp+YTCXMFdOxDBAEAd1qdsPBngehpaqFfY/3oeLKijj69CibJReQnj2By5eBL1+ArVsBBwdg3Djg1SsZCJ9PqlcH+vQBSpcGPsV9gKaqJgw0DZQn0HcYaBpgWsNpeDLmCZ6PfY5xdcbh+PPjqLa6GsyWm8HjlYfM+1RTA9auBVavBs6dAxo2BFRUgI0bgTVrZN5dnnj9GpBIgPBwQFzeE2+/vUXNkjUhCILSZDLSMsKUBlMQNC5I+qza9WgXKqysgAFHB0BPXQ+Djg9Ch70d8Cbqjcz7FwRg8mTg0iXg82egTh3gROpjculSoFEjIDFR5t3misBAwMwMuOMfBWhHwKZCRTwJfwK70nbKEQiAmkgNS1ovQfSMaCxpuQStLFth0fVFqLCyAuptrof7offlLoO+PnD4MFCjBnDvHlC5MhAcLPducyQwkH2fzC0k+F+NfRA/7IUmTdi+JTeX4NnnZ1jbfq30/SwPVAQVtLBoAQDQ09DDTOeZcLF3QWmd0ohPicc2v22otqYa2uxugxPPTuBbwje5yZKRpk0BPz92P+3YAUycqJBu8wRXsjk/RV2kjumNpuPx6MfQVddFYkoiOu/rDP8wf5zrfw6OZRzR81BPnAk889N2kpKAdu2A+fOB06fZS7lTJyAqSr7yx8QAsbGAjmEsoMKUUgtDC/l2Kge6VOuCF+NfwMHUAZEJkeh+sDs67u0oEwWhYUPg1i2gRAn2QLexYQqcMnn2DKhqHYP4lHiY6poqV5ifUNW4KtzbueP52OdoX6U9QmNC0WpXKww9MRRiiVjm/Y0Zw5TsN2+Ao0fZy2XSJODaNZl3lWvSJsvx8UC8ZjASUhJgVdJKeQJlQEVQQfsq7XG2/1kEjQvC+Drj4f3GG4/DH6OGSQ14hXjBaq0V1vqslcmk9XuaNQPu3weqVgW6dgV27aoITU02Xh07yry7XDFkCLBoEXDZl82kK5VXR5I4CbalbZUjUAYEQcDUhlNxvM9xBI0LgqWhJe68vwOnTU6wdLeE+x13hMWEya1/kQjw9weaNAE+fACsrIDr1+XWXa4ICgLKlwcMdNWBgJ4QPtmicWMgKCII867NQy+rXmhXpZ1CZepUrRO2dN6CD1M+IHBsIBa2WIiu1briSfgTdD3QFYaLDWHpbgk3Lzf4fvCVy72VRunSwIULgJsb0Lq13LrJN1zJ5uQKVRVVAMCbqDcICA9Auz3tEBYThgsDLsC2tC26HeyGCy8uZHu+ujpgawusWgV4eTEFISgI6NULSEmRn9xpCoBOqc8AAA2RBsrolZFfh3KkrF5Z3B1+F9MbTkdJ7ZLwDPGEzTobHH92vMBtV6kCXL0KlCkDPH7MXjDKYsEC4MEDwNQqCABgaWipPGFyiZm+GY73OY6LAy7CQMMA2/y2ocyyMrgSfEXmfbVqBdy+DRgYMAWuTBmgRw/g7VuZd5UrypdnK1NQjcc3ycdCpWRnpLJRZSxrswzvJr3DklZL8CHmAxJSEmCgYYBTz0/Jrd/y5QFvb2DgQGDrVnOMH8+86yUSYPlyYNMmuXWdJc2aAf37Az4vmJKdgngAUKolOyssjSzxbOwznOxzEjVMauDV11eYcH4CGm5tiOjEaADArbe3kJCSINN+1dTY6t7AgWzi6OwMHD8u0y7yRFAQez4HRgTiuL8X7B1TYGBAGH12NDRUNbCyzUqlySYIAqoYV8Ffjf7CsT7HEDwhGPu770cZ3TJ49fUVXK+6otbGWii3vBwOBhyUmxwiETBrFtChg9y6yDdcyebkiSrGVeA12AvqInX0OtwLmqqauDjwImqWrImuB7ri8qvL2Z67eDHQti0wejRb/lq3Drh4kVni5MWLF+y3Zuk30FbVRqMKjaAiFN2vvaqKKha1XISQiSEIGB0AS0NL/HbgN0y/NB0pkoLNVsqVYxOg0qWZRaBZM7ZsqmhOnmQrH1XM1QEA9crVU7wQ+aSVZSuETwtHW8u2CI8LR4udLdDzUE8Ef5XtunP16szCZmkJfPzI7idlLW1bWQH29gAM0ldVrEoVPiU7DR11HUxtMBUvxr3AhLoTEBYThquvr8Ltqhv8Pvph8Y3FBb6XvkdTky1n9+79BqtXMyU3KYlZ4CZMAJ4+lWl32RIbC3h6Al+/AkHhTMn+FPMJGiINVDOpphgh8kinap3wZMwTvBr/Cu0qt8PLry9R+b/KWHxjMRpsbQCjf43Qbk87rLi1Aq++ysbPTSQCdu4E9u5lrjXduwPr17OJkaJZvBiYORPYcn8H/G1bwtkZ2P94PzxeeWBhi4WFymikqqKK3ta98XbSWxzueVjqmpksScbX+K8AgBtvbqD1rtZYeXslPiZ8VKa4CqHoahscpVHeoDy2d9kOv49+mHZxGoy0jHBp4CVUMaqCTvs6wSvEK8vzVFWB/fuZr1v37kDz5sxvcfVq+Vlz0pRsw8b7YGtqC49BsveXVQbaatowNzTHH7X+AAAsvrkYDbY0QHhseIHaLVeOvYRLlmSW7e7d2YtZkaSNmWlFZq2qa1ZXsQIUEDWRGs4NOIetXbZieoPpOBt0FtXXVMcMjxlSC5wsMDVlkyIbG+ZTH16woc83r18zi7qZeQIqGlQEgEJpyf4eY21jrGi7As/GPkPHqh3hdtUNjbc1xnSP6aizqQ78P/rLtD9BAEaOfIXFi9lzsEsX5k+vowP07asYH+2HD9lz9+BBIMFzCpaUeYtnEc9gVcpKulpZWDE3NMfZ/mdx9/e7qGZcDdM9psNM3wwtLVoiJDIEky9OhvVaa/h+8JVZn337Ak+eMOPQqFFsVeL5c5k1nyuaNGE/918GA1Hl0bypKnY+3IkqRlWkz//ChiAI6F6zO56PfY617ddCJIgw8sxI9DjYAwHhAXj37R0mXZiEAXcHYLbnbCSmKClAQQFwJZuTLzpV64TJ9Sbj3Itz+Jb4DSbaJvAY5AFzQ3N03NsR199k7chmYMAslWZmzF968WK2/D1+PHsByJqXL1nQ5Rej80XC7SCvjKg1Aod7HoaBhgF8Qn1g4W6BK68K5qJgZsZ8Rk1Nme/voEEyEjYXxMYCERHs77dqbEJUWC1sOTHEfggWtVqER6MeoaR2SSy6sQjV11SXqQuJsTFb2q5dm7le9esHuLvLrPlc0bEj4OEB1Klgh45VO0JfQx9m+maKFaIAWBpZ4mDPg7g59KbUL/lR2CPU2lgLM6/MlLlv/bRpLMjYw4NZtFetYn7A//wj026yJDCQ/Y6KAkAqaNvADP5h/oXOVeRn1C5XG1ddruJY72PQUtXCqcBTKKdXDif6nEC3Gt1QwaCCTPvT1WVBq61bA6GhbOXG3Z25/Mib9+9Z39HRwPNPwUCkORo1Ivi890HjCo0hUhHJX4gCoCZSw6jao/Bi/Au4NXXDhZcXMPrMaDSt1BS3ht1C85LNMefaHDTd0VSuftvKhCvZnHyzsOVC+P7hC30NfQBAKZ1SuDzoMsz0zdBuTzvcfnc7y/OqVGE+t7a2bFlu1y7A0JBluoiWnaEPAPDoEWBonIzXEZ9w/sV5HHlyRLYdKJk0i8Hria/Rq2YvxCTFoOWullh/b32BHlpmZsDdu2xSdPQosGKFDIX+CVL3Hk1gT+A6CBCKVDaYrNBT14OprikECEgSJ6Hlzpb45/I/SBYny6T9EiWY25WzM8veM2kScEX2ruBZQsQy0cTGAnZ2QEB4gNIzi+SX+uXr4/qQ6zjc8zDM9M0gJjHmec/DTM+ZMu9ryBCWdcnfH5g7l/n/rlwp/6w+gYHsmRsSAqi1/Rs+STvwKfZTkVKyAfbc61q9Kx6Pfgz3tu7w++iHrvu7QkOkARVBBUniJCSJk2TWn6oqcP48MH06IBYzF59WrZgSLE88PFjA7IcPwKekYBipmOObymtExEfAqayTfDuXIbrqupjVZBZejHuBkU4jscl3E1rubIlyWuVwovcJjK8zHoIggIgQm6TgpVM5w5VsTr5RF6lDX0MfCSkJWHxjMZLESTDVNcWVwVdgqmuKNrvbwOe9T5bnCgLzbxs/Hli2jPm+vXgBjBwpWwvBs2fA86dqQLIaIuIjiuTLPzcYaBrgQM8DuDjwIhpVaIRRZ0ah9+HeeP45/2ubZmbMDUBdHZg6lQXbyZvYWLZ8Xrky8DnuM/Q19KEmUpN/x3KkpE5JeA/xRi+rXvgc9xlNKjbBgusL0HhbY5n5auvqAmfPshe/RAJ07swUKXnz8SMQF8f+vmk0Ejff3kRNk5ry71hOSJe5xz3HyjYroamqiVW3V2H13dUy99Pu3JlNjkJD2aRo507AQs6Jj4KCWB/3fFOQUmcJLr46DwCwMy1aSnYa6iJ1jKs7Di/Gv8CU+lOw8+FO1FxTE44bHDH+3HiZ9iUILCvLzp0s+9KVK8ztR54EBbFJUYmScUhSD0P1UhbSd2rtcrXl27kcKK1bGqvbr8aT0U/Qvkp7bH+9HTOuzIC5ITOkbPPbBqu1Vj9NolDU4Eo2p8B4Bntiusd0/H35bwAsC4bnYE8Yaxmj/d72CIoIyvI8FRWWWWTJEmYRcHNjyvaWLbKRKyEBiIwE1DSSAU2Wt7OoW0VzopVFK3i5eMG1iSsOPTmEmmtr4p/L/+RbQbC0ZLl+K1QA2rRh1m150qABy1drXfsLksRJKKdXTr4dKggtNS3s+m0XGlVohLuhd7G01VI8+/wM9hvsse/RPtn0oQWcOsUU7dhY9lmmKcDyImOu+3fkgyRxUqEOeswt6iJ1TKg3Ac/HPkfjio0x7tw4GP5riJW3V8q0H2dn5pqVksLy09+5w/L+ymvlPDCQTWD9Xr0DqaQgWcJWU4qaJft7SmiWwJLWS3D397sw1TVFQHgANtzfgCU3lsi8r4ED2TNRR4cZiPz8WEYmsewzdiIoiNWVCHioDmy+hcGO/eET6gN1kXqhSLmYX6oYV8HBngfxr82/iE6MRoMtDTD5wmRUKlEJWmpaaLunLQYfH4yIuAhli1pguJLNKTDtqrTDaKfRWHZrGU4HngbAUppdGMBmo233tM02t+mqVSzX7x9/sCC7li3Zy+bRo4LLlZZtQdckEkg1YBfFHNl5RUVQweyms7GtyzaIBBEWXF8A+/X2+JaYvwIBaYqAsTHQooV8Fe2oKLY0alj5GQCgmnHR9MfOCjWRGg70OAB7U3u0smwFv5F+sCpphX5H+2HIiSGISYopcB8aGsyinZbnd+hQ+fqOprk36OoCoXHshisKQY+5pYJBBZzrfw4r26xEfHI8Jl2YhOY7mss0UMvODrh5k7n9NGkCODoyw4M82LKFFXpK1mWzo8iESJTXLw9DLUP5dKhgHMo44O7wu5jdZDYECPjT40/MuTpH5v00b85qC4hE7P1Vu7Z8glcDA5l75fVrqhDe10OPlpXgE+oDu9J2UBepy7YzJVDHqA4CRgdglNMorLi9AsNPDcfKNivxT+N/sPfRXtRcW1OqUxRVuJLNkQnL2iyDXWk7DD4+GO++vQPAZqtn+p3Bx5iP6LC3Q5ZKhJoa8yPV0GBBW5s3s5dNz54sMLIgpPn36pT+AFUVVRhqGhaqyoHyxsXeBc/GPENFg4oICA+A3Xq7fCva5cuzCVBsLFO0fWUXwJ+Jnj3Z78SSdwCwl2ZxoqxeWVwfch22pW1RqUQlXHW5ipnOM7HDbwccNzjKJDOCqioLhuzdGzhwAJgyRX6Kdr16QKVKgLVDLL4msBRdxcGSnRFBEDCh3gQEjQtCRYOK8AzxROmlpXHn3R2Z9WFhAdy4AVRLnVNOn86CI2VNrVqpz1VDNjt6E/WmyLqKZIe6SB2uTV3hPcQbGiINzPaajQ57OuBT7CeZ9mNtzVzoypdn99ehQywLiawKrBGl58g+dd8HZh12QtcgCfdD76N22aLnKpIdehp6WNNhDbwGe0FFUEHbPW0RHhsOz8GeKK9fvkin3AW4ks2REZqqmjjY8yASUxIx/NRw6fY65ergYI+D8Pvoh56HemYZ7GVmBmzfzh4ooaHMZSQoiKVMKohyEJTqpSIq+Qom2iboVqNb/hsrolgYWSBgdABql62NkMgQTDo/Kd/ZEmbNAvT0WH7fzp1ZuXpZk5aXu2bF0gCAhuUbyr4TJSMIApLFyRh1ehTW+KzBnGZzcGXwFcQlx6He5npYfms5JFSwhLwiEbuPxo9nQatubjVkJH1mKldmqQMtHF8DALRUtYqNi8/3mBuaI3hCMIY5DENUYhQabG2AZTeXySz7iKkpWzGqXZv5/w4fzoIjZcXLlyzI/Pp1QKfkF2iraePll5ewLVV03Q5+RsMKDXFvxD2U0S2Diy8vwmqtFQ4GHJRpFoty5ZhfvYkJCxK/fj19FUkW+PiwuhIPkg/gQ62RePnlJaKTooukP3ZONKnUBP4j/TG1/lRsfrAZfQ73wewms9G+SnsAwM23Nwv8XFQGXMnmyIyqxlWxv8f+HypQdajaAes7rsf5F+cx4vSILB9ynTqxQK369VkRlNmzgd27gW3b8i/Py5dMKVRrsA51y9XF5s6b899YEUZHXQe3ht3C+DrjsdVvK3478Bs+Rue9CICZGbBxI1OyP35kVf6SZBfAj7g4ViRDJAJU9FiFzuJmFU1DVUUVH2M/Ytqlabjx5gaaVmoK/5H+6FC1A6ZcnILO+zojMiGyQH2oqDCfUWNj4OrV0pgp+yQZOHSIrW5Ur6YCE20TVDGqUmyDiwE2QdrceTPO9D2DFuYtMPXSVDTc2hDPPj+TSfsGBiyLRc3U2NHevTP7vRcEDw+WjtPHB2imNh1XB1+FBJJiZ8nOiHUpa7yf/B4PRj5ApRKV0Ptwb/Q41ANfkr7IrI/y5VlRIUFg6WKDgljth4IiCECNGmwSm6L3CqaalXAvlFkhilJmkbygraaNJa2X4NawWyihWQKd93fGgKMD4PHKA422NsLkC5OLXKo/rmRzZErHqh1RzaQaiAjvv6XnN/rd8Xe4NnHFdr/tmOU5K8tzTUyY5XrbNpY/tkULYMyY/Ptnv3wJVKkqwVuVq7AoUfx9sX+GSEWEVe1WYXW71TgVeAqW/1niaXjey8z17s0mQGIx8yMdO1Z2rghp/r1lygAXX56DrpouSumUkk3jhQxBELC9y3ZUKlEJvQ73QlhMGIy1jXG011GsbrcaF15eQJ1NdfI1RhlRVWVL2qqqEsybxyausmTECPa7rVN1AGzl6legfdX2uDDgAnb9tgu+H3xhvdYaq+/IQLMCS2fq4cGCjVVVZRe8GhjIgmNfvADq1AEehz8GUPSDHnNCEARUN6kOB1MHtLFsg9OBp/H7vd+zLZqWH6ysgNOnWVEoCwuWCx0oWDDkrVusWNHlywBKBKO6qTl8Qn2go6aDGibyWZkqLNQpVwf3R9zHLOdZOBBwAAOPDkT3Gt2x6s4quF11U7Z4eYIr2Ry5MNNzJhw3OuJjTLrFdFaTWfjd4XfM856H9ffWZ3leWBjLQTpgAHMhKVGCFdnIj392QACQIopCYryANffWYP9jOedbKgKMqTMGM51nIi45Dnbr7XDjzY08t+HqygJWhw1jlTrXZz2UeSbNh75qNcKlV5egra5drK2iBpoGONLrCL7Gf0XfI32RIkmBIAgYU2cMPAd74lviN9TdXBcnnp0oUD+VKwPz5z+CIACDBwPe3rKRPzoa+PaNWdxMKn3E57jPqFmy6KbvyyuCIKC3VW8McRgCCUkw7vw41FhTAw8+PChw26amrPKqkRErgnLiRMFLrwcGsnYB4EKJ7jgYcBBaqlqobFS5wPIWdkSCCLHJsbj48iKWt14OXVVdtNzZEktuLJGZZbRhQ1ZJ8+lTZowICWFBrefP56+9Y8dYRWRvb0DFOBjVSjEl27GMY6EvQiMLNFQ14NbMDT7DfaCvqY8jT4/A0dQRblfdsOKWggo3yACuZHPkQl/rvohOjEafw32kftiCIGBdx3XoUKUDxpwdk6XyYGrKgh9v32ZLbnv2sDK2o0fnzWKanMzSAj68awioSJAkToKRlpGsLq9IM6fZHKxquwrJkmQ4b3fOV4Ge8eOBDRuA9u2ZNfvcuYLLpZ4aLF/d8RPEJJaW6C7O2Ja2xfqO6+ET6oPHnx5Ltzeq0Aj3RtxDNZNq6HqgK9y83Arkj1inzlcsWcJyaLdrJ5vS0BlXHoac6QOg+Lr3ZIeaSA0bOm5A0Lgg2JW2w7PPz+C40RGb7m8qcNuVKrFUcUlJQI8eLKPF69f5by8oiKWdg+ZX3PhyFIERgbApbfNLKGyCIGBzp81wKOOAGZdn4O/qf6Nr9a740+NP9DjUI98B4d/TqRN7Ll68yAKO1dTYtl278t5WWk7zG/e/QqIehQoGFeD30a9YBT3mBntTe9wbfg99rPvA96MvSumUwuSLk3E/9L6yRcsVXMnmyAWrUlbY2Gkjrr6+ij8v/SndrqqiigM9DsCprBP6HumLW29v/XBur15sGfrff5myPHs2e0ht3577/t+8YUq5ln4coMoch4t7juy8ML7ueOzsuhNEhB6HemDz/bz7q4tErBR0WvGThw8LJlP58uy3flV/ACj2S6JpDLIbhKBxQbA3tc+03UzfDN5DvDHYbjBcr7qi24FuBVIGpkxhhTS0tVkWhI95d8vPRJqvsJUV8Oor07iLU/q+vGBpZAm/kX5Y12EdVFVUMdtrNm6/u41LLy/hdODpfE+QatRg/r7q6sCnT0zR/pSPJBkpKWy8kpIAM1s2cGGxYcXeVSQjWmpaON77OLTUtPD3478xpvYYLG21FCeenUDtTbUR8ClAJv0MGwbMn88q5TZqBDRuzHzhly7NWztBQUDJkkBClAE2Vn+HOuXqICEloVgGPeaEnoYe9nTbg40dNyIqIQolNEvIJOWpIuBKNkduDLAdgAl1J2DlnZXY/TDdGVRHXQen+55GOf1y6LSvU5ZVCVeuZCmSBg0CJk5kL5cxY1gFx9yQ5nqgWyocQuq/CgYVCn5RxYiBdgNxuNdhOJVxwvDTw/H35b/zrAw0aAC4u7OXeL16BasyGJD6jvuqexMAfimLjamuKYgIm+5vwssv6ZFumqqa2NZlG1a1XYXTgadRb3M9BEYE5rufgQOBM2eYgt2sWcHSZD5ONbzXrw+Ex4ZDXUUdZfXK5r/BYsBIp5HwGe4DTVVNOG9zxqQLk9BpXyfYrbfDLv9d+SoK5eTExiytHHrr1nlPEycSMcPDt29ARXs2IYpJivmllGwAKG9QHpcHXYahuiE0VTUxpcEUXB50GVEJUaizuY7MXApnzGD1HlavZuPVqxfz0z6Sy0VDiYS9w4gAkAp+a1FOWtStuAY95oQgCBheazjuDr+LUjql0Hxnc4w+MxrnX+TTH0dBcCWbI1eWtFqCrtW7/uCqUVKnJM73Pw+Right97TN5LsNsACdgweZz6+BAXMb0dQEfv+dPYByIk3J1ij1FjpqOjDTN4OGqoasLqvY0K1GN9wcdhMjHEdg4fWF6H24d54VgXHjgDlzgPh45oP47l3+ZBk9mv1+J2Y+rQ0qNMhfQ0WUz3GfMd1jOrof7I745HjpdkEQML7ueFwaeAmfYj+hzqY6OBt0Nt/9ODmx1GPPnrEViJR8VgtPy4Bh4xSNBHECTPVMi7UPfW6xN7XHvRH30NKiJQLCA9C4QmMQEQYdH4R5T+flywe4adN0Be3hQ2DBgrydLwjsufnxI2Bo8Uq6vThnFskO61LW2FRrE+qXrw8AePTpEY72PgoHUwf0PdIXE85NQJK4YGmTBIEZinr1Ygp3u3bA33+zCWlueP+eFbaJiAAqtriIjU8X4M77OzDUNISloWWBZCvq2Ja2xb3h99DbqjfW3VuHDns74NTzU8oWK1u4ks2RK2oiNRzrfUya6zKjpdTSyBJn+p3Bp9hP6H6w+w8Ptho1mBKQxsqVrGDDunU595vmcyoxDER5g/IY7jj85yf8wqiJ1ODa1BVqKmo4/OQweh3qleeXzMyZrGrnt2/sZZJXEhJY+r4SJQDb0szl4FdxF0mjpE5J7Om2Bw/DHqLJ9iaYdnEajj49Kt3fzLwZ7o24B3NDc3Tc2xELvRfmS2ETBBZIp6HBgut+/z1/GWLScgEbVGSVHisbFv8AutxipGWE0/1OY5bzLHi/8Ya6SB2T6k3C1c9Xcevdjy5yuaFTJ+buQwQ8ecJc6XLLxYuswA0AVCwvQhndMgBQpEtzF4S0AifhseGY5TkLbXe3xXDH4ZhQdwLc77qj2Y5mCI0OLVgfKmy8WrRgOc8bNQLK5nKhp3x5pmCHhAD6Tiew9OZS3P9wH05lnfhEFunuI8taLwMRocv+Lth4f6OyxcoSrmRzFMaq26vQfk/7TJZSp7JO2NZlG26+vYmJ5ydmed7ZsywIqEIFtvT21185BwAFBzNLW3ythXCu6IyZTeSQJLgYUUavDDZ03AAAOPbsGLru75rJmpob1q0DundnaeJOnwYSE3P/eEkLoqtYEXjz7Q0qGFSAlppWnvovDrSr0g5rO6xFkjgJ7nfdsck3PYCu1a5WmHB+AlpatEQ9s3r4+8rf6H+0f76sblZWLMc1AOzYwVYi8sqRI2yVycAoAQBQ16xu3hspxqgIKnBr5oZTfU/h1ddX2O63HaMsRqFB+fyv0PTvz9K6nT7NKuRuymV85YkTbLxEImDJb9PQuGJjmJcwh76Gfr5lKQ6U1CmJB388gG1pW7iccMHXhK/Y2nkr/D/6w2GDA7xfFywVj4YG8822sWHBq8ePs3iIt29zPvf5c7Y6KCr5ChVLVMSjsEe/lAtdTgiCgMn1J+P8ALYi/sfpPzD90nRli/UDXMnmKAx9DX1ceHkBf1/ObOrsZdUL0xtOx7p767DFd8sP5zVuzBTs/v1ZMCQRMHLkz61vL18CFjWi8FXlhdRqw/k5LvYu6FKtC1RVVHHuxTl02NshT8ElgsAsNw4ObJm0b996UuU5JwJT3YxrWkngGeL5S4/ZSKeR8Bvph9i/Y7H7NxbLQEQw0TbBiy8vsOLWCqk1dN/jfei8r3O+goA6dUp3O3B1zVvhp+Rk4OpVtvIQk8z6blapWZ5l+BXoWLUj7o24h3L65bAxeCN2+O3A0/Cn+Q6GHD0amDcPOHyYBYjnpipkYCALnrSzY654/h/9f0lXkayoWKIivFy8MMt5FnY/3I2Vd1bi5tCbKKFZAi13tcTeR3sL1L6+Psu+ZGTEXOuuXk1fVciO7dshLR4VoxqMEpolICbxLxn0mBOtLVvj7u93YWloWSgzUnElm6MwhjgMwWin0VhycwkOPD6Qad/85vPR2rI1Rp8djTvv7mTap6cH7N/PcmivWwcsXMhyj+7Zk3U/YjGLzH4dGgckacD1qiv2Pdonr8sqNgiCgI2dNsJIywgVDSriashVtN7VOk+VB7W12UtfSwuIjFTDoEG586G/e5f9rur0FqHRodBS/fWs2N+jqqIKY21jAGxs9nXfh4DRAYj7Jw6PRj3CklZLsLDFQlx6dQktdrbA57jPee7jr7+AtWtZYPHw4aysd25ImzxVqwbcfccG71dL35cXKhtVxvUh12FnYAeXEy6wXmeN5beW57u9v/9mE1mABbPmVBUyMJBZRR1rJ8N6rTUCIwKLbTn1/KCqogq3Zm7wHOyJ6Q2nw9bUFreG3UK9cvXQ/2h/LPBeUKB82qVLs5WjsDDmCrJvHyvBnh2HDrFnYk0rCd5Gh0AlVVX7VYMec8KhjAOCxgVhVO1RyhblB7iSzVEoK9quQMPyDTH05FA8DEvP+SZSEWFf930op1cO3Q92/yEQ0tGR5WbetAmoVYtltZgwIet0Vp8/ayAlBXh8p7Q0fV/FEoVvhlsYKaVTCls7b8WCFgtwsOdB3Au9l2cFrkIFtiwK5N6HXlOT/VatyBQ2m9I2eZT810FdpA7rUtaY2mAq/mr0Fw71PIQHHx6g8bbGeBP1Jk9tCQIwahSbGJmbM8UtPDzn89IUhFq1gA2+G6AiqPzSqw+5wUDTAItsFmGg7UBISILpHtPzXbhGEFg9AXNzVhGySxemRGdFfDzLLJKcDFg6vkFAeAAIxC3ZWeBc0Rn9bPoBAM4EnoGGqga6Ve+Gf678g+GnhktrPuSHevWAFSuYAUhfn72/sqsIGRjIxrVus3CISYyYpBiY6pqinF65fPdf3BEEoVD6q3Mlm6NQ1EXqONTzEIy1jOHz3ifTPiMtIxzrfQxf4r+g56GeP/iauroyn92HD9kLJiaGKd7fExrKrKC6xlGACrM+8BzZuadD1Q7oZ9MP3Wt2x9FeR/Ek/Amabm+KD9Efct1G48bA4MEhAFh+5pzcRrS12e/3IuYGUbcc9+/NLcFfgyEhCd5EvUHDrQ3xJPxJntvQ1WWK26dPrCpkTqsPN1mWRTRpwoLHDDQMCuULrrChpqKGHV13YFLdSZCQBE22N8Hn2LyvQABshe/4cVZ6PSAg3b3ge96+Zb7YAGBkmW7y/tXS9+WVZEkyvN944/rb6+hj1QdbHmxBx30dC5SrfvRo5kv/7Rvg68viV37oN5nFFInFQDvn0oj/Jx6RiZGoXbY2v8eKIFzJ5iicMnpl8HTMUwxzHPbDPjtTO2zpvAXX31zHlAtTMu3T12cla0eOZJlHZs4EDhwATp7M3Mb790zJ1i79AVqqWtBU1YSprqncrqe4svvhbvx95W8c6XkEIZEhcN7unCdL6YABb1CrFktFldXLJCP377PCC0FRbHWjIMFhvxojao2AVSkrqAgqiE+OR6OtjbIs8vQzVFRYCWci5j+6IoeqxWk5shs3JsQlx3Erdh4QBAHL2y7HmNpjEJ0UDet11nmawGbE1jZ9pUhVNetjqlZlmX+0tYEUPTbb1VbThrkhNzz8jKEOQ3F/xH2U1imN/QH70dKiJS6/uoxGWxvh3bf85SkVBGDjRhaUr6ubdUq/kJB0C3eTJkBcchyCIoJ40GMRhSvZHKWgo64DADj/4jwWei/MtK+vTV9MqT8Fq31WY7vf9kz70twKLl5kFjdbW7bcnbE4Q5qSrWL8ClpqWjAvYc4tAPmgokFFPP70GCcDT+LSwEsIjw1H422NMxVL+RkiEeHQIVbK+dKl7JdGExOZz722NhASGQIBAnfvyQN6Gno43fc0dNV1oaWmBQNNA7TY2QLngvJW637ECOaGpa7OArPu3Mn+WH19oEoV4G1cIAiEysY8fV9eWd1+NdpVbocv8V9Qf0t9PA1/mq92hg5lftmLF7PqkFllXrp3D6hdGwiJegUBAuxK20nT2HGyp2bJmrg7/C7G1xkPj1cemNNsDl5HvUbdzXXh99EvX23q6LCMI4LAiq197+YTFsYmTJUqAZfD9mHg0YEgEA96LKLwu4yjVI49PcaspU8yl8Ja1HIRWpi3wMjTI39wKwkNZZkR/vc/YMsWVmDhz/TK7XjzRguCAMTpBsCqpBWmNZimiEspdjSu2BhTG0zFhvsb8DXhK64MvoLYpFg03tY4yyqdWWFuzixt16+zip1ZuY0EszTLsLQEqptUR42SNbgCkEfKG5THyT4nEREXgbK6ZVHdpDo67++cqdJqTqioABs2MFcRTU2gTx8gMjLrY588AerWBa6GXAXAXQ/yy5l+Z3Br2C0kpCSgwdYGuPY6l5GnGRAEdo9Vr858s5s1y2x0+PdfpmTXqQOU0ysHVRVV2Jvay+4iijmaqppY1W4VHo58iL8b/43rQ65DLBGj0dZGeZ7IplGtGsvmc+cOKwz1PMPjtF49lvqvbVvg0qtL8AzxBMCDHosq/E3GUSru7dxRz6weBh0flCkISFVFFft77Ieprim6HeyGT7HpEY5lywJTp7J0cXFxbJl740bAy4vtDwvTQpsOiYhynIlmlZphiMMQBV9V8WFus7mwKWWDYSeHoYJBBVx1uQoxibOs0pkdAwaw/NkbNgA9e/7o73vvHvttawsERgSiZsmaMr6KX4Pa5Wpjb/e9WNBiAbxcvOBc0RkDjw3MUxYLa2s2Ya1WjfnyZlWoJjycTXRLlADCYsMAAB2rdJThlfw6CIKAWmVrYXHLxVARVNBqV6sfMi/lBh2d9LznISHAkCHp47ZvH7vn6tQBulTvgmRJMp8U5YO0YGw1kRq+xH+BqooqOu7tmO8iKN27s1XYr1+B3r3Tt/v6ArGxbLIUHBkMdZE6KpWoBBNtE1lcBkfBcCWbo1Q0VDVwrPcxGGsZo8v+LpkUNxNtExzrfQyf4z6j16FemSK7//mHBUGOHs0s2paWLAVZXBxzFylVJQQQJUNNpJbnoiqcdDRUNbDrt134Gv8VZ4POwqqUFc70O4Pw2HB02NsB0YnRObaRlgnByIi9QL739719m/22dHqJF19ewFDTUA5X8mvQtXpXNKnUBPoa+ljeejl61OyBKRenYPfr3Fu0XV3ZxGfRIlbAZP36zPuvMuM1JBLg3bd3MNQ05EvZBeTp56f4Ev8FloaW6HOkD9bcXZPnNqys2ESWiGWLSbvP0laPatcm+H3wA/BrllOXFVWNq2JRy0WIS46Duqo6/jj9BxZdX5SvttzdAQsLwN+fpdIEmNEIYP7YwV+DkZCSwP2xizBcyeYoHVNdU5zocwIR8RE/+GA7lHHApk6bcPX1VUy7lO72oa3NHlABAUyB27QJePGCBUUmJIhw21sHSFHFTM+ZOP/ivIKvqHhhZ2qHF+NfYJDdIABs2fJgz4Pw/+iPXod75SqtVYkSTGEDWG7mjHl9Hz1iv6NLeYBAKK1TWsZX8OtxOvA0HDY4oGu1rhhoOxBbQrZg9d3VuTpXTY1NjHr3ZsVLJk0C/PzS96fl0m7QALgXeg+WRpY85qGAuDVzg11pO0TER6CNZRuMPTc21+OVkcGDARcX9ve0acCZM0B0NAuy0zaJQJ8jfQAANqV4isz8oiKoYHL9ybj9+21U0K8AAJhxeQb+u/NfnttSVQU8PVn2l4kT2SqRry+LeTAyScbbb28RmxzLlewiDFeyOYUChzIOePDHA0xv+GMprAG2AzCx7kSsurMKx56mlzfr3JkFjhgbs6W14cOBXbvYvuDHpQARK99uYWihkGsozpjpmwEAbr69ibdRb9G+Snus77ge51+cx8jTI3NVqKFpU+aXnZLCxi7NbcTIiPkgvoxnfiMNyzeU12X8MrS2bI3GFRtj2Mlh+N3xdzQyboRx58Zhl/+uXLcxbx6bxOrrM4U7JrWo5INUry5HR8LDTw/x6ksuy3pyskVdpI7d3XYjMiESGqoa6Fy1M8adGwf3O+55bmvNGpZ9SSRK9/WtXh0IjnyFRHEiyuiWkQaec/KPYxlH+P7hCxd7F1Qzrobx58dj64OteW6nQgVWYC05GWjVigVCVqkCfI77DGMtVoyKrxQVXbiSzSk0VDWuCkEQ8Pzzc2z23Zxp3+JWi+FYxhEjz4zMVBhlx450y83ixcxfGwB0S36GmkgNAHiqKhkRlRCFdnvaYciJIZCQBL87/o5ZzrOw1W8r3K665aqN5ctZ1HxwMPAuNQtWTAzzx34SHgAAqGvGc2QXFHWROo70OgIzfTP0ONgD/2/vvsOjqLowgL83nRp6kY4gRUB67yAgiIhUKSKCVKUICChSlGJBAQVEUFAQAUUUEUGpCh+9Q6gBQu+9pt7vj5MlIWR3Z5PZks37e548SXZnd28yuzNn7j333DcLv4n6heqj69KuWHp4qaHnGDcOCA6W1eqOHZPULEB+BoCgbBcRFROF3BlYvs8MpXKUwvj64/HHkT/wVuW30LJ4S/Rf2R9Ttkxx6HnSppXqFQEBMsIHSKm4EzdOPHodMke6gHSY02IO9vTcgyZFmqDbH92eKD1rxJAhUt1n7175vVo1KXX7VuW3oKBQPnd5k1tOrsIgmzzOxE0T0WNZD/xxJK4Atr+vP+a0mIMbD27g7RVvP7Z9dLTkje7cKZMh06aNQkD2M8gQmAFZ02RFxsCMrv4TvFJwUDAmPj8Ra06uQe05tfHjvh8xrOYwdC3bFWP+HYPvdn1n9zkCAoCVKyUdoVs3ICJCUhGefho4desU/Hz8kDkNc7LNkC1tNizvsByRMZEYGTISC1stRIWnKqDd4nZYe3Kt/cdnAz7/XGpiN2smo0SzZsmCNRkyAKG3pVj2M1mfcfafkmoMrDYQc1+ei4aFG2JR60VoWbwlBvw9AJO3THboeYoXl/zsw4fl92bN8KhEIBd6Ml+QfxB+bfsrsqTJgi+2fIEXf3oRD6MeOvQcM2ZIChYg+wuQdKxi2YrxHJaCMcgmj/PlC1+iwlMV0HFJR+y/tP/R7WVylsEHtT/AwgMLseTQkke3R0VJD2nv3kCNGkBMjEJk8BH4+fgxVcRk3ct3x5QmU3Dx7kV0/q0zqnxbBTOazUDjpxuj5589DZW0KlYMmDwZWL1aFsq4elX24b2Ie8iSJovz/4hUpFi2YljSdgla5mmJ7OmyY0XHFSiatSheWvAStp3bZvfxr70G1K8PbNggAUDv3jKx7osvJAAA5HNJ5vBRPuj8XGcopXDs+jE8m/1ZtCzeEgP/HohJm+2sEJRAx47SOxoUJDWyd13YBYCpB86S1j8tjr51FLnS58LyY8tRanopw6VOAel46NFDfq5WDZiyZQr+Of4PKuZm6b6UjEE2eZw0/mnwe7vfkSEgA15a+BKu3Lvy6L5hNYehfO7y6L2896O0kcBAYOpUGcYeORLInv0hbmfYjnoF6+Gjeh+568/wSkop9KvSD0ffPoo1r63BB7U/QIBfABa0WoD0AenRclFLbDy90e7zdO8OlC0bt3BG+fJSyYSl4MxXr1A9tHiqBQDgTvgd/N3xb+RMnxMvzH8BBy4fsPlYpaSHrXVr6RnNEnsNVK0asP281K/nJDrnWHRgEcZuGItsabPhleKv4J1/3nGoHCMg9bOPH5f9FhwUDIA1zZ0pa9qsCOkTgoKZCuL4jeMo9005HLxy0PDjO3eW0pnBwcDasLUIjw5H5TyVndhicjavCrKVUs2VUjNvxa/ETylSnox5sLT9Uly8exEf/vvho9utpY00aiSBwFdfAUM/Wo+o8lNRp0AdNC7S2A2t934+ygf1C9VHm2fbAACuP7iOLGmyIDw6HLXn1EbXpV1x6l4iS8/FUkpW7QwMlN/LV7uFy/cuo3i24q5ofqp08MpBlJxeEvP3z8fqzqsR6BuIRvMaPcrVtaZoUangU6qUpGMVLixVEM7ePoviWYujer7qLvoLUpfRdUdjeM3hmLVrFoL8gvBKiVcw6J9B+HzT54afw8cnbp5KhoAMyBSUCfmD8zupxQQAWdJkwZZuW1A4U2FE62jcj7gPAIYmh/v4AHlljvmj9B6OPKRsXhVka62Xaa17BAcHu7spZIJKeSphdefV+KzRZ4/dbi1tZNIkmVH/zdfFAABX7l/BtfvXXNrm1OrpLE8jtF8oZr80G34+fvh+z/fouqProxUBE5M9u0zQatAAOBT4AwAwXcSJimcrjmZFm2Ho6qHYfXE3VnVehfDocDSc2xDn75y3+/j9+2X1wBMngIsXNY5eO4q6Bety4qOTKKUwvsF4jKs/Dj8d+AnRMdF4pfgrGLxqMCZumujQc0XHRGPnhZ0ok7MMyy26QM70OfFv13/xVIan0Hh+Y/xz/B9U+66a4QW8AODcnXNQUBx5SOG8Ksgm71Mjfw0E+QXh5sObj5XvSyxtJG9eqTASrh8AMcCo9aMe5SGS8/koH3Qt1xVru6xFgE8AcgXlQoXcFWw+pmlTyc3ecm4TAA5lO5OP8sEPL/+AKnmroNOSTrgfeR8rO67ElftX0GheI7sXpLduxa2qmjHXVdwKv4U0/mmc3/BU7r1a72Fy48m4HX4b37/8Pdo+2xZDVg3BZ//7zP6DYx27fgzbz29HkG+QE1tK8eXNmBdrXluDIL8gvPrrq9h5YSfG/jfW0GPvRdzD/cj7yJU+Fz9jKRyDbEoRxqwfg9a/tMb/Tv8PgPW0kT59gEo9PoPykd4alu9zvZr5a2J+q/m48PACBv0zCDcf3rT7mCPXZIJQmVycROdMafzTYGn7pciZPieaL2iOpzI8hT/a/4HQ66F4Yf4LuBtx1+pja9YEevaUxWrCgyWXO34FIHKe/lX7Y1XnVcgQmAHTmk7DK8Vfwbur38UPe34w9HjLcbNcrnLObCYlUDhzYazuvBo+ygeBvoGYuXMmTt20nkZncfPhTfgqX8538AIMsilF+Kj+R8iXMR96/NkDEdERAKynjVwIP4fgwGD4KB/mH7pJ65Kt8Wq+VzFz10zkm5QPP4f8bHP7s7fPIsgvCAG+AS5qYeqVI10O/NXhL3Qo3QE50uVAvUL18HObn7Hzwk68sfQNm7mjX30F7NsHnAqXgr5FsxZ1VbNTPV8fX2it0ernVjh9+zRq5quJXst7YfeF3XYfu/nsZgBA3UJ1ndtIekKJ7CWwqvMqAEBUTBRGrx9t9zEPoh4gWkejdcnWTm4dORuDbEoR0gekx/Rm03HwykF8+r9PH92eWNrI+YfnEeQfhLwZ8zJoc6NuhbqhZr6auB95Hz3/7GkzH/Hmw5vInja7C1uXupXIXgJfNP4C/r7+uHr/KpoWbYqPG3yMXw7+gs82WU9D8PeXGswHLrFGtjsopTCo2iDsu7QP1x5cQ+agzGj1cytcf3Dd5uNCLstCT7Xz13ZFMymBsrnK4uc2P0ND44e9P+DYtWM2t99+Tir3cNJjyscgm1KMpkWbok3JNhj731gcvXYUQOJpI+cfnIfWmjWy3cxX+WJh64UIDgzGrYe30P2P7on2koZHhSNGxzBgc4NbD2+h4syKePuvtzGo2iC0fbYthq8Zjn+O/2PzcXsvSU924Uz8jLnaS8VewvIOyxF6PRTFshXDmVtn0GlJJ8ToGKuPCbsVhgDfAKQNSOvCllJ8TYs2xei6o6Ghn1jROKEpW6dAQeHZ7M+6qHXkLAyyKUWZ0mQKWpZoiTR+cZNB4qeNzNk9B7ejbqNzmc6Y1NixxRvIfHky5sHC1guhobH82HLM3Tv3iW0u3r2IGB2Dts+2dUMLU7fgoGC0e7YdZuycgclbJ2P2S7PxbPZn0X5xe6ul/bTWOHRVyosVzFTQha0li4aFG2J8g/FYH7YebUu1xYrQFY+VOk0oKjqKk4o9wMjaI9GjfA98uunTRI+FFqHXQxHkFwR/X38Xto6cgUE2pSi5M+TGglYLkC8432O3W9JGei3vBQColq8ayuYq64YWUkKNnm6E92q+BwCYvWf2E/dbJj0Wy1rMpe0iMaHhBLQq0QqD/xmMnRd24rd2v0FDo+WilrgXce+J7c/dOYd7kffwTtV3UKtALTe0mADgnWrvYFC1QRhTZwy6PNcFY/4dg+VHlz+x3c2HN3H1wVW0LN7SDa2k+JRSmNp0KoplLYauS7smunBXdEw0bjy4gZzpcrqhhWQ2BtmUIoXdDEO7xe0e5WFb0kYs6Qg7z+80VPuXXOPDeh+iVv5a2H5u+xOrDE7bNg0AmN7jJpbSfvmC8+Gtv95CgUwFsKDVAuy/tB/dlz2Z4mNZwa55seasa+5GPsoHExtNRJGsRTC96XQ8l/M5dPqt0xMjEJb83pLZS7qjmZSAv68/mj3TDDE6Bs0XNMfJGycfu//glYOIQQwnFXsJBtmUIt2NuIslh5Zg0D+DHt1WJmcZfFTvI6TxSYPxG8cbKpVEruHr44tFrRchY2BGvLTgJfy0/6dH9x25dgQKCnkz5nVjC1O3dAHpMKnxJBTIVAC3Ht5CkyJNMK7+OCw8sPCJpbwtk+jsrRRJrhEdE43Ov3dG6RyloaDwyqJXcD/y/qP7V4SuACD59+QZRtQagQwBGXAv4h6aL2iO2+G3H923Pmw9AKB87vJuah2ZiUE2pUilcpTC0BpDMXfvXKw5sebR7UNrDsUbhd4AwBrZniZ3htz4qdVPOHnzJLr83gWh10IBSE52+oD0XInOzVoWb4llry5D1rRZAUgKVuuSrfHu6nex+sTqR9uFXAlBgE8Apm6b6q6mUjy+Pr4olKkQftz/I/pW6ot9l/ah15+9Ho1AWBbkqvhURXc2k+LJnCYzhlQfgsiYSBy+ehjtF7dHVEwUAGDH+R3w8/FDkyJN3NxKMgODbEqx3q/1PopkKYJey3vhQeSDR7dfengJafzSMKfNA9UvVB/vVH0HUTFRaPpTU0THRONOxB3kTM995W6Wi5zj149j+vbpUEphTos5KJGtBNovbo+wm2EAJMj28/XjRawHGd9gPCrkroBp26dhYNWBmLdvHmbsmAFAVnsEgMJZmI7lSfpX7Y8sabKgeLbiWBG6AoP/GQwAOHj1IGrlr4W6Beu6t4FkCgbZlGKl8U+DGc1mIPR66GND2hcfXkShzIXYM+qhPn3+U5TMXhLHrh9D9z+6I0bH4OnMT7u7WRTrm53foO9ffbHt3DakD0iP39r9hqiYKLRc1BL3I+8j5HIIIqIjUDC4oLubSrECfAOwoNUCRERHYMf5HXihyAvov7I/Np7eiEt3LyF9QHoE+XFJdU+SMTAjvnrhK3zR+Av0r9IfU7ZOwZdbv8SeC3s46uBFGGRTitagcAPMfXku3q4St7T6+YfnOYnOg/n6+GLta2sR6BuI7/d+DwConq+6extFj4yoPQK50+fGW3+9hRgtE7DmvzIfey/uRctFLXEn4g6iYqJYvs/DFM1aFNObTcfha4cxpu4Y5AvOhxd/ehHROhp5MuRxd/MoER1Kd0Cjpxvh80afP7owitJRmLdvnrubRiZhkE0pXufnOiNjYEZEREcgRsdgStkpmNFshrubRTbkTJ8TC1otePT7S8VecmNrKL6MgRnx2fOfYfv57Zizew4AoNkzzfBhvQ8fW6SG6SKep3OZzjjy1hFUylMJS9ouQXh0OACgf5X+bm4ZWXMn/A6GrR6GvpX6Plp8hqvfeg8G2eQVLt+7jPLflMesnbOQ3i898mRkz42na1miJT5v9DnyZMjDGtkepkPpDqiZvyaGrRmGGw9uAADeq/UeXi7+Mnzgg3299qFewXpubiUlpJRCpqBMiI6JxpqTazCt6TTUKVAH3cp3c3fTyAp/X38sOLAA4zeOx8qOK5EzXU4Uy8bjobdgkE1eIXva7MiZPid6Le+FT458wvJ9KcQ71d7BmYFnkMY/jf2NyWWUUpj6wlS0f7Y9fJScJnyUDxa2Wog9vfagdM7SSBeQzs2tJGsOXjmIoauH4sd9P2JYzWGPTQwnzxLkF4QRtUdg05lN2Hd5H248vIFCmThK5C0YZJNXUEo9ShFZeXHlY3VHybNxgqpnei7Xc/iq6VcIDgp+dFugXyD2XdqHr7Z+5caWkT2lc5bGuPrjsC5sHV6Y/8KjBYTIM71R7g0UzFQQ3f7ohojoCAbZXoRBNnmNolmLYnC1wVBQnPhIZJJNZzah57Kej+ouz9s3D3P3zXVzq8iewdUHP1qRs0iWIm5uDdkS4BuAkbVH4uLdi3gm6zOomrequ5tEJvFzdwOIzPRZo8/wvN/zHMomMsnBKwcxc9dM1C5QGx3LdMTJmydRJmcZdzeL7PBRPjje7zi2nduG7Ok4kc7TdX6uM3Zd2IW+lfuieLbi7m4OmYQ92eR1AnwC3N0EIq/xRrk3UOmpShi8ajBuPbyFUzdPcTg7hcgUlAmNnm7k7maQAX4+fviq6VcMsL0Mg2wiIrLKR/lgatOpuHj3Ivr+1Rfh0eGskU1EZACDbCIisqlynsroVq4b5u+fDwAMsomIDGBONhER2TWhwQSUzlEaPSv2hK/ydXdziIg8HoNsIiKyK3u67OhflSsHEhEZxXQRIiIiIiKTMcgmIiIiIjIZg2wiIiIiIpMxyCYiIiIiMhmDbCIiIiIikzHIJiIiIiIyGYNsIiIiIiKTMcgmIiIiIjIZg2wiIiIiIpMxyCYiIiIiMhmDbCIiIiIikzHIJiIiIiIyGYNsIiIiIiKTMcgmIiIiIjKZoSBbKZVOKeUT+/MzSqmXlFL+zm0aEREREVHKZLQn+z8AQUqpPADWAOgK4HtnNYqIiIiIKCUzGmQrrfV9AK8A+Epr3RJASec1i4iIiIgo5TIcZCulqgHoCGB57G1+zmkSEREREVHKZjTIHgBgOIDftNYhSqnCANY5rVVERERERCmYod5orfW/AP4FgNgJkFe11v2c2TAiIiIiopTKaHWRn5RSGZVS6QAcBHBEKTXEuU0jIiIiIkqZjKaLlNRa3wbwMoC/AOQH0NlZjSIiIiIiSsmMBtn+sXWxXwawVGsdCUA7rVVERERERCmY0SD7GwBhANIB+E8pVQDAbWc1ioiIiIgoJTM68fFLAF/Gu+mUUqqec5pERERERJSyGZ34GKyU+kIptSP263NIrzYRERERESVgNF1kNoA7ANrGft0GMMdZjSIiIiIiSsmMrtr4tNa6Vbzfxyil9jihPUREREREKZ7RnuwHSqmall+UUjUAPHBOk4iIiIiIUjajPdm9AMxVSgXH/n4DQBfnNImIiIiIKGUzWl1kL4DnlFIZY3+/rZQaAGCfE9tGRERERJQiGU0XASDBdezKjwDwjhPaQ0RERESU4jkUZCegTGsFEREREZEXSU6QzWXViYiIiIgSYTMnWyl1B4kH0wpAGqe0iIiIiIgohbMZZGutM7iqIURERERE3iI56SJERERERJQIBtlERERERCZjkE1EREREZDIG2UREREREJmOQTURERERkMgbZREREREQmY5BNRERERGQyBtlERERERCZjkE1EREREZDIG2UREREREJmOQTURERERkMgbZREREREQmY5BNRERERGQyjw+ylVKFlVLfKaUWu7stRERERERGODXIVkrNVkpdVkodSHB7E6XUEaVUqFJqmK3n0Fqf0Fp3c2Y7iYiIiIjM5Ofk5/8ewFQAcy03KKV8AUwD8DyAswC2K6X+AOALYEKCx7+htb7s5DYSEREREZlKaa2d+wJKFQTwp9a6VOzv1QCM1lo3jv19OABorRMG2AmfZ7HWurWN+3sA6AEAOXPmrLBw4UJz/gAH3L17F+nTp3f569LjuB88A/eD5+C+8AzcD56B+8EzeMt+qFev3k6tdcXE7nN2T3Zi8gA4E+/3swCqWNtYKZUVwDgA5ZRSw60F41rrmQBmAkDFihV13bp1TWuwUevXr4c7Xpcex/3gGbgfPAf3hWfgfvAM3A+eITXsB3cE2SqR26x2p2utrwHo5bzmEBERERGZyx3VRc4CyBfv97wAzruhHURERERETuGOIHs7gKJKqUJKqQAA7QH84YZ2EBERERE5hbNL+C0AsBlAMaXUWaVUN611FIC3APwN4BCAn7XWIc5sBxERERGRKzk1J1tr/aqV2/8C8JczX5uIiIiIyF08fsVHIiIiIqKUhkE2EREREZHJGGQTEREREZmMQTYRERERkckYZBMRERERmcyrgmylVHOl1Mxbt265uylERERElIp5VZCttV6mte4RHBzs7qYQERERUSrmVUE2EREREZEnYJBNRERERGQyBtlERERERCZjkE1EREREZDIG2UREREREJmOQTURERERkMgbZREREREQmY5BNRERERGQyBtlERERERCZjkE1EREREZDIG2UREREREJmOQTURERERkMq8KspVSzZVSM2/duuXuphARERFRKuZVQbbWepnWukdwcLC7m0JEREREqZhXBdlERERERJ6AQTYRERERkckYZBMRERERmYxBNhERERGRyRhkExERERGZjEE2EREREZHJGGQTEREREZmMQTYRERERkckYZBMRERERmYxBNhERERGRyRhkExERERGZjEE2EREREZHJGGS72unTwOXL7m4FERERETmRVwXZSqnmSqmZt27dcndTEhcTAxQuDOTMKT8TERERkVfyqiBba71Ma90jODjY3U1J3L//AtHRwIgRgI9X/euJiIiIKB5Geq40dy6QMSPw3nvy++HD7m0PERERETkFg2xXuXcPWLwYaN0aSJMGmDYNKFMG2L7d3S0jIiIiIpMxyHaV06eB/PmB116T3199FcidG2jbFrh5061NIyIiIiJzMch2lRIlgAMHgNq15fcsWYCFC4GzZ4Fu3QCt3ds+IiIiIjINg2xXuHMHuH8fUEq+LKpVA8aPB5YskfQRIiIiIvIKDLJdYcYMSQ25evXJ+wYNAjp2BPLkcX27iMi6zZuBZs2Abdvc3RKy58ED4JdfgN69mX5HRB7Dz90N8HpaAz/8AJQsCWTL9uT9Pj7Ajz8+vn383m4iMi4yEvD1TX6JzJAQoFYtKbm5cyewYweQN685bSRzREUBa9YAP/0E/PabjBiOHAlkyuTulhERAWBPtvPt2SMn7C5d7G/71VeyHfOziRyntcx5KFxYymVGRzv+HA8fyvdnnwWmTgU2bZJUrxYt5Du5V/xjY9euQJMmwNKlMoF8zRoJsgHgyhX3tI+IKB4G2c42dy4QECAnAXvu3AHmzQNmzXJ+u4i8zYoVwJYtElx36QK89JJjj58/HyhYEDh4UH7v1UvmTfz0E3DihFwsk3scOQK8/z5QpAgQFia39eolPdiXLgHffgvUry+jGL/8Ivtx3z53tpiIiOkiThUVJSfo5s2lmog9w4bJqpD9+wNVq0odbXKve/eAU6ck3QeQE3pkJODv//hXUJB720kSZOfPDxw7Bvz+u+wXAAgPB/bvBypWTPxxt24BfftKkF2jBpAu3eP3v/gicPIk0xDc5bvvJKCOiQGef146IwDZV4mpVw/IkAHo3Fny6QMDXddWIqJ42JPtTL6+wF9/AR98YGx7Hx/pyc6cWXq+7951bvvItnv3gLJlgRdeiLutc2cgXz4gVy4ga1ZZwTN+8JaUFAUyx1dfyeJOlpGjli3l9lmzgEqVgDZtgKNHH3/M//4n+3jhQuDDD4H164ECBZ587kyZJFVh8mSpBkTOpzUweDDQvbv0Up87B6xcCZQubftx2bJJz/a+fcDo0S5pKsWjtXye5s+XErVEqRh7sp1JKaBCBccekyOH9H43bCj5oI0aOadtZN/IkUBoKDBnTtxt77wjwVpkZNyXZZTi6lWgenVgyBCpfZ7cyXdk3M2bEgjnyPHkfV26yL6ZOFHSC958U/Zt7tzyu1LAhg2SGmJLZCSwaJEEb4ULS3BOzqMUEBwM9OsHfP454OfA6erFFyU4//RT+dlarzeZS2upmDVpkvxesmRcmtWaNZLuk9hFLHkPrYEbN4yN3qcCjAKc5eZNOZkfPuz4Y+vWlYVrLAE2e0ddb/t26bXs1Qt4/fW425s0kf3ap4+k9QweDLzxhtz34IGUYuzRQ3reEvaaknPs2iUB899/J35/hgzSo3n8uOzPb7+VFVcBYNw4mZxsL8AGpId8yRIZaWrRArh82ay/gOI7cULKJwLAiBHAlCmOBdgWX3whQd2BA+a2jxIXP8Du10+q8nz5pdwXHQ288orkyhcsKMfUOXOAM2fc2GAy1Z490glVqJCM8laoAHzyiaR5pWIMsp1l8WI5mVvyBx1VvLh8X7tWcrOPHzevbWRbZKT0ROfKBXz8sfHH5csn++vbb+WAU6YMMGFCqj/ION2ECRIAV61qe7ucOaViyKFDErgBkq+bMaPx18qdW6pZXLkiQUN4eNLbTU/67z+gcmUZfYiKSl450wwZZNShZ0/z2kfW3b0LrF4tAfbkyUD58kCDBnKfj4+MFk2ZIsHX8uXSOTF9utx/7x4wahSwbBlw8aLb/oRUz5FzVVQUsG6d7DtA5sRMmwaUKiX70t8f+PXXuBHd336T+U2pDNNFnGXuXAmUrU22MiptWjno1Kghb+Jy5cxpH9nWvr3kfgYHO/Y4pSRAb9pUTjbbtzNtxJkOH5YD+fDhxvdVkSLJe80KFYDvv5fe8LVrH8/Zp6T77jtZTKZwYQm2ktJ7nZBl0uOff8rPzz+f/Oekx2ktPdUZMgAbN8r3hBdHSkmnQ5kyclyMiZEqPhkyyP2HDgFjx8YFeXnyyDyK996T7+QcWssxtEQJ+b1gQfncFSokn8NChYCaNaU0KgBERMgx79dfZXL51atSzad1a/ns9u0b12kxerSM7gJS/rRDBymRWqWKzJlp08bFf6x7eNXZXynVXCk189atW+5tyIkTctX+2mvJX1imalU5cAUEAHXqyJUjOZe/vxzcmzdP+nPkzi0HnwUL5Pdjx4B334276idzfPqpVHbp39+1r9u2rZycGGAnX3S0pBl07y6VQbZsAYoWNe/5o6LkIqxLF+DaNfOel+Imp7ZuLSOAGTMaO+f5+EiPpyU/u2JF4PZtOW9OmiQpkwcPyr4DgFWrZORo7VquI2GWu3elo6B8eZl7pLV8RqpWlaB42TIpm/nrr7J9eLh0+r3wgkxsbdhQznGWY2CmTE+OCqZJI9/TppXc/I8/lkB90CAgf34UtYwoejGv6snWWi8DsKxixYpvurUhP/4oB5qOHc15vhIlZBJk48aSE7x1KyddOUNMjFxtd+okk6XMYOlJW7EC+OwzSSNauRJ45hlznj81u35dJgn36JH4hEdnswSC//wjJ6jGjV3fBm+gFHD6NPD225JHbUYPdnx+fjKyWLmy9LQtXGju86dWlgD7iy+kdzq5+y1dOuk1rVnzyfsuXZJUot9+k/Nh375S6cmRVC+Kc+SIXLQcPizzUgoXls/hRx89vt29exIUAxJkDxki81caNXK8bG3hwsDQofJ17BiwahWOFy6MPOb8RR7Lq3qyPUZgoAyF5M9v3nPmzStX+aNHs362s8yaJdUjnLFaXL9+UgP91i1ZqY6TWZMvSxZg717ppXSXmBjp7WnbNm6yHhmjtfRU+vjIiM+XX5ofYFuUKyfHzkWLGGSbIWGAPXly8kdtbenUScoB/vADkD498NZbknbAXm3HLVkiKTiXL0sHwbBh1lMa06WTid6AXNBMmCCLfCV3XYiiRYE+fRATFCQpJDduJO/5PBiDbGcYOlQO5kkREyOljrp1kxrb8WXJIgGFj48sjvHJJzzImOXcOUnnqF//8WoiZqpdW05GmzbFTfihpLG874sVk9Qcd/HxkZNWjhwyyevPP93XlpRmzRrZf4cOOS+4jm/oUAnM+vThsuvJNWqU6wJsi6AgScHctk1Gcz/5RF43MlIucn/9NS69hKzbuFFGA3btipuY6iYqKkpShfr1c2s7nIlBttlCQ5NWTeLcORm2KVJEcp3mzJErRmu9LnPmyBVoz548sCSX1jL8GBEBzJzp/B6ZJk1k0RNeICXdBx9IHqgnjAjkyyeL2pQsCbz88uN11cm6sWOlF6tQIde8niVt5PPPZcEaSrrmzaXDx1UBdkKVK8v5EZAOp23b5Hjw1FMyaX3GDJbYjO/SJRn1A+Ti5L//5LjlZtrPTxYN+/FHaZMXYpBtIp+ICBmGGTDA2AOiooA//pADVv78UhO2UCHJM710SSqKdOgAzJ795GPHjJHJebNmSQ4bazIn3X//SVm2Dz8Enn7aua+lFPDzz5Kb7Y6Tkze4dUtWd1RKVlX1BDlyyKTk+vWlfCPZtmGDpE8NGZL8oWdHPPOMpGspJWXkWBrVMZaUqEqVgPHjPeMY9swzsh+XLpV5ERs3SqULy77dsUM6T44dS50dG5s3y+TGNm2kU8LfP26ukCcYPlwmwPbtK6MSXoZBtomybt4si9DYmzR3/LgEyPnzy6IWO3bETQZYs0Zm/GbPLpPlGjeW1BFLUX8LpaTne+FCCbDLlpWDCzmudm0pRzRwoGtez1Li6vRpmTVPjvn6a6lE4M5c7MRkyCDpIpbV7s6dY410a8aNk2Ncjx7uef2ICAnEypaVTozUGHw5KjQUqFVLOgg8ja+v9GzPmycL3Bw9Glc+9/ffZcT3mWek97ZzZwTv3+/W5rrMDz9IVbKgIKkE4imdEvGlTSsjIgcOSJ1tL8Mg20Q5//lH8kNt5TkNHy4pIZ98IgeBpUvloDB+/JP1e9OmlQNEy5ZSomz8+Cefr107eXN27Rp3UOEJw7jr1yXgbdHCNXmh8fXsKfuPiy8Yd/++5II2aSK9M54mIEDytG/ckPzfTp3iZueT2L1bVuccNEiOce4QECCdEhUrSifGK69IzV+ybswY+b8lVv3DkyglE+v8/eX3jz6SKhpff/1ovYmSY8Z4Za/pY6KipOOocmXpyHvuOXe3yLoWLaQU4F9/eV38wiDbLFeuIMvWrXJStXW1+OOPUgP09GlJFXnpJdvBXWCgpBd06iRVDN5778k34VNPyRVgUJCsMFmxoqSceNmb1XRr18owlbtGACZPlqDx7bfd8/op0ezZMmnN03qxE8qUSSbzLFgANGuW9JVfvdFzz8lk0d693duO/Pll5HDiRDm5ly7NOtrWHDwIzJ8vx6pcudzdGscoJRNse/WSggTbtmHnN9/EBeHeasMGudh/5524CiGeSimJWVau9IwUJBMxyDbLL7/AJzpaZj9bExEhQ8i1a8uKVkb5+cmwT8+eUkKnf3/rw9C3b0tg3rGj9JLypJG4Bw9kqDpnTlnBzx2KFZOyYosXS9BB9rVtK5VZatVK+nPcuwd8+62k6jjrQlQpqVbz/feSq12vnvGJWOfOyYRAb+XjI6NznlDj2MdHetS3b5eLoqxZ5Xam+Txu1Cgpnffuu+5uSfIVLoyIrFnjSkh6q+rV41JOU4JMmeTzeOWKjM57CQbZZnnzTeyZOFFWsbLm7Fn5YBcs6Pjz+/jIcNc778ikr+7dE6+skCePXMFOmCCpJqVKyQQfetzEiZIbP2tW3KpUSRURIZNLklIWbNAgqeHbp49X1wo1TY4c0gOalN6OqCgJrosWBd58UxZUePZZ+VzdvWt+WwFZQW3pUukJHDZMbjtxQkaxpk6ViX/t2j2+cuSAAVIL//Zt57TJnXr1kkWZHHXmjHPTOcqUiRsd2bVLPpO7djnv9VKS69flQnHgwLiLkBTOJyJCRpQTS8H0FoGBklaXLp27W2Kc1nJcbt/ea9J5GGSbxd8fN+31iIaFyfekBNmABBYTJ0qvwpw50lud2BvR11dO6Nu3y+SiTz9l6khCmzfLpKd69ZL2+GvXJPWnXTv5H1evLqknb78dt5+N8PcHvvtOctKsLQhAckHZsaNUpHCU1hLUlikjwXWBApIqNHeu5AT36SOLPQ0aJAGw2Zo1kwo2kyfL71Onyv5++225YN69Wz7Hll61F1+USWbeVjv28GGp8nD9uvHHXLkiI04FCsjnrGhRGS2cPl3+b87oibx/Xz7fVapIxYORIx+vaz9jhlSCev/9uK/58733GJsli3RIDB7s7paYJiYgQP6uSZOkWIG3CQmR92VKK2OolMQ3ISFynPQGWmuv+6pQoYJ2h3Xr1tne4LvvtAa0PnEi+S/22WfyXM2ba/3ggfXtHj7U+uJF+fnKFa2PH0/+a3s4u/tBa61LlND6lVeMP2lMjNaHDmn96ada16qltY+P/P9z5tS6WzetFyzQumtXrf39tfb11bpjR6337k3y3+ANDO0HoxYvlv/3woWOPW7LFtlfgNbPPKP1r7/KvrSIidF60yatX31Vaz8/rZXS+qWXtF616vHtzHTsmNbbtsnnMjo68W0++CBpf68Vpu6LpHrtNa3TpNH68mX720ZEaD15stbBwbJf+vfX+pNPtH75ZfnMSUirddq0Wtepo/XQoVr//nvcsS65rl2T94SPj7wnypWLu69KFfmM+/rGvWeaNIm738b7xiP2gyOuXLH+HrXl1i2tDxzQ+n//03rFCnkfz5wp560RI7Tu10/rLl20btdO6+nTtb50yfSm27Ju3Tqtd+2S99Do0S59bZf44AN57xr5rLlRop+HmBitX3hB6wwZtD5/3uVtSgoAO7SVeNTtAbEzvjw2yLa88SMizHnB6dNlF/bqZWz7Nm20zpRJ67/+Muf1PZShE9mJE1ofPWp/uyNHtB44UOsiReJO7M89JyeKrVufPAGdOaP1O+9onT69bPvCC1r/+6+xgG33bgnw7tyxv20KYGpA8eqrWufOrXVUlLHtjx7VunVr2Qc5cshnxd7n7tw5+Yxmzy6PK1lS66+/1jo8PPntd1RkpNZVq0qQGRaW7Kdze3B3/LgEpQMH2t921Sr53wNaN2qk9cGDj98fE6P1yZNyYduvn9aVK8vFreXz2batXMi4SkyM1jduyM8nTmhdvrzWv/2W6Gfe7fvBUQ0bal2vnmOP2bZN3reW/ZHwSym5P18++QLkvdGokdazZ8f9L53o0X54+WVpiwte06VKl9a6du2kPz46Wt7Lf/yh9bhxcvwtXVouamvU0HrCBK337Ut2R4TVz8OxY1oHBEhnVQrAINtF7B5AO3fWOn9+c1/03XdlNy5aZH/b48clQFRK6zFjktZDkQKYeiIrXlw+7E2aaD1tmtanThl73LVrWn/0UVzAVrWqnHht/c83bJBt+/d3rI23bmm9bp300s6aJT1+Q4fKQVBrrTdu1HrsWMee0wSm7ofq1Y2d7C9f1rpvX+lhTJdO61GjtL5927HXevhQ6x9+0LpCBdkfZcpovWdPkpqdLMePa920qfH3nA1uD+7efFPrwEC5kLHmxAmtW7aU/3nhwtIzbfQkfv++9JoOHy6BgJ+fvA9c3EOqN22SERNA64oVpRc33t/g9v3giPXr5e/44gvjj9m7V+vMmbUuVEguglaulP9JSIh0QNy+/fgxMCZGHvPee7LPATnevvSS1j/95LQOh0f7Yfduec1x45zyOm4RGpq0/TZpkozKVq4sx874F0YFCmjdrJnWffrIqI7l9nz5pJNv2TKt791zuKk2Pw8ffCAjHZGRDj+vqzHIdhG7B9BateTLTBERWlerJkMroaH2t793T4J9QOsXX/S+K3htYD+cOKH155/bH4o6c8bxg1VC9+5pPXWq1gULynOVKCEBsTV9+8pF0KZNcbc9fCi/z5mj9bBh0vtSooScxLSWHvWEvUX+/lr/8ovcv2SJ3DZ3btL/jiQwNaDIm1fSDeypXVt6xXr10vrCheS9ZkyM9OTkyiX/z7FjU8QBPzFuD+62bNH6m28Sv+/uXRkZCgyUAHncONspcPZcuCD739dXRpRGj3bt6FBkpHxWLZ/5unUfjcC4fT8YFRMj56qnnpILGCOOHJFRozx5kpYSGRMjveDvvCPPAUh6Udu2csFlYqfQY/thyRJ5D3qLzz/XDqWl7tkjF6WAdArVry8jRDNnar15s3TiJHT2rNzfokVcQB4UJCO3U6caHn2z+XlIQZ2ADLJdxO4BNH9+CXDNFhYmvQcVKkhAZk9MjHwQnn7a43O2ksLufli4UN76+/fb3u7HH2W7XbuS36jISOmZKVJEguj33088feH2bXmf5Mun9bx5ctu5c48HzyVKSKC9cmXcY9aulYPl6dNywojfAxgZKcFnunSSV+4ipgUUMTHS/s8/t73dgwdysnj3XXNe1+LqVa3bt5f/f6VKT6YvONuVK3Iy27IlyU/hscHdP//IBRSgdYcOcmFrliNHtG7VSj9KGZo2zbxUPSPCwyXdaOTIRzet//tv171+cvz9t/zfpk83tv3Jk7Ifs2c35xgTHa31f/9Jz2mOHPrRaOCOHcl/bu3BnwczjBolKR1GREZKelOOHElPS3v4UN4v/fpJTGE5VzVrpvXq1cmfoxASIgG9BwfdDLJdxOYbJiJC8rE/+MA5L/7777I7+/Uz/hhLQB4R4VV52nY/uB9/LP8re2kE3btLDrvRPGAj7tyRCZKWk0ZivQ2rV0svmCXFIyZG6z//lDy1pPaknjsnJ8BSpZI0rJcULj+Rbdsm/9fFi53z/D//rHXWrNLjOnGiue8LW27ckOHawoUdT32J5bag4sIFrXv2tB48Fy0qJ+YNG5zXhs2b5SINkIvcn3923qRWWxYu1Pdz5ZJeQE/Xrp2854zMRzh/XvZhpkzOSauyjAzkyCEdFD17yoVvMjzxeVi3Tjqprl9P1vN6DKPvb8u50DLqacbrHj4sgb4lVbJMGcm1T6QD0NBxqW1b/WiOzIIFrjvuOoBBtovYfMOcOCH/7u++c14DBgyQ1/jtN8ce9+WXcQG6K3t6nMTuB7dnTwmW7ClSRHIDnWHBAq0zZpQvS9qHs61cKft52DCXvJzLA7uvv5a/7+RJ573GxYvyngC0rlnTWIqWGTZskIv0119P0sPdFmQPGSLtTmwi4v37EjSNGuX8dlguVEuVkn1XubJclLnS/v06Mk0aydU2moLhLpGRxiaGX7kiwU/69HIx40w3b8rEWV9fGbmdPj3JAdcTn4e9e+V94axOMFdxJM3q8GHpMHCkypajbfnuu7jPXI4cMhcs3jwJQ8elqCgZfX72WXmeYsUcj3GcjEG2i9h8w6xdK//uNWuc14DwcDmAZ8rkWKAREREXoNerl2LzTi3sfnAbN5b/ky1m5GPbc+KE5NMDEjy5Im90wQKX5eGbFtj9+qv0hpw+bXu7bt20zpLF+b2UMTEyMTI4WHKIp093Tc+opayfkUnOCbglyL56VVKUrFUIsEw6S8Lfk2RRUdIrmju3BPh9+rh0Xsq+cePkddu3d09vuj3R0cbzk2/elFSDoCDb80zMduCAnKcArcuWlYndDkr089CqlXR6XLuW/Da6y4svSllfe6KjpZMgc+bkz12xJyZGKgY1bSr7LDBQjtUHDjh2XIqOlh730qUl3VVriV08oGOQQbaL2HzDzJ4t/25n16k+flwOFFWqOP7mmzlT2vjpp85pm4vY/eAWKybl3WyZN0/+F7t3m9WsxEVGyqQvpWTofOdO576excOHTh+2Ni2wmzBBG0rvKVtWyoC5yunTWj//vLStYUP7FwHJFREhn+uSJR3uwXNLkG25KAgJSfx+y5yHAwdc2y6tZTJXv37Sy54zp8yXcEHQu27durghejdU/LFr0SLpcTx82PZ2d+9K3q+/v9bLl7umbfHFxEhbLfn8r73mULCY6OfB0ps9YoR57XSlO3ckgB0wwP62U6fK3/r9985vV3yHDsmk5DRptAb01cqVHT/HRkfHdQR+842k0X37rXtKrcZKNUE2gOYAZhYpUsS0f54jbJ7IRo6UQMoVb4RffpFdO3iwY4+LiZEJdTlyuCxv1xnsBhQPHtjP6evWTa7yXTXZYt06mVHv7y/5vs5+3caNpXfYicPWpgV2ffrIvrDFMulx+HBzXtOomBhJU0mXTnq2f/zRucHaqVMyRO8glwfZN2/K/6NVK+vbvPee7DM3nhz1jh0yqgVo3aCBTJZ0onXr1sn7o3Nnz0tNiIyUDgh7F3EPHshFpY+Pebm8SXXnjnzmAwKkwtbEiYYm/1v9PLRqJc+TEnuzLef99ettbxcWJuk9jRu7bzTl6lWtx43TERkzSlz02mtJ66RYvTru81uokNvWmEg1QbblyyN7srt0katuV+nTR3bvn3869rjz502py+tOpgQUTz8tFR1c6epVucgB5ADozAP98uXyOj17Ou0lTAvsXnxR6rvbYilj+Ouv5rymo0JDpZY3IKMkyZyYZVdkpCxyZJDLg+zLl+W9ZasyT4sWUinH3aKipPJIxowSrI0cmbwSgjY82g8Ja0V7gh9+0HYnDkdESDqCO3pBbTl6NC4doWBBrefPt9lRYfXzEBIiPeQeXMnCqo4dZa6RrXTPmBgZ7Uuf3pRFrpJrw7JlUg0qMFDSjoYNkwt0R8TESOGGeFV8XI1BtovYPJHVqSM5UK7y4IEMn2fNmrSyWDExKXYJdpv74dAhGU6zlbN++rR8NCZNMrllBlh6RgMCZFELZ06ssyxkZNLS3QmZFtiVKWM/z3DaNPlb3HniiIqS1BZ/f6mt7cyKPSNHygQwg2X9PLJkWZEi9tO2XOnCBSkjaKlC4oRye0/sh82bpSykqxfNSSgiQnoCy5WzHWBaOm+mTXNd2xzx999yQQ5IvriVOVAe+XlIjogIGTmyNzF6zhz531hymt3s0X4IC9O6UydpW7ZsWn/1lUfkWhtlK8j2AblGWBhQsKDrXi8oCFi0CAgPB159FYiKcuzxw4cDFSsCly45p33usns3MHkycO+e9W3+/Ve+163rihY9TimgVy9g9Wrg6lWgalXgf/9zzmuNHQtUrw68+SZw7JhzXsMMVarY3xc7dwJZswL587ukSYny9QWGDQO2bQOyZQOaNpV9efeu+a81cCCQJw/w+uvyGfck4eHApk222/XgAXDiBFCypOvaZU+uXMD8+cCqVfI5bNxYjp1XrzrvNf39gQMHgFdece9+/PNP4ORJ4KOPAB8bYcGSJUDbtkCfPq5rmyMaNQJ27QLmzgWuXAEaNJDP4f79xp9Da2DCBODTT53XTrPFxMh5rWdP69tcvCjHjZo1gd69XdY0QwoUAObNk+N4mTLA228Dzz4r7zet3d26ZGGQ7QpRUcDZs64NsgHgmWeAb74BNm4ERo1y7LGvvy6B6IABzmiZ+4SFyXdb+2LdOiBzZvmwu0utWsCWLUCmTHKiWLjQ/Nfw95fnLV9eDtKeauZM4J13bG+zc6dcFCrlmjbZUrYssGMHMGSItL1sWQk6zZQpk3y2Dx8Gxo0z97mTa9s2oEYN4O+/rW9z5Ii855591nXtMqphQ2DfPmD0aODXX4FSpSQIdYYKFYAffpAL6d693RdQvPyyvEebNrW+za1bEqiVL++yZiWJjw/QuTNw9Cjw2WfA5s3Ac88Bb7wh52F7lAL27JELjmvXnN5cUwQGyjm7alXr2/TtKxe3335r+0LKncqXlw6m5cuBgACgVSu5KNi+3d0tSzIP/U97mbNngehouVpztQ4dgO7dgfHjga+/Nv644sWBESMkCHPWCcYdwsKA7NmBdOmsb7N+PVCnjvsPREWLSqBdqZL0qI0bZ/5JOF8++XuLFTP3ec1i5O998EB6AytUcH57jAoMlJ6wf/+Vz36tWsB77wEREea9RpMmQKdO0uvmSE+ds23cKN+rV7e+zcGD8t0Tg2xARgJHjZKTe44cQPPmchy9fdv812rTRl5rzhxg0iTzn98IpYBq1WxfpB45It899ViRUFAQMHgwcPy4XKTPny/H1OHD4WtvdOmDD6STqVMnGXHxZFrLxfz589a3WbxYeoXHjPH8/aeUXOzt2QPMmiX//+rVpac+BfZqM8h2hVOn5Lure7ItvvpKThJ9+jgWqA0dKifB3r2BO3ec20ZXOXnS9n44fVo+1O5IFUlM1qxyZd+xo1z0vPGGuYGaxf370vvzyy/mP3dy/P03kCWLpPlYs2+fBLIVK7quXUbVqiXt69pVguHKlaXX3SyTJslrOJoO5kwbNwIlSkjKjDUhIYCfnwQ9nuy55yTQHjZMguAyZeSi1GwjRwKtW8v/ztWBxKxZcgERGWl7O0uQXby489tkpixZgIkTpf2tWwMff4xK3bvHXeglplQp4PPPgf/+k7/XkQ4qV9u5U9JEVq9O/P7r16UXu0IFYNAg17YtOfz85H156BDQrJmkurRrl+JiEQbZrmAkRcGZgoJk2LNzZwnUBg0ylh4QEBA3tHT8uPPb6Qp37gCFClm/35352NYEBkq+2qhRwPffSw/mjRvmvoa/PxAaCnTr5ln52adPy99qK2DbsUO+e1JPdnwZMsjn6I8/gMuXJdAeMkQubJIrWzZg7VqgXLnkP5cZYmIk9aFmTdvbhYRIgB0Q4Jp2JUdgoFwgbdggJ/569eSE/+CBea/h4yOf8cWLXZ/yNHu25DH7+9ve7vBhmXdQuLBr2mW2ggXlf7x5M1RkpPSO2rpgGjhQjoWvvx6XInPzprn73Qy//y77pVmzxO8fOFAC7e++k/dvSpMpE/Dbb8Ann0gcU6mS7QskD8Mg2xXCwuTAmS+f+9rg7y8BWr9+0vvVrZux3q+qVeVAU7ass1voGps3Az/9ZP3+9eslH7t0aZc1yRClJEd07lzp7ape3dxhTH9/mSjr7y/D155yIjlzRk4guXNb32bnTkkBcufny4jmzeXk0L279KyVLg2sWWPOc9++DfTvH3dB7y4hIZK7W6uW7e0OHvSsSY9GVK8O7N0rI4KTJ0vgZbnAM0NQkATbR45Iz7krerTPnJGUtNat7W975Ajw9NMp48LIlqpVsWvaNOCpp2Si5I8/Wt/2qackFaNKFfn93Xcl3WLuXBk98wS//QbUri2jngmtWCFtHTZMRmVSKqXkf79mjVzoVK4MLFjg7lYZwiDbFcLC5MMaGOjedvj4yMlhzBgJuNu0AR4+tP+4gABJUZg61TmpCq7m62v9Pk/Jx7amc2epfnDpklwAbd5s3nPnzy89PXv3SsDmCU6flioatnpgduyQXmxPmPRoj2XC4vr18j5s2FBSgK5fT97z3rwpPZK9erk3b/GZZ2Q06IUXrG/z8KGMjHlqPrYt6dIB06ZJGtOdO/IZHDXKfqqFI/79V3rtXBFELFki340E2YcPe34+r0HhuXLJiEuNGnJMNZpG2aEDkDMn0KWLHHP++cf5jbXl6FG5YG3ZMvH7R4+WfTZihEub5TR168qoS7lysi/69fP4mMRDIwkv4+ryfbYoJfl/X30lw0xNmxrLcfrvPymr88knTm+i0+zdKyeTw4cTv9+Sj12vnmvb5ag6dSS4zphR2mpm5ZGmTaV84y+/AOfOmfe8SXX6tO2yfA8eyEnGU1NFrKlTR96Pw4dLT1PJkvI/T2qAnD+/pDT8/bftnjlnCwyUXjVb6T2eXFnEqEaNZLLpq68CH34oPfe2Jp45ols3mV8waJBzJlrGt3ix5Jk/84zt7aKjZUQzpeVj25I5M7ByZdx8lx497F8s1a0LbN0qF0C3b0uZR3eW+tu6VTqEWrR48j6t5djYuLH7O/jM9NRTkiL3zjsSx9SpY6xqjJswyHaFsDD3VBax5a235GT8339A/fr2a8E2bAi0by+1la0FqZ4uJERyuqwFMpb8PE/Kx7amWLHHK498+KF5PZgffiiT9fLkMef5kuOFF6QurzV793rupEd70qSRqj87dwJ588rf+fLLST9h9O4tFSIGDJDcb3cYN85+CkVIiHxPaekiCWXOLCM/P/8s1W0qVpSgJ7l8fYHp02W0avTo5D+fNTEx0iPYo4f9bcPCpMfQS3qyH7HMd3n/fZk30by5/U4nHx85Fx46JKmX7dq5pq2J6dxZPuuJdURcviw1+osUcX27nM3fXyam/vKLfPbKlbM+8dPNGGQ7m7tqZBvRsaP0Zh84ID0xZ87Y3n7KFCB9elm8xJPrKltz8qR8t3bBs369zEQvVcplTUqWbNnkwNK5swxZd+5sLP3HHj8/yW+2lIZyxmIqRr37roygWOPpkx6NeO45uWCaOFFSgUqWlNrJjvL1lUDh7l35v7na6dPSI2gvhSkkRNpqr/c0pWjTRv7moCDpVZs7N/nPWamSHGe//NJ55Rl9fOT5+/a1v21KrSxihFLSeTRrlhxPa9UyNooXGCgXtAUKyCRmd3U+JZaLDchEdsA7g2yL1q3lHJAzp4wuffaZu1v0BAbZznb+vATanhhkA8CLL8oQ8/nzUhHg6FHr2+bIIVePGzd6Xqk3I8LC5MOYNm3i93t6PnZiAgMlIBs7VurANmwoK52ZYc8e6R11V55vZKT9AH/nTnlf5s3rmjY5i5+fpAdY6n2//rr0ZjqqZEmZb+Ho4lNmsKxMaq+yyMGDKaeyiFGlS8siPNWrS77uoEHJL6s4fryUUXXWuWP/fuOdJZYA0tt6suPr3l3WhDh+XHLtHbm4adFCvlyZHzxnjlSaunUr8ftTQ5ANyHty61YZ0c2c2d2teUIKiiZSKHeX7zOidm0JMB88kKt4W4F2ly5SKsgy2/p//5MUDDPKkTmbrdz4U6ekpzslpIokpJQMdy5aJEFnlSrmlDgqV06Gq+fPl14eV9u9W8rf/fWX9W1S0qRHIwoXlove5s2lhzEp9XlffVXKVGrt2pP+xo0y0mWvMk9ISMrOx7YmWzbZd2+9BXzxhRwnk1NqM2tWSb/JkMG8NlpcvCgjKEZ7/o4ckfbYyrX3Bk2aSKnGmBiZFGm0+s/AgXLe/PJL57Yvvl9+kTz5jBkTv//4cRkx8rRUVWdIl07SX7t3d3dLnsAg29lSQpANSED1339yYm7YUIZ+E6OU1Pu1/D0zZsiQTY4ccnJfssRzyr8llCGD9TJGKSkf25q2beXvuH9fetRWrUr+c77/vkyc6dfP9oIwzmB5D1rLDb9/Xy4mUmI+ti0BATIhzbKAVFIC7eho6Vmztxy9mTZulJxwW5VgUnJlESP8/WUy1qxZwLp1Umrs0KHkPefWrUCDBuZOgvztNznWv/iise29qLKIXWXLSvpW/vwyEdxSgcWWpk3lourDD+UCxtlu35YLgJdftt7BEBoqAbY3jRjZ4qEdLQyync0SZNuqkOApiheXnpjbt4Hnn7c+eSp+OsWcOZLH1qmTfG/VSnrGPdGSJVI+LTHr10tPTUrJx7amShU5KefPL5MGZ8xI3vNZFsnIlk0m+7hyZUFLkG3ts7Nnj/Q4peR8bGsCAqSnyhJoO7ofLYuGTJ8el8bhTA8eyNwTe6kilsoiKX3Soz3du0uQffu2fCb//DPpz+XjI89l5iTIX36R473R/XDkiHfmY1uTL590OpUvLzn3339v/zGTJslF5PDhTm8eVq6UUSprpfsACbK9PVUkBWCQ7WynTslCGimlhE65csDy5TIJsnFjqb9ri5+f9LLMmAFcuCC9pyNHyn03b0o5qmvXnN3q5EuJ+djWFCgggVWTJpJTPXBg8hZOyJ5dTsozZrh2xbDTpyX9IFOmxO+3LE/ujUE2IMeMX36R3sbevR0PtMeOlQuUN9+EcnbaSJo0MhdgyBDb21kqi3hrT3Z8NWpIOlPRosBLL0mJxaTMbahUSSqAmDUJ8vJlqcXdurWx3r+bN6XSSWrpybbIkkXOZ/XrA127yhoTthQtKhMhLZVYnEVrGSnJkUNGjqwJDZXFg8itvCCi8HCeVCPbqBo1ZDgxJESGwO7dM/Y4Pz9JNWneXH7fs0fyeevUMa+GbFJt2yaTWfbuffK+sDD5SsmpIgllyAAsXSqLykyeDLzySvLSeKpVi6sf7qr62ZYa2dYCAcusck8oNegsgYGSOmIJtK2NxCQmfXrZ/tAhFExKtRJH+fhIsG3LwYPeVVnEnnz5JMe3XTvgvffwzBdfJC3QHjcOCA6WfO/kTkJeulRGE4wsQAN4d2URe9Knl1GIV16RzoqRI23//8eOlRrOzkzR0FpSwcaNs76w2vXrMh+APdluxyDb2VJikA1IL/ZPP0lu2iuvAOHhjj9H3bqyrOupUxK4Hz9uejMNO3JE0iiCgp68799/5bs3BdmAHIAnT5aVOpctkxJH9kYm7Fm4UHpHXJGf3a6d9AxZs3Ond016tMYSaDdrJpVeHAm0GzcG3ngDOVetcm4pxq5djS3KERLifZVF7EmbVo6lQ4fiqT//TFraR9aswMcfSwrD0qXJa0+XLtJDW6aMse1TQ2URWwIDZVJ5167ARx9Jx4W1qiwBAXI8On9e9pUz+PjIxZatSX6ppbJICsAg25mio6U3LiUG2YD0dMyaJUvHduyYtHzcevXkyv7OHcnXPHDA/HYaYcmNT2ymtSUf21uHsPv2leB461YZVbhwIenP1bixfJ83z5y22dKundQKTsy9ezKhzNsmPVoTGChVfCyB9syZxh87eTJ2fPut9Mo5Q3i4rIB36ZL9bb21sog9SgETJuDCCy/I5LikzJXo1k1GBi0jhUkVECAjjkYvTo8ckVHKwoWT97opmZ+f1KAfOFAmtr7+uu3VIV97TSaim71i5zffAN99Z380w9KhxSDb7RhkO5On18g24o03ZELHr78mfRGaSpXkqr5wYRnydIewMMmNT6wne90678nHtqZtWymFd/y4jCpYejoclTmzpN04q5fGIjJSetCsLa7jzZMerYkfaPfsaTzQzpABURkzyv80ORPwrNm5UwJte5MeLZVFvH3SozVK4eigQZL606ePsaoV8fn4AB06yAhVUkYWAUkDHDHCsUWrDh+W0St//6S9prfw8ZF1IsaOlU6G1q2t/x8nTJCLzrFjzXv9CxeAwYNlJMPeBVJoqGyTmi+MPIQXRxUewFbvaUoyYIAsbvH991ISLCk5gSVLSomvfPmkh9/V5eCspe2EhUk6iyXf2Js1bBhX8aBmzaTvgzp15LHWFkEwQ1gYUKKELFmdGMukx9TSk21hCbSbNpVAe84c44+dOlV6QVesMLdNGzfK9xo1bG9nqSySGnuyY2lfX0k9qFJFAuYNGxx/ko0b5ViWlEmQM2dK6oojE/FTW2URWyxrEkydKqVsmzZNfBn2SpXiJkvaWnfCEe+9JxdXn39uf9vQUFmgK7FOJXIpBtnOdOqUfE/JPdkWo0ZJsD1ligx3JoXl6vvTT+Uk48pVI4sVSzzn2hvqYzuiUiU5SQcEyN9syUd3RO3aEixt2mR68x6xlO/Lly/x+3fsAHLlAp56ynlt8FSBgdIL+vzzEmhbglx7eveWALdbN5kYZZaNG2UiY44ctrezLJCUioNsAJKjvWyZnBdeesnxFLoSJWRUom9fxzo8btyQMqtt2hhPFYmKkgVPUms+tjV9+8riJ//9J9VHEqugNWGCTAQeODD5r7d9u3RyDRggcxrsYfk+j8Eg25lSUo1se5SSK+iuXWXizqRJSX+u3r1lkYb27SXPzRWmT5dlihNav15qQKemIezixSVAzpNHcqx//92xx1erBsye7dxUDXs1si2THlMry2SsggVlYrK1xaPiCwqSYe4rVyRdwSyFChmrVBESIqkORoIEb2dZHTJNGim1aWT/WVgmQW7YIAGc0UD7jz8kaDZaVQSQc1hkJHuyE9Oxo6Tf7NsnOdgJ90POnHKuzJEj6ek9gDxvv37yfCNGGHsMy/d5DK8KspVSzZVSM285cxjbEWFh0ttmr6xVSuHjI8ONrVtL2khSA+1MmWQyZePGkudtdGlfZ/Cm+tiOyJtXTtJly8oCQt99Z/yxadPKxZa9nsvkOHNGvufN++R9d++mrkmP1mTOLIFTeLis/Hb/vv3HlCsnJ/5Fi2QyrBmmTJFyYvZYKouklDUDnK1AAVlU5M4dCbQdGV3o1i1uZLFXL2NzZX75RV7Tkc9Naq8sYk/z5nL++usvYNq0J+8fMEBSupLznlcK+OADWfnV2hLq8d2+LbXQ2ZPtEbwqstBaL9Na9wh21+S6hFJq+T5b/Pwkp69VKwm0J05M2vOkTSs9qO3ayQFk2zZTm/mYDRskrSDha5w8KSk9qSVVJKGsWWVp3uefl3JQn3xivFfswgWZ6W4ksEuK06flAjWxk9OePdLO1NyTbVG8uHwe9+yRScpG9t/QoVLGzYwe5fv3jb9nDh5MXSNGRpQpIxPZjh+XCZFGP09KAV98IXm6WttP/9BaJp2/9ppjJS8tNbIZZFv39tuyuu7gwXGLLVlY/te7d8uFbVI1bWp7dcf4WFnEo3hVkO1xvDHIBmSW+YIFUrFiyBAJzpIiIEBKUp06JekjznLypASFmTM/frslHzs1THq0Jl066Q199VVg2DCpA2vEnj3Sg7Z5s3Pa1bWrBBGJ8faVHh3VrJmkQi1aJGkE9vj5SX6nGf+/3r2ld9yehw9lCDu152Mnpm5dOQ5u2SKfQ6OlUpWSEYRvvpGfz561vtKgUvIajs6nOXxYUluyZnXscamJUtJbHRws+y+xiiOjR0tHhqOdSWPHSieUI7n3DLI9CoNsZ4mJkd64lF5ZxBp/fzloW4KzxPKdjfD1lVwzIPFZ2mawlhufGvOxExMQIJN4XntNJrj+8Yf9x9SoISk2zirlV6OGvLcSs2OHlGNMjZMerRk6VP5f778vk+qMCA+XiZNff530192wwVju59Gjqb6yiE2tW8uy6X/8IRcujgRVSknd+Jo1ZYQxsSDv8uWktYuVRYzJmVMC7f375XyY0KRJEoRXqwa8+66x1XdPnJAg++RJx0YfLOVZmZPtERhkO8uFCzJhxBt7si38/IC5c2UCyPvvG+8FTUynTjLk5gxhYRKQxU890FqC7Lp1vX/FQCN8fKRHrEIFoHNnqShgS8aM0oOZlOok9mgtK9JdvJj4/al90mNilJJJxOXKyefx0CH7jwkIkFGkwYPt7+/EnDsnAYC9+thA3DB6ar+gteWttyT949tvJdfaEenSSXD355+SJ3zvXtx9t29LB4ORFTkTOnyYqSJGNW0qqSNTpkiufXyFC8tnoFs3yeEuW1aqvdgyZIh0QhkZnYovNFRS7Zy1+BQ5hEG2s1h6T705yAYk0P7hB+kFHTlShsWSUke7cmXgf/9zTvrByZNP7oewMBlpSK352IkJCpIazH5+UrEi/ok6MbVryxB3cmbOJ+b6dVkCPrGJeXfuyIk/tU96TIxlnkPatFIazt5JXCmZ8BoYKJ9fR1d0/d//5LvRINvXV0r9kXVjx0pu9vDhjtdX7tVL0oDWrpUOC8tqg3/+KZ9Re3XME7p+XSrRsCfbuE8/BUqVkhUhE44eBAdL4YDVq+VCyJK+mNik1bVrpUzn8OGJT/62hZVFPAqDbGdJLUE2ICfP2bMlj3bMGAm2HQ2033hDDjrOqDRSr54Mo8aX2upjG1WggOTbh4RI5Rdb+7FOHTl579tnbhtsle/jpEfb8uWTC6VTp6REpr3AOU8eKW+5ZYvjPZ0bN0pAX7as/W0PHpQcUVYWsU0pGVEKCpLjaXS0Y4/v0kU+v5s3SwoRACxeLOlV1ao59lyc9Oi4oCD5/9+8aX0icoMGcQUDLJOB16yJu19rYNAgiR0GDXK8DayR7VEYZDuLt6z2aJSvrwxzdu8uvTHvv+9YoJ0+vdTu/f1381bIshg5UiqhxLdhA/OxrWnUSPbhggWSJ2pruytXZIEbM9kKsnfskO8Msq2rUUMC53/+iQu0bGnfXqr8TJliLFfU4qWXZCjbyHLbISHMxzbqqafkc7dpk6wY6Ki2bWVVzwkTpNzlihXSyeBomVJLkM2ebMeUKiWdRcuXy+fQlgcP5DzZsKF0aty6JRdac+fKqISj5X/v35c0LgbZHoNBtrOEhclkCG+pkW2EJa+3Z085wA8b5lig/fbbcsJOrN5oUkVFJT7jft8+yV9lPnbihg0DWrSQfF1rSz+nSSMXKmaz1MhOLMjeuVOCkNy5zX9db9K9u+T4fvGFnLDtmT4dWLfOseNVw4bymbUnPJyVRRzVqZOkFIwYERfsOqJhQ1mP4MABmQjZpo3jz3H4sByPCxVy/LGp3VtvSY52YmX94qtQQUbn3n1XRoNLlJARotKlZaTQUSdOyHcG2R6DQbaznDqVenqx4/PxkRN2794y/DxhgvHH5swpRf2NLGxh1MaNMoQXvwpGdLQc+EqXNu91vI2Pj+TaFyokJ+jz5xPfbvVqqd8aGWnea58+LWkF2bM/ed/OnczHNuqLLyRVqkcPZLAXqGXJIqM6WgNffWV9f1uEhclSz0bSGY4ckbxTjhoZZ0kbSZMmaWkjFunSyaiio/nYgOy3IkVkjgY5RikJmjNmtF7WzyJNGimDu2WL5G3PmmVscaHEsHyfx2GQ7SzeWiPbCB8f6Y1u00bqslpKChnRoIG5s6LDwiRwyJMn7rYTJ+SgV6qUea/jjYKDZfLNnTuyLxMbEbhxQ1J8du0y73V79JDnTDjKcOeOnPiZKmKMv7+s8pc9O4qPH2/7RG9x5oxUuHjhBRm6tmb2bKBqVWOLp1h68tiT7ZjcueWCZ/PmpK+uW7q0pH75+jr+WFYWSR57Zf0SqlQJ2LtX9ldSVyBm+T6PwyDbGWJipCc7tQbZgARIkyfLib5/f8fSRlatkp4Xe9UtjAgLk7bkyxd32/798p092faVKiUB1aZNMvSZUO3a8t3MetlFisgy0wnt3s1Jj47KmhX49lukO31aaqDbkz+/XFgdPCgVZqxVjtm4USY8Zshg/zkPHmRlkaTq0EHStkaMiFvi3BUiI6VXlPnYyWOrrF9iAgIeP1c5KjRUPvMJF14jt2GQ7QwXL0qvX2oOsgHJnR09WlJAjC6QAUjFgk2bpBcgucLCpBc7ICDutgMHJPDm8LUx7doBAwdKr9qPPz5+X86c0ttlZr1sS3WThDjpMWkaN8b5Zs2kosGWLfa3f/55+eytXSupCgmHriMj5XmMlO4DZF+yskjSKAXMmCFpH8lJG3HUyZOyn9mTnXzxy/pdverc12L5Po/DINsZUlP5Pnv69ZNgtn9/45ULatQAqleXnFJHa/cmlFjazv79ciBKmzZ5z52afPKJ9Fr36CFDmvHVqSM9m2YEAJGRMunr55+fvG/nTrlgypUr+a+Tyhzv3Vv+d127Gksb6dRJ9vmiRcDWrY/ft3u3fJaNBtkHDzJVJDly5ZIL3C1b5JjoCqwsYp6gIOCnnyTATs6CbUawfJ/HYZDtDKmtfJ8t/v7A1KnyP/nkE+OPGzJEelOWLEne63fsKKtsxXfgAPOxHeXvLwFX5sySRhB/oZMGDeT/aUYvzfnz0nNqrXwfJz0mSXS6dFJi8/BhKWlpxJAhElAnrK+8caN8NzKZzlJZhKNGyfPqq8DLLwMffGBsNc/ksqSmsCfbHKVLy3no66/jJieaLTxcJo0zyPYoDLKd4dQp+c4gW9SrJ7V4P/44rsSQPS+9JDmcn32WtBUkLd58U4bpLB4+lCWkmY/tuFy5ZCLdqVOSI2rRtq0EXjlzJv81LDWyE+Yl3r4t9dOZKpJ0jRrJ5+Hzz42ljSgFlCkjP//5Z9zoQs+ekoP/1FP2n+PIERnhYE928iglAZqr0kaOHAFy5GBur5lGj5bOivffd87zh4VJBwWDbI/CINsZwsKk/Fi6dO5uieeYOFEOMAMGGNvex0dy2QYPTnqQff++7Iv4KSeHD8sJij3ZSVO9ugRqM2c+WTUmuak9gPUa2bt3y3f2ZCfPxImyTPPrrxtP39Ja0hQ6d5Za2unSAbVqGXvswYPynUF28uXKJaOCW7fKhZIzsbKI+XLnlkXRFi2S8pdmY/k+j8Qg2xlSc/k+a/LkkWHqZctkJSwjWrSQSXdJLWe0davUeY5f+YKVRZJv5EiZSPrBB3G3jR8vIzdJre9qYa0nm5MezZExo6SNHDliPG1EKVmqvUgRoH59+VxaLobsCQlhZREztW8vdelHjnRu2siRI8zHdoYhQ2QBr6FDkzdCmxhLpweDbI/CINsZGGQnrn9/OXD362ds8hUgaQLjxsX1iDkisQmoBw5IgMgDUdLlzi3VRhYulMmIltvOn0/+ib9XLwmoE44Cbd4sgXeOHMl7fpLqIT16SG/o5s3GHpM5c1wJsj/+MF5e8+BBVhYxkyVtJH16GY0wY/QooWvXZH4Fe7LNlzGjXCCtW2espJ8jQkPl+Z2xCi8lGYNss7FGtnUBATLceeKE5FobERkpvaRGt4/v5EnpBU9YI7tECUldoaQbMkTqsQ4fLr9blgBObim/TJme7K2OipKVJZ9/PnnPTXE++0w+F46kjeTLJxdRn35qPAALCeGkR7PlzCnH0W3bpOqI2VhZxLl69pTqVkOHmptbbynfl3ARL3IrBtlmu3xZZvly0mPiGjSQ1QPHj4/rabYla1aZlT1/PnDunGOvFRYm+afxA2pWFjFHcLBM4Fm1SgLgQoUkJSi5i9J8/TWwZs3jt23ZIqsPvvBC8p6b4mTMCHz3nUwmjZ/2Y0/x4nKBZeREbqkswnxs87VrJwudfPCB8dQdo1hZxLkCAmR0dv/+J9cdSA6W7/NIDLLNxhrZ9n3+ufQwG50EOXCgXPF/+aVjr5MwbefmTTkhMR/bHH36yMXksGGSX1injvRkJyfX8L33ZEn1+FaulLzehg2T1VxKoGFD6VX74gtZ/MlsR4+ysoizKAVMmyYjp/36mfvcR45IIMhzmPO0aSOTuD/4wHjqpC1RUTJyyyDb4zDINhuDbPvy5ZODy9KlwIoV9rcvVEgOSjNmSI+mUUOGPL4UuGUVQfZkmyMwEPjwQ8nL/uUXqT4xcKCk+CTF7dtyIZSwssiKFUDVqpJKQub67DP5f7/+ulTjMZPl88Z0EecoWBAYNUouSpcuNe95Dx+WYM3Pz7znpMdZqmedOWNOys/p0xJoM8j2OAyyzcaFaIx55x2pONCvnwwr2/PuuxJo3bxp/DWaN5cvC1YWMV/HjvL/HDFCUoHefffxJewdYRn2jp9Df+kSsGsXU0WcJUMGSRs5duzx2udmsFQWYdqB87zzjnQavP02cPeuOc/JyiKuUa+eHNfGjweuX0/ec7F8n8dikG22sDCZ3Zs+vbtb4tkCAuQKPjRUavfaU7488Pffxi9ebt2SBVLu3Im77cAByUVNWB6Oks7XF5gwQfbjt99KZQJLxRFHWcr3xe/J/ucf+d6kSfLaSdY1aCBVXSZPjiuVaAZWFnE+f3/gm2/kAnXUqOQ/X2SkBGy8MHKNjz+Wc9WECcl7Hpbv81gMss3G8n3GNWokS3SPGxe3SqY9p04ZSzHZsUMWzIgf8O3fL70+nH1trqZNgdq1gTFjgO7dZZ8mRWJB9ooVUravXLnkt5Os++QTIEsWxyZB2sPKIq5RvbqUZJwyJW7RpqQ6cULSDtiT7RplygCvvSYdTpbjX1KEhgJp0kgpVfIoDLLNduoUU0UcMWmSTJQz2gvTrx/QqdPjPdSJSZgbr3VckE3mUkqCtEuXpCfs9GljlWMSevNN4MKFuOW6o6OlJ7tx46QvSETGZMwoqT4rV8oIUHKxsohrffyxVGLq2TN5ZeFYWcT1PvxQvifnApfl+zwWz1xm0po92Y7Kn1+qVMybF3eAt2XECMlfmzrV9nYnT0oqQ9688vuFC8CNG8zHdpaqVWUlunXr5PeklPLz8ZGloy0B9Y4dkn7CfGzX6NtXajCb0ZttqSzCnmzXyJxZOiy2b5cJ4kllqZHNINt18ueXzqN584C9e5P2HCzf57EYZJvI/8YNKcfDINsxQ4fKUNeYMfa3rVQJaNZM8rht9WaHhUnutWWGPCc9Ot+4cbKwSWBg0hal+ewz4Icf4n5fuVJ6ZrgIjWukSyclFNevB9auTd5zWSqLsCfbdV59VcoyvveerL6aFIcPy4UWK/m41vDh8j8fNszxx8bESB49g2yPxCDbREEXL8oPDLIdkyOHXMkvWhQXDNsyapT93uyEIwoHDsh3pos4T4kSsnBQRETSgrSvv46b6AhIPnblylwm2JV69JDRnxEjklfv/OBBGZFgj6jrWJZcDw+XUppJwcoi7pE5syzutXKl48fOc+dknzPI9kgMsk3EIDsZBg+WcmJGcrMrVQJeflnSP6yZPFlKI1ns3y+TQrJmTW5LyZbRo6XiQZkyjj0uOho4ezZu0uO1a7JsNKuKuFZQkATYmzcbm2CcmCtXpNJMhQqsLOJqRYpIsPbzz0nbf4cP88LIXfr2lePfu+86doHL8n0ejUG2iYIuXZIfOPHRcVmySM3X336Tusj2/PqrFPO3pmJFoFq1uN+5nLpr5MkjvWjLliGd5eBvhGXSpKW84qpVcqJhPrbrde0qC0B98IHjvdlay2jGtWvArFnOaR/Z9u67Eij36ePYAkNXr8oIIXuy3SMoSDopdu50rDeb5fs8GoNsEwVdvCjBYoYM7m5KyjRggAybjRxpf1vL5Lht257Izfa/dQv46Sfg8mW5ITpackSZj+0asTn2xeOPJNiTsHzfihXyWapY0fz2kW0BATKitGvXk0vc2zNtGrBsmVwAP/ecU5pHdgQGSu3ssDDgo4+MP46VRdzv1VclPW7aNOOPCQ2V0UPLJH/yKF4VZCulmiulZt5yZOltEwVdusRUkeQIDpal0JcvB7Zssb/9kSNAlSpPHJDSHzsmKxEeOiQ3nDghE1LZk+0amTMD+fIhw4kTwIYNxh5z9aqcKPLnl4k8f/8tddR9fZ3bVkpcx44SbI0cKfvDiH37JO2raVOZY0HuU6cO8PrrMkHcMh/FHktlEfZku09QkKw1sHRp3Aq49oSGAoUL81jpobwqyNZaL9Na9wgODnbL6wddvMggO7nefhvInt1YGbFixeSEnqDSyKPc+EKF5Dsri7hehw7yffhwY9u/+GLchdCePZI+wlQR9/Hzk6HrAwckv9ee+/elFy5TJmDOHNbr9QSffSYdF2++KasK2nP4sPSCM93RvXr1ku/ffGNse5bv82heFWS7ldYMss2QPr2UMVq92lit5VGjJP8zXm920MWLEiRYFjU5cEBO+qzZ6zrNm8v3//3PeDk/Hx/5WrlSfm/c2DltI2PatpWLnlGjZBVAWwYNkooic+dKtSByv2zZZCXBbduklOLy5ba3P3IEKFqUPaLuVqCAdDrMnClVQ2zRmkG2h2OQbZYrV+AbHs4g2wy9e0slECNlxCpXjuvNvnsXABB04cKTNbKffhpIm9bJDadHypXD5bp15echQ+zvx48+iquTvnIlUL681Osl9/Hxkf1y9Cjw44/Wt/vtN1kAZfBgSfEhz/Hqq1IpJlMmCdw6dZLUrMSwsojn6NtXqvQsXmx7u0uXgHv3GGR7MAbZZjl1Sr5zqC350qSRMlQbNkiPtj2WnrY9ewDE5sZbUkUAVhZxk1BLSart2+NWgrRm6VLJw795E9i0iaX7PEWLFlKK78MPpf55QmfPSg5phQqyGBF5nsqVZRLrqFGyFkHJkpICFP/CNyJC5q4wH9szNGwoowr2JkCyfJ/HY5BtlrAw+c6ebHN07y690UbKiFWuLAX5a9YEABwcORKYPl3ue/gQOHaM+dhuEJEtm/SO5ckjJ3hb+/H0aQnI16yRajDMx/YMSklv9smTkmsdX3S09IyGhwMLFkhVEvJMAQGSY79rl3QEtWsHvPIKcOGC3H/8uOxP9mR7Bh8fKcG4eTOwe7f17Vi+z+MxyDaLJchmT7Y5AgOlssHWrcBff9nfPl06qYJw7BjCc+SIO1kcPiwnD/Zku0eaNFL/fONG6/vxwQMZGs2fX0r3BQcDVau6tp1kXZMmQPXqEmw/fBh3+8cfS7791KnS60aer3RpCdw+/VTSskqWlIsnS/k+9mR7jtdflxRHW73ZoaGSQ8+4w2MxyDZLWBgiM2SQAIHM0aWLlCYyuihGv37AM8+g4OzZcRc9rCzifpYLnN69E9+PllJV+fLJif/55+Py6cn9lALGjpXRIkvFg82bZXSifXv5nFLK4ecn8yT27pXj4htvAD16yH3syfYcmTLJSNFPP8kiQYkJDZUA29/fpU0j4xhkm6VcOVxkHqm5/P3lRL57t0yusqdzZwBAwXnz4gK3AwdkqJTDae7TqJHk7J45A8yb9+T9d+5IDn1MjARy/Bx5nnr15GvCBEkx6NBBLopmzGC5vpTqmWeA9eulp/ThQwnWMmZ0d6sovr59ZaQvYaqWBSuLeDwG2Wbp3h3H+/Rxdyu8T8eOMoQ5cqSkfdhSpUrcz5bc+P37gRIleKXvbosWSTA2YMCTvdkVKsikqytX5HeW7vNMH30k1QwqVpQLpp9+4shdSmfJ/T16VOZDkGcpU0bmGn399ZOLQmkt840YZHs0Btnk2Xx9ZcJOSIixRTFCQ3HizTfjlphlZRHP8PTTQMuWwI0b1pd6XrlShq+5PLBnqlFDJqSePy+fyWrV3N0iMkvu3PIZJc/Tt69MTP3778dvv35dFhlikO3RGGST52vTRoKv0aPtL4rx9NM43aGD9JrevCk9bszH9gw//CCLDS1e/HhvtiW3d8MGpop4uq+/Br74wvhKnkSUPK+8ImsGJJwAyfJ9KQKDbPJ8Pj5Sp/fo0cRzeq0JCZHv7Mn2DOnTA5MmSQrPihVxt1vKVEVGsnSfpytQABg4kKsCErlKQIBMTP3rL0mrs2D5vhSBQTalDC1aSD3s0aPtLzVrwcoinqdLF5kw17mz1F4GpEZ2VJQE4TVquLd9RESepmdP6Wz6+uu420JDZcQ2/sJr5HEYZFPKoBQwfrwEZDNmGHvMgQMyWz5fPue2jYzz95dSi9evS4UKrWWfXr0KNGjABU2IiBLKk0fmtMyeLdVGAAmy8+YFgoLc2zayiUE2pRwNGsjXuHFS9s2e/fslVYQlxjxL//5AliyyjPq8eXLSuH2b+dhERNb07SudEwsXyu8s35ciMMimlGX8eCn1Nnmy7e20lp5spop4Hn9/4JNP5Odu3WSlR4BBNhGRNXXqAM8+KxMgtWaQnUIwyKaUpXJlGTb77DNJMbDmwgW56uekR8/0+uvAU09JLnZgoNRCt9Q2JyKixyklNc137gRWr5bOJgbZHo9BNqU8Y8cC9+4BH39sfZsDB+Q7e7I9k5+frB4IyIIKrCpCRGRb585AhgzA4MHyO4Nsj8cgm1KekiXlYDN1KnD2bOLbWCqLsCfbc3XoABQtKj8zVYSIyLYMGYDXXgP27ZPfuYCQx2OQTSnT6NGyzOyHHyZ+/4EDsopZ1qwubRY5wM9PFjapUQOoXdvdrSEi8nx9+8b9zCDb4zHIppSpYEGgVy8paXT06JP3WyqLkGd78UVg40aWoSIiMqJECamylTevrC1AHo1BNqVc778vwdnIkY/fHh0NHDzIfGwiIvI+8+bJCpDk8RhkU8qVMycwYACwaJEsyx0rzYULUnuZPdlERORtcudmJ1IKwSCbUrbBg4HMmaVXO1Y6y3LdPAgRERGRmzDIppQtUyZg2DBgxQrgv/8AAOlOnJCaoiVLurdtRERElGoxyKaU7623ZGGT4cMBraUn++mngbRp3d0yIiIiSqUYZFPKlzatTH7ctAlYvlyCbOZjExERkRsxyCbv8MYbsvrVsGFIe/Ys87GJiIjIrRhkk3fw95eFaUJCoGJi2JNNREREbsUgm7xHu3bAc8/Jz+zJJiIiIjdikE3ew8cHmD4dF59/HnjmGXe3hoiIiFIxBtnkXapXx+H33gN8fd3dEiIiIkrFGGQTEREREZmMQTYRERERkckYZBMRERERmYxBNhERERGRyRhkExERERGZjEE2EREREZHJGGQTEREREZmMQTYRERERkckYZBMRERERmYxBNhERERGRyRhkExERERGZjEE2EREREZHJGGQTEREREZnMq4JspVRzpdTMW7duubspRERERJSKeVWQrbVeprXuERwc7O6mEBEREVEq5lVBNhERERGRJ2CQTURERERkMgbZREREREQmU1prd7fBdEqpKwBOueGlswG46obXpcdxP3gG7gfPwX3hGbgfPAP3g2fwlv1QQGudPbE7vDLIdhel1A6tdUV3tyO1437wDNwPnoP7wjNwP3gG7gfPkBr2A9NFiIiIiIhMxiCbiIiIiMhkDLLNNdPdDSAA3A+egvvBc3BfeAbuB8/A/eAZvH4/MCebiIiIiMhk7MkmIiIiIjIZg2yTKKWaKKWOKKVClVLD3N2e1EIpNVspdVkpdSDebVmUUquUUsdiv2d2ZxtTA6VUPqXUOqXUIaVUiFKqf+zt3BcupJQKUkptU0rtjd0PY2Jv535wA6WUr1Jqt1Lqz9jfuR9cTCkVppTar5Tao5TaEXsb94MbKKUyKaUWK6UOx54rqnn7vmCQbQKllC+AaQBeAFASwKtKqZLubVWq8T2AJgluGwZgjda6KIA1sb+Tc0UBGKS1LgGgKoC+sZ8B7gvXCgdQX2v9HICyAJoopaqC+8Fd+gM4FO937gf3qKe1LhuvXBz3g3tMAbBSa10cwHOQz4ZX7wsG2eaoDCBUa31Cax0BYCGAFm5uU6qgtf4PwPUEN7cA8EPszz8AeNmVbUqNtNYXtNa7Yn++Azl45gH3hUtpcTf2V//YLw3uB5dTSuUF0AzAt/Fu5n7wDNwPLqaUygigNoDvAEBrHaG1vgkv3xcMss2RB8CZeL+fjb2N3COn1voCIMEfgBxubk+qopQqCKAcgK3gvnC52BSFPQAuA1ilteZ+cI/JAN4FEBPvNu4H19MA/lFK7VRK9Yi9jfvB9QoDuAJgTmwK1bdKqXTw8n3BINscKpHbWLaFUh2lVHoAvwIYoLW+7e72pEZa62itdVkAeQFUVkqVcnOTUh2l1IsALmutd7q7LYQaWuvykHTOvkqp2u5uUCrlB6A8gK+11uUA3IOXpYYkhkG2Oc4CyBfv97wAzrupLQRcUkrlBoDY75fd3J5UQSnlDwmw52utl8TezH3hJrFDseshcxa4H1yrBoCXlFJhkPTB+kqpH8H94HJa6/Ox3y8D+A2S3sn94HpnAZyNHVkDgMWQoNur9wWDbHNsB1BUKVVIKRUAoD2AP9zcptTsDwBdYn/uAmCpG9uSKiilFCTX7pDW+ot4d3FfuJBSKrtSKlPsz2kANARwGNwPLqW1Hq61zqu1Lgg5H6zVWncC94NLKaXSKaUyWH4G0AjAAXA/uJzW+iKAM0qpYrE3NQBwEF6+L7gYjUmUUk0hOXi+AGZrrce5t0Wpg1JqAYC6ALIBuARgFIDfAfwMID+A0wDaaK0TTo4kEymlagLYAGA/4nJQ34PkZXNfuIhSqgxk8pAvpBPlZ631h0qprOB+cAulVF0Ag7XWL3I/uJZSqjCk9xqQdIWftNbjuB/cQylVFjIROADACQBdEXucgpfuCwbZREREREQmY7oIEREREZHJGGQTEREREZmMQTYRERERkckYZBMRERERmYxBNhERERGRyRhkExF5EaVUtFJqT7wv01ZVU0oVVEodMOv5iIi8mZ+7G0BERKZ6ELusOhERuRF7somIUgGlVJhS6hOl1LbYryKxtxdQSq1RSu2L/Z4/9vacSqnflFJ7Y7+qxz6Vr1JqllIqRCn1T+zKkkRElACDbCIi75ImQbpIu3j33dZaVwYwFbJCLWJ/nqu1LgNgPoAvY2//EsC/WuvnAJQHEBJ7e1EA07TWzwK4CaCVU/8aIqIUiis+EhF5EaXUXa11+kRuDwNQX2t9QinlD+Ci1jqrUuoqgNxa68jY2y9orbMppa4AyKu1Do/3HAUBrNJaF439fSgAf631WBf8aUREKQp7somIUg9t5Wdr2yQmPN7P0eDcHiKiRDHIJiJKPdrF+7459udNANrH/twRwMbYn9cA6A0ASilfpVRGVzWSiMgbsAeCiMi7pFFK7Yn3+0qttaWMX6BSaiukg+XV2Nv6AZitlBoC4AqArrG39wcwUynVDdJj3RvABWc3nojIWzAnm4goFYjNya6otb7q7rYQEaUGTBchIiIiIjIZe7KJiIiIiEzGnmwiIiIiIpMxyCYiIiIiMhmDbCIiIiIikzHIJiIiIiIyGYNsIiIiIiKTMcgmIiIiIjLZ/wGx/JymZX1u9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the loss values\n",
    "total_loss = history.history['loss']\n",
    "reco_loss = history.history['reco_loss']\n",
    "kl_loss = history.history['kl_loss']\n",
    "val_total_loss = history.history['val_loss']\n",
    "val_reco_loss = history.history['val_reco_loss']\n",
    "val_kl_loss = history.history['val_kl_loss']\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot training losses\n",
    "plt.plot(total_loss, label='Total Loss', color='blue')\n",
    "plt.plot(reco_loss, label='Reconstruction Loss', color='green')\n",
    "plt.plot(kl_loss, label='KL Loss', color='red')\n",
    "\n",
    "# Plot validation losses\n",
    "plt.plot(val_total_loss, label='Val Total Loss', color='blue', linestyle='--')\n",
    "plt.plot(val_reco_loss, label='Val Reconstruction Loss', color='green', linestyle='--')\n",
    "plt.plot(val_kl_loss, label='Val KL Loss', color='red', linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "# plt.ylim(1e-2,1)\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f99babab-5b29-49e2-a808-1820efe212ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 10ms/step - loss: 0.9913 - reco_loss: 0.9735 - kl_loss: 0.0231 - beta: 0.1546 - val_loss: 0.6355 - val_reco_loss: 0.5919 - val_kl_loss: 0.0436 - val_beta: 0.1546 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5790 - reco_loss: 0.5332 - kl_loss: 0.0492 - beta: 0.2085 - val_loss: 0.5182 - val_reco_loss: 0.4621 - val_kl_loss: 0.0561 - val_beta: 0.2085 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4881 - reco_loss: 0.4338 - kl_loss: 0.0543 - beta: 0.2628 - val_loss: 0.4701 - val_reco_loss: 0.4104 - val_kl_loss: 0.0596 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4506 - reco_loss: 0.3978 - kl_loss: 0.0519 - beta: 0.3172 - val_loss: 0.4235 - val_reco_loss: 0.3687 - val_kl_loss: 0.0548 - val_beta: 0.3172 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4061 - reco_loss: 0.3578 - kl_loss: 0.0471 - beta: 0.3711 - val_loss: 0.3654 - val_reco_loss: 0.3146 - val_kl_loss: 0.0508 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3553 - reco_loss: 0.3111 - kl_loss: 0.0433 - beta: 0.4253 - val_loss: 0.3272 - val_reco_loss: 0.2805 - val_kl_loss: 0.0467 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3329 - reco_loss: 0.2919 - kl_loss: 0.0399 - beta: 0.4794 - val_loss: 0.3052 - val_reco_loss: 0.2643 - val_kl_loss: 0.0409 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3019 - reco_loss: 0.2650 - kl_loss: 0.0359 - beta: 0.5335 - val_loss: 0.2791 - val_reco_loss: 0.2388 - val_kl_loss: 0.0403 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2738 - reco_loss: 0.2409 - kl_loss: 0.0317 - beta: 0.5877 - val_loss: 0.2479 - val_reco_loss: 0.2107 - val_kl_loss: 0.0371 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2473 - reco_loss: 0.2185 - kl_loss: 0.0277 - beta: 0.6419 - val_loss: 0.2251 - val_reco_loss: 0.1938 - val_kl_loss: 0.0313 - val_beta: 0.6419 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2135 - reco_loss: 0.1890 - kl_loss: 0.0233 - beta: 0.6958 - val_loss: 0.1991 - val_reco_loss: 0.1719 - val_kl_loss: 0.0272 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3553 - reco_loss: 0.3299 - kl_loss: 0.0364 - beta: 0.1489 - val_loss: 0.3742 - val_reco_loss: 0.3195 - val_kl_loss: 0.0547 - val_beta: 0.1489 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3813 - reco_loss: 0.3300 - kl_loss: 0.0527 - beta: 0.2032 - val_loss: 0.3734 - val_reco_loss: 0.3126 - val_kl_loss: 0.0608 - val_beta: 0.2032 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3684 - reco_loss: 0.3133 - kl_loss: 0.0553 - beta: 0.2575 - val_loss: 0.3626 - val_reco_loss: 0.3022 - val_kl_loss: 0.0604 - val_beta: 0.2575 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3515 - reco_loss: 0.2971 - kl_loss: 0.0534 - beta: 0.3120 - val_loss: 0.3395 - val_reco_loss: 0.2760 - val_kl_loss: 0.0635 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3355 - reco_loss: 0.2849 - kl_loss: 0.0496 - beta: 0.3663 - val_loss: 0.3294 - val_reco_loss: 0.2735 - val_kl_loss: 0.0558 - val_beta: 0.3663 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3172 - reco_loss: 0.2702 - kl_loss: 0.0464 - beta: 0.4204 - val_loss: 0.3159 - val_reco_loss: 0.2634 - val_kl_loss: 0.0524 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2963 - reco_loss: 0.2524 - kl_loss: 0.0431 - beta: 0.4745 - val_loss: 0.2912 - val_reco_loss: 0.2393 - val_kl_loss: 0.0519 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2766 - reco_loss: 0.2370 - kl_loss: 0.0385 - beta: 0.5286 - val_loss: 0.2669 - val_reco_loss: 0.2203 - val_kl_loss: 0.0466 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2562 - reco_loss: 0.2214 - kl_loss: 0.0338 - beta: 0.5827 - val_loss: 0.2518 - val_reco_loss: 0.2137 - val_kl_loss: 0.0381 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2323 - reco_loss: 0.2014 - kl_loss: 0.0296 - beta: 0.6358\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2321 - reco_loss: 0.2013 - kl_loss: 0.0295 - beta: 0.6368 - val_loss: 0.2245 - val_reco_loss: 0.1905 - val_kl_loss: 0.0340 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2073 - reco_loss: 0.1811 - kl_loss: 0.0249 - beta: 0.6905 - val_loss: 0.1995 - val_reco_loss: 0.1716 - val_kl_loss: 0.0279 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2913 - reco_loss: 0.2670 - kl_loss: 0.0327 - beta: 0.1438 - val_loss: 0.3563 - val_reco_loss: 0.3050 - val_kl_loss: 0.0513 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3573 - reco_loss: 0.3081 - kl_loss: 0.0506 - beta: 0.1981 - val_loss: 0.3521 - val_reco_loss: 0.2938 - val_kl_loss: 0.0583 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3499 - reco_loss: 0.2962 - kl_loss: 0.0540 - beta: 0.2523 - val_loss: 0.3459 - val_reco_loss: 0.2870 - val_kl_loss: 0.0589 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3405 - reco_loss: 0.2867 - kl_loss: 0.0535 - beta: 0.3066 - val_loss: 0.3386 - val_reco_loss: 0.2783 - val_kl_loss: 0.0603 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3292 - reco_loss: 0.2774 - kl_loss: 0.0509 - beta: 0.3608 - val_loss: 0.3222 - val_reco_loss: 0.2652 - val_kl_loss: 0.0570 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3111 - reco_loss: 0.2627 - kl_loss: 0.0477 - beta: 0.4150 - val_loss: 0.3045 - val_reco_loss: 0.2452 - val_kl_loss: 0.0593 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2926 - reco_loss: 0.2474 - kl_loss: 0.0446 - beta: 0.4691 - val_loss: 0.2946 - val_reco_loss: 0.2490 - val_kl_loss: 0.0456 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2745 - reco_loss: 0.2330 - kl_loss: 0.0405 - beta: 0.5233 - val_loss: 0.2745 - val_reco_loss: 0.2292 - val_kl_loss: 0.0453 - val_beta: 0.5233 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2553 - reco_loss: 0.2172 - kl_loss: 0.0369 - beta: 0.5771\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2553 - reco_loss: 0.2171 - kl_loss: 0.0369 - beta: 0.5773 - val_loss: 0.2553 - val_reco_loss: 0.2171 - val_kl_loss: 0.0382 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2332 - reco_loss: 0.1997 - kl_loss: 0.0319 - beta: 0.6311 - val_loss: 0.2272 - val_reco_loss: 0.1921 - val_kl_loss: 0.0351 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2069 - reco_loss: 0.1784 - kl_loss: 0.0271 - beta: 0.6852 - val_loss: 0.1978 - val_reco_loss: 0.1662 - val_kl_loss: 0.0316 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2583 - reco_loss: 0.2343 - kl_loss: 0.0304 - beta: 0.1387 - val_loss: 0.3627 - val_reco_loss: 0.3122 - val_kl_loss: 0.0505 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3563 - reco_loss: 0.3088 - kl_loss: 0.0495 - beta: 0.1929 - val_loss: 0.3487 - val_reco_loss: 0.2888 - val_kl_loss: 0.0599 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3485 - reco_loss: 0.2948 - kl_loss: 0.0539 - beta: 0.2471 - val_loss: 0.3402 - val_reco_loss: 0.2766 - val_kl_loss: 0.0636 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3359 - reco_loss: 0.2819 - kl_loss: 0.0537 - beta: 0.3014 - val_loss: 0.3416 - val_reco_loss: 0.2846 - val_kl_loss: 0.0570 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3270 - reco_loss: 0.2746 - kl_loss: 0.0518 - beta: 0.3556 - val_loss: 0.3512 - val_reco_loss: 0.2950 - val_kl_loss: 0.0562 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3124 - reco_loss: 0.2620 - kl_loss: 0.0494 - beta: 0.4097 - val_loss: 0.3115 - val_reco_loss: 0.2580 - val_kl_loss: 0.0535 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2969 - reco_loss: 0.2500 - kl_loss: 0.0458 - beta: 0.4638 - val_loss: 0.2875 - val_reco_loss: 0.2342 - val_kl_loss: 0.0533 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2769 - reco_loss: 0.2339 - kl_loss: 0.0420 - beta: 0.5179 - val_loss: 0.2711 - val_reco_loss: 0.2198 - val_kl_loss: 0.0513 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2563 - reco_loss: 0.2172 - kl_loss: 0.0377 - beta: 0.5720 - val_loss: 0.2476 - val_reco_loss: 0.2020 - val_kl_loss: 0.0456 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2328 - reco_loss: 0.1985 - kl_loss: 0.0328 - beta: 0.6244\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2325 - reco_loss: 0.1984 - kl_loss: 0.0328 - beta: 0.6260 - val_loss: 0.2232 - val_reco_loss: 0.1853 - val_kl_loss: 0.0379 - val_beta: 0.6260 - lr: 4.9000e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2077 - reco_loss: 0.1785 - kl_loss: 0.0281 - beta: 0.6800 - val_loss: 0.1976 - val_reco_loss: 0.1656 - val_kl_loss: 0.0320 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2379 - reco_loss: 0.2136 - kl_loss: 0.0278 - beta: 0.1337 - val_loss: 0.3582 - val_reco_loss: 0.3143 - val_kl_loss: 0.0439 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3572 - reco_loss: 0.3125 - kl_loss: 0.0468 - beta: 0.1878 - val_loss: 0.3624 - val_reco_loss: 0.3091 - val_kl_loss: 0.0533 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3449 - reco_loss: 0.2933 - kl_loss: 0.0521 - beta: 0.2420 - val_loss: 0.3434 - val_reco_loss: 0.2859 - val_kl_loss: 0.0575 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3389 - reco_loss: 0.2854 - kl_loss: 0.0530 - beta: 0.2962 - val_loss: 0.3367 - val_reco_loss: 0.2734 - val_kl_loss: 0.0633 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3263 - reco_loss: 0.2740 - kl_loss: 0.0520 - beta: 0.3503 - val_loss: 0.3244 - val_reco_loss: 0.2665 - val_kl_loss: 0.0579 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3122 - reco_loss: 0.2622 - kl_loss: 0.0495 - beta: 0.4045 - val_loss: 0.3136 - val_reco_loss: 0.2571 - val_kl_loss: 0.0565 - val_beta: 0.4045 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2961 - reco_loss: 0.2486 - kl_loss: 0.0466 - beta: 0.4586 - val_loss: 0.2947 - val_reco_loss: 0.2400 - val_kl_loss: 0.0547 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2771 - reco_loss: 0.2328 - kl_loss: 0.0434 - beta: 0.5126 - val_loss: 0.2738 - val_reco_loss: 0.2310 - val_kl_loss: 0.0428 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2574 - reco_loss: 0.2169 - kl_loss: 0.0390 - beta: 0.5667 - val_loss: 0.2543 - val_reco_loss: 0.2066 - val_kl_loss: 0.0476 - val_beta: 0.5667 - lr: 3.4300e-04\n",
      "Epoch 54/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2338 - reco_loss: 0.1980 - kl_loss: 0.0345 - beta: 0.6198\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2337 - reco_loss: 0.1979 - kl_loss: 0.0344 - beta: 0.6208 - val_loss: 0.2237 - val_reco_loss: 0.1875 - val_kl_loss: 0.0362 - val_beta: 0.6208 - lr: 3.4300e-04\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2094 - reco_loss: 0.1791 - kl_loss: 0.0298 - beta: 0.6748 - val_loss: 0.2084 - val_reco_loss: 0.1743 - val_kl_loss: 0.0341 - val_beta: 0.6748 - lr: 2.4010e-04\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2226 - reco_loss: 0.1978 - kl_loss: 0.0257 - beta: 0.1286 - val_loss: 0.3568 - val_reco_loss: 0.3159 - val_kl_loss: 0.0410 - val_beta: 0.1286 - lr: 2.4010e-04\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3539 - reco_loss: 0.3116 - kl_loss: 0.0451 - beta: 0.1827 - val_loss: 0.3461 - val_reco_loss: 0.2922 - val_kl_loss: 0.0539 - val_beta: 0.1827 - lr: 2.4010e-04\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3451 - reco_loss: 0.2948 - kl_loss: 0.0510 - beta: 0.2369 - val_loss: 0.3431 - val_reco_loss: 0.2835 - val_kl_loss: 0.0596 - val_beta: 0.2369 - lr: 2.4010e-04\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3375 - reco_loss: 0.2849 - kl_loss: 0.0526 - beta: 0.2910 - val_loss: 0.3386 - val_reco_loss: 0.2772 - val_kl_loss: 0.0615 - val_beta: 0.2910 - lr: 2.4010e-04\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3261 - reco_loss: 0.2736 - kl_loss: 0.0520 - beta: 0.3451 - val_loss: 0.3268 - val_reco_loss: 0.2641 - val_kl_loss: 0.0626 - val_beta: 0.3451 - lr: 2.4010e-04\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3128 - reco_loss: 0.2621 - kl_loss: 0.0501 - beta: 0.3993 - val_loss: 0.3081 - val_reco_loss: 0.2568 - val_kl_loss: 0.0513 - val_beta: 0.3993 - lr: 2.4010e-04\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2951 - reco_loss: 0.2471 - kl_loss: 0.0473 - beta: 0.4534 - val_loss: 0.2980 - val_reco_loss: 0.2435 - val_kl_loss: 0.0545 - val_beta: 0.4534 - lr: 2.4010e-04\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2786 - reco_loss: 0.2333 - kl_loss: 0.0441 - beta: 0.5074 - val_loss: 0.2781 - val_reco_loss: 0.2257 - val_kl_loss: 0.0524 - val_beta: 0.5074 - lr: 2.4010e-04\n",
      "Epoch 64/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2585 - reco_loss: 0.2171 - kl_loss: 0.0402 - beta: 0.5600\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2584 - reco_loss: 0.2170 - kl_loss: 0.0402 - beta: 0.5615 - val_loss: 0.2515 - val_reco_loss: 0.2041 - val_kl_loss: 0.0475 - val_beta: 0.5615 - lr: 2.4010e-04\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2372 - reco_loss: 0.2004 - kl_loss: 0.0356 - beta: 0.6155 - val_loss: 0.2265 - val_reco_loss: 0.1834 - val_kl_loss: 0.0431 - val_beta: 0.6155 - lr: 1.6807e-04\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2116 - reco_loss: 0.1796 - kl_loss: 0.0313 - beta: 0.6696 - val_loss: 0.1981 - val_reco_loss: 0.1609 - val_kl_loss: 0.0372 - val_beta: 0.6696 - lr: 1.6807e-04\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2144 - reco_loss: 0.1877 - kl_loss: 0.0243 - beta: 0.1235 - val_loss: 0.3667 - val_reco_loss: 0.3309 - val_kl_loss: 0.0358 - val_beta: 0.1235 - lr: 1.6807e-04\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3546 - reco_loss: 0.3152 - kl_loss: 0.0431 - beta: 0.1776 - val_loss: 0.3507 - val_reco_loss: 0.3019 - val_kl_loss: 0.0487 - val_beta: 0.1776 - lr: 1.6807e-04\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3442 - reco_loss: 0.2953 - kl_loss: 0.0503 - beta: 0.2317 - val_loss: 0.3452 - val_reco_loss: 0.2849 - val_kl_loss: 0.0602 - val_beta: 0.2317 - lr: 1.6807e-04\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3354 - reco_loss: 0.2835 - kl_loss: 0.0522 - beta: 0.2859 - val_loss: 0.3322 - val_reco_loss: 0.2721 - val_kl_loss: 0.0601 - val_beta: 0.2859 - lr: 1.6807e-04\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3264 - reco_loss: 0.2743 - kl_loss: 0.0518 - beta: 0.3400 - val_loss: 0.3209 - val_reco_loss: 0.2622 - val_kl_loss: 0.0588 - val_beta: 0.3400 - lr: 1.6807e-04\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3120 - reco_loss: 0.2614 - kl_loss: 0.0504 - beta: 0.3941 - val_loss: 0.3132 - val_reco_loss: 0.2543 - val_kl_loss: 0.0588 - val_beta: 0.3941 - lr: 1.6807e-04\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2966 - reco_loss: 0.2478 - kl_loss: 0.0481 - beta: 0.4482 - val_loss: 0.3015 - val_reco_loss: 0.2480 - val_kl_loss: 0.0535 - val_beta: 0.4482 - lr: 1.6807e-04\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2800 - reco_loss: 0.2339 - kl_loss: 0.0451 - beta: 0.5023\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2800 - reco_loss: 0.2339 - kl_loss: 0.0451 - beta: 0.5023 - val_loss: 0.2753 - val_reco_loss: 0.2233 - val_kl_loss: 0.0520 - val_beta: 0.5023 - lr: 1.6807e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.9463 - reco_loss: 0.9309 - kl_loss: 0.0242 - beta: 0.1546 - val_loss: 0.6399 - val_reco_loss: 0.6006 - val_kl_loss: 0.0393 - val_beta: 0.1546 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5922 - reco_loss: 0.5472 - kl_loss: 0.0483 - beta: 0.2086 - val_loss: 0.5015 - val_reco_loss: 0.4423 - val_kl_loss: 0.0593 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4851 - reco_loss: 0.4321 - kl_loss: 0.0527 - beta: 0.2628 - val_loss: 0.4467 - val_reco_loss: 0.3901 - val_kl_loss: 0.0566 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4393 - reco_loss: 0.3872 - kl_loss: 0.0511 - beta: 0.3170 - val_loss: 0.3793 - val_reco_loss: 0.3249 - val_kl_loss: 0.0545 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3899 - reco_loss: 0.3424 - kl_loss: 0.0466 - beta: 0.3712 - val_loss: 0.3608 - val_reco_loss: 0.3106 - val_kl_loss: 0.0502 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3579 - reco_loss: 0.3144 - kl_loss: 0.0429 - beta: 0.4253 - val_loss: 0.3210 - val_reco_loss: 0.2719 - val_kl_loss: 0.0491 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3278 - reco_loss: 0.2878 - kl_loss: 0.0393 - beta: 0.4794 - val_loss: 0.3068 - val_reco_loss: 0.2625 - val_kl_loss: 0.0443 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3079 - reco_loss: 0.2709 - kl_loss: 0.0359 - beta: 0.5335 - val_loss: 0.2830 - val_reco_loss: 0.2433 - val_kl_loss: 0.0397 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2698 - reco_loss: 0.2373 - kl_loss: 0.0316 - beta: 0.5878 - val_loss: 0.2487 - val_reco_loss: 0.2119 - val_kl_loss: 0.0368 - val_beta: 0.5878 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2426 - reco_loss: 0.2143 - kl_loss: 0.0272 - beta: 0.6418 - val_loss: 0.2224 - val_reco_loss: 0.1928 - val_kl_loss: 0.0296 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2130 - reco_loss: 0.1894 - kl_loss: 0.0226 - beta: 0.6958 - val_loss: 0.1959 - val_reco_loss: 0.1700 - val_kl_loss: 0.0258 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3520 - reco_loss: 0.3272 - kl_loss: 0.0355 - beta: 0.1490 - val_loss: 0.3787 - val_reco_loss: 0.3318 - val_kl_loss: 0.0469 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3769 - reco_loss: 0.3258 - kl_loss: 0.0526 - beta: 0.2033 - val_loss: 0.3598 - val_reco_loss: 0.2949 - val_kl_loss: 0.0648 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3650 - reco_loss: 0.3097 - kl_loss: 0.0554 - beta: 0.2576 - val_loss: 0.3370 - val_reco_loss: 0.2730 - val_kl_loss: 0.0640 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3490 - reco_loss: 0.2947 - kl_loss: 0.0534 - beta: 0.3120 - val_loss: 0.3374 - val_reco_loss: 0.2767 - val_kl_loss: 0.0608 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3374 - reco_loss: 0.2854 - kl_loss: 0.0503 - beta: 0.3661 - val_loss: 0.3249 - val_reco_loss: 0.2669 - val_kl_loss: 0.0581 - val_beta: 0.3661 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3166 - reco_loss: 0.2692 - kl_loss: 0.0464 - beta: 0.4204 - val_loss: 0.3115 - val_reco_loss: 0.2569 - val_kl_loss: 0.0546 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2998 - reco_loss: 0.2552 - kl_loss: 0.0431 - beta: 0.4745 - val_loss: 0.2960 - val_reco_loss: 0.2459 - val_kl_loss: 0.0501 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2763 - reco_loss: 0.2356 - kl_loss: 0.0393 - beta: 0.5287 - val_loss: 0.2660 - val_reco_loss: 0.2194 - val_kl_loss: 0.0466 - val_beta: 0.5287 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2518 - reco_loss: 0.2162 - kl_loss: 0.0347 - beta: 0.5827 - val_loss: 0.2479 - val_reco_loss: 0.2037 - val_kl_loss: 0.0441 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2312 - reco_loss: 0.2002 - kl_loss: 0.0297 - beta: 0.6363\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2311 - reco_loss: 0.2001 - kl_loss: 0.0297 - beta: 0.6368 - val_loss: 0.2178 - val_reco_loss: 0.1836 - val_kl_loss: 0.0342 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2041 - reco_loss: 0.1778 - kl_loss: 0.0253 - beta: 0.6905 - val_loss: 0.1944 - val_reco_loss: 0.1665 - val_kl_loss: 0.0280 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2855 - reco_loss: 0.2605 - kl_loss: 0.0338 - beta: 0.1438 - val_loss: 0.3550 - val_reco_loss: 0.3046 - val_kl_loss: 0.0503 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3532 - reco_loss: 0.3029 - kl_loss: 0.0517 - beta: 0.1980 - val_loss: 0.3536 - val_reco_loss: 0.2905 - val_kl_loss: 0.0631 - val_beta: 0.1980 - lr: 7.0000e-04\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3476 - reco_loss: 0.2924 - kl_loss: 0.0550 - beta: 0.2523 - val_loss: 0.3394 - val_reco_loss: 0.2801 - val_kl_loss: 0.0592 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.3377 - reco_loss: 0.2836 - kl_loss: 0.0537 - beta: 0.3066 - val_loss: 0.3273 - val_reco_loss: 0.2646 - val_kl_loss: 0.0627 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3278 - reco_loss: 0.2759 - kl_loss: 0.0507 - beta: 0.3608 - val_loss: 0.3263 - val_reco_loss: 0.2642 - val_kl_loss: 0.0620 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3109 - reco_loss: 0.2618 - kl_loss: 0.0481 - beta: 0.4150 - val_loss: 0.3006 - val_reco_loss: 0.2505 - val_kl_loss: 0.0501 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2946 - reco_loss: 0.2489 - kl_loss: 0.0448 - beta: 0.4691 - val_loss: 0.2868 - val_reco_loss: 0.2382 - val_kl_loss: 0.0486 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2780 - reco_loss: 0.2355 - kl_loss: 0.0412 - beta: 0.5232 - val_loss: 0.2703 - val_reco_loss: 0.2241 - val_kl_loss: 0.0462 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2531 - reco_loss: 0.2151 - kl_loss: 0.0371 - beta: 0.5773 - val_loss: 0.2450 - val_reco_loss: 0.2057 - val_kl_loss: 0.0392 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.2305 - reco_loss: 0.1972 - kl_loss: 0.0321 - beta: 0.6300\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2303 - reco_loss: 0.1971 - kl_loss: 0.0321 - beta: 0.6314 - val_loss: 0.2244 - val_reco_loss: 0.1879 - val_kl_loss: 0.0365 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2067 - reco_loss: 0.1780 - kl_loss: 0.0274 - beta: 0.6852 - val_loss: 0.2024 - val_reco_loss: 0.1743 - val_kl_loss: 0.0282 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2594 - reco_loss: 0.2353 - kl_loss: 0.0300 - beta: 0.1388 - val_loss: 0.3541 - val_reco_loss: 0.3067 - val_kl_loss: 0.0474 - val_beta: 0.1388 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3486 - reco_loss: 0.3007 - kl_loss: 0.0498 - beta: 0.1929 - val_loss: 0.3460 - val_reco_loss: 0.2883 - val_kl_loss: 0.0577 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3454 - reco_loss: 0.2925 - kl_loss: 0.0536 - beta: 0.2472 - val_loss: 0.3409 - val_reco_loss: 0.2829 - val_kl_loss: 0.0580 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3373 - reco_loss: 0.2833 - kl_loss: 0.0533 - beta: 0.3014 - val_loss: 0.3329 - val_reco_loss: 0.2708 - val_kl_loss: 0.0621 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3239 - reco_loss: 0.2721 - kl_loss: 0.0509 - beta: 0.3555 - val_loss: 0.3294 - val_reco_loss: 0.2724 - val_kl_loss: 0.0570 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3112 - reco_loss: 0.2620 - kl_loss: 0.0481 - beta: 0.4097 - val_loss: 0.3073 - val_reco_loss: 0.2495 - val_kl_loss: 0.0578 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2935 - reco_loss: 0.2467 - kl_loss: 0.0456 - beta: 0.4638 - val_loss: 0.2963 - val_reco_loss: 0.2465 - val_kl_loss: 0.0498 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2751 - reco_loss: 0.2319 - kl_loss: 0.0423 - beta: 0.5179 - val_loss: 0.2693 - val_reco_loss: 0.2227 - val_kl_loss: 0.0467 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2539 - reco_loss: 0.2148 - kl_loss: 0.0381 - beta: 0.5715\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2538 - reco_loss: 0.2147 - kl_loss: 0.0381 - beta: 0.5720 - val_loss: 0.2437 - val_reco_loss: 0.2027 - val_kl_loss: 0.0409 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2309 - reco_loss: 0.1961 - kl_loss: 0.0339 - beta: 0.6259 - val_loss: 0.2244 - val_reco_loss: 0.1872 - val_kl_loss: 0.0372 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2076 - reco_loss: 0.1778 - kl_loss: 0.0291 - beta: 0.6800 - val_loss: 0.2036 - val_reco_loss: 0.1707 - val_kl_loss: 0.0330 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2376 - reco_loss: 0.2135 - kl_loss: 0.0276 - beta: 0.1337 - val_loss: 0.3488 - val_reco_loss: 0.3033 - val_kl_loss: 0.0456 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3480 - reco_loss: 0.3014 - kl_loss: 0.0488 - beta: 0.1878 - val_loss: 0.3454 - val_reco_loss: 0.2900 - val_kl_loss: 0.0554 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3432 - reco_loss: 0.2907 - kl_loss: 0.0533 - beta: 0.2420 - val_loss: 0.3436 - val_reco_loss: 0.2802 - val_kl_loss: 0.0634 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3341 - reco_loss: 0.2801 - kl_loss: 0.0536 - beta: 0.2962 - val_loss: 0.3315 - val_reco_loss: 0.2719 - val_kl_loss: 0.0596 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3217 - reco_loss: 0.2699 - kl_loss: 0.0515 - beta: 0.3503 - val_loss: 0.3137 - val_reco_loss: 0.2547 - val_kl_loss: 0.0590 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3118 - reco_loss: 0.2622 - kl_loss: 0.0489 - beta: 0.4044 - val_loss: 0.3046 - val_reco_loss: 0.2509 - val_kl_loss: 0.0537 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2933 - reco_loss: 0.2459 - kl_loss: 0.0466 - beta: 0.4586 - val_loss: 0.2940 - val_reco_loss: 0.2408 - val_kl_loss: 0.0532 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2752 - reco_loss: 0.2311 - kl_loss: 0.0432 - beta: 0.5111\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2750 - reco_loss: 0.2310 - kl_loss: 0.0432 - beta: 0.5127 - val_loss: 0.2729 - val_reco_loss: 0.2249 - val_kl_loss: 0.0480 - val_beta: 0.5127 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.9254 - reco_loss: 0.9089 - kl_loss: 0.0274 - beta: 0.1544 - val_loss: 0.6290 - val_reco_loss: 0.5820 - val_kl_loss: 0.0470 - val_beta: 0.1544 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5758 - reco_loss: 0.5275 - kl_loss: 0.0511 - beta: 0.2085 - val_loss: 0.5165 - val_reco_loss: 0.4568 - val_kl_loss: 0.0597 - val_beta: 0.2085 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4797 - reco_loss: 0.4250 - kl_loss: 0.0544 - beta: 0.2628 - val_loss: 0.4371 - val_reco_loss: 0.3791 - val_kl_loss: 0.0580 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4276 - reco_loss: 0.3756 - kl_loss: 0.0512 - beta: 0.3170 - val_loss: 0.3762 - val_reco_loss: 0.3211 - val_kl_loss: 0.0551 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3888 - reco_loss: 0.3409 - kl_loss: 0.0463 - beta: 0.3713 - val_loss: 0.3407 - val_reco_loss: 0.2897 - val_kl_loss: 0.0510 - val_beta: 0.3713 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3636 - reco_loss: 0.3200 - kl_loss: 0.0427 - beta: 0.4252 - val_loss: 0.3275 - val_reco_loss: 0.2829 - val_kl_loss: 0.0447 - val_beta: 0.4252 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3349 - reco_loss: 0.2953 - kl_loss: 0.0389 - beta: 0.4794 - val_loss: 0.3006 - val_reco_loss: 0.2569 - val_kl_loss: 0.0437 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3097 - reco_loss: 0.2740 - kl_loss: 0.0345 - beta: 0.5336 - val_loss: 0.2691 - val_reco_loss: 0.2268 - val_kl_loss: 0.0424 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2817 - reco_loss: 0.2498 - kl_loss: 0.0304 - beta: 0.5877 - val_loss: 0.2466 - val_reco_loss: 0.2109 - val_kl_loss: 0.0357 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2532 - reco_loss: 0.2260 - kl_loss: 0.0262 - beta: 0.6417 - val_loss: 0.2191 - val_reco_loss: 0.1901 - val_kl_loss: 0.0290 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2234 - reco_loss: 0.2001 - kl_loss: 0.0220 - beta: 0.6958 - val_loss: 0.1875 - val_reco_loss: 0.1620 - val_kl_loss: 0.0255 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3600 - reco_loss: 0.3348 - kl_loss: 0.0360 - beta: 0.1490 - val_loss: 0.3712 - val_reco_loss: 0.3185 - val_kl_loss: 0.0527 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4023 - reco_loss: 0.3511 - kl_loss: 0.0523 - beta: 0.2034 - val_loss: 0.3722 - val_reco_loss: 0.3120 - val_kl_loss: 0.0602 - val_beta: 0.2034 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3721 - reco_loss: 0.3175 - kl_loss: 0.0546 - beta: 0.2576 - val_loss: 0.3481 - val_reco_loss: 0.2864 - val_kl_loss: 0.0617 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3669 - reco_loss: 0.3137 - kl_loss: 0.0523 - beta: 0.3120 - val_loss: 0.3419 - val_reco_loss: 0.2822 - val_kl_loss: 0.0597 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3436 - reco_loss: 0.2941 - kl_loss: 0.0487 - beta: 0.3662 - val_loss: 0.3255 - val_reco_loss: 0.2716 - val_kl_loss: 0.0539 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3224 - reco_loss: 0.2767 - kl_loss: 0.0449 - beta: 0.4204 - val_loss: 0.3115 - val_reco_loss: 0.2580 - val_kl_loss: 0.0535 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3028 - reco_loss: 0.2603 - kl_loss: 0.0418 - beta: 0.4744 - val_loss: 0.2818 - val_reco_loss: 0.2343 - val_kl_loss: 0.0475 - val_beta: 0.4744 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2801 - reco_loss: 0.2413 - kl_loss: 0.0380 - beta: 0.5285 - val_loss: 0.2624 - val_reco_loss: 0.2210 - val_kl_loss: 0.0414 - val_beta: 0.5285 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2565 - reco_loss: 0.2214 - kl_loss: 0.0340 - beta: 0.5827 - val_loss: 0.2448 - val_reco_loss: 0.2049 - val_kl_loss: 0.0398 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2313 - reco_loss: 0.2007 - kl_loss: 0.0295 - beta: 0.6361\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2312 - reco_loss: 0.2006 - kl_loss: 0.0295 - beta: 0.6368 - val_loss: 0.2195 - val_reco_loss: 0.1864 - val_kl_loss: 0.0331 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2058 - reco_loss: 0.1792 - kl_loss: 0.0251 - beta: 0.6905 - val_loss: 0.1916 - val_reco_loss: 0.1619 - val_kl_loss: 0.0297 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2884 - reco_loss: 0.2631 - kl_loss: 0.0342 - beta: 0.1438 - val_loss: 0.3578 - val_reco_loss: 0.3054 - val_kl_loss: 0.0523 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3590 - reco_loss: 0.3084 - kl_loss: 0.0519 - beta: 0.1981 - val_loss: 0.3475 - val_reco_loss: 0.2891 - val_kl_loss: 0.0584 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3503 - reco_loss: 0.2961 - kl_loss: 0.0547 - beta: 0.2523 - val_loss: 0.3506 - val_reco_loss: 0.2899 - val_kl_loss: 0.0608 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3418 - reco_loss: 0.2881 - kl_loss: 0.0530 - beta: 0.3066 - val_loss: 0.3373 - val_reco_loss: 0.2783 - val_kl_loss: 0.0590 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3274 - reco_loss: 0.2767 - kl_loss: 0.0501 - beta: 0.3609 - val_loss: 0.3261 - val_reco_loss: 0.2616 - val_kl_loss: 0.0645 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3139 - reco_loss: 0.2665 - kl_loss: 0.0463 - beta: 0.4150 - val_loss: 0.3112 - val_reco_loss: 0.2583 - val_kl_loss: 0.0529 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2978 - reco_loss: 0.2534 - kl_loss: 0.0432 - beta: 0.4691 - val_loss: 0.2911 - val_reco_loss: 0.2398 - val_kl_loss: 0.0513 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2740 - reco_loss: 0.2332 - kl_loss: 0.0400 - beta: 0.5232 - val_loss: 0.2716 - val_reco_loss: 0.2213 - val_kl_loss: 0.0503 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2565 - reco_loss: 0.2194 - kl_loss: 0.0357 - beta: 0.5773\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2565 - reco_loss: 0.2194 - kl_loss: 0.0357 - beta: 0.5773 - val_loss: 0.2464 - val_reco_loss: 0.2078 - val_kl_loss: 0.0386 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2289 - reco_loss: 0.1965 - kl_loss: 0.0317 - beta: 0.6311 - val_loss: 0.2216 - val_reco_loss: 0.1850 - val_kl_loss: 0.0366 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2079 - reco_loss: 0.1788 - kl_loss: 0.0274 - beta: 0.6852 - val_loss: 0.1978 - val_reco_loss: 0.1686 - val_kl_loss: 0.0292 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2583 - reco_loss: 0.2337 - kl_loss: 0.0314 - beta: 0.1387 - val_loss: 0.3504 - val_reco_loss: 0.2974 - val_kl_loss: 0.0531 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3518 - reco_loss: 0.3022 - kl_loss: 0.0513 - beta: 0.1929 - val_loss: 0.3477 - val_reco_loss: 0.2849 - val_kl_loss: 0.0628 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3457 - reco_loss: 0.2915 - kl_loss: 0.0546 - beta: 0.2471 - val_loss: 0.3447 - val_reco_loss: 0.2812 - val_kl_loss: 0.0636 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3415 - reco_loss: 0.2869 - kl_loss: 0.0542 - beta: 0.3014 - val_loss: 0.3399 - val_reco_loss: 0.2792 - val_kl_loss: 0.0607 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3290 - reco_loss: 0.2772 - kl_loss: 0.0513 - beta: 0.3555 - val_loss: 0.3139 - val_reco_loss: 0.2559 - val_kl_loss: 0.0580 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3132 - reco_loss: 0.2647 - kl_loss: 0.0476 - beta: 0.4097 - val_loss: 0.3045 - val_reco_loss: 0.2475 - val_kl_loss: 0.0570 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2964 - reco_loss: 0.2509 - kl_loss: 0.0444 - beta: 0.4638 - val_loss: 0.2838 - val_reco_loss: 0.2313 - val_kl_loss: 0.0525 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2766 - reco_loss: 0.2346 - kl_loss: 0.0411 - beta: 0.5174\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2766 - reco_loss: 0.2345 - kl_loss: 0.0410 - beta: 0.5179 - val_loss: 0.2681 - val_reco_loss: 0.2249 - val_kl_loss: 0.0432 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 7s 9ms/step - loss: 0.9007 - reco_loss: 0.8906 - kl_loss: 0.0184 - beta: 0.1544 - val_loss: 0.6202 - val_reco_loss: 0.5808 - val_kl_loss: 0.0395 - val_beta: 0.1544 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5588 - reco_loss: 0.5165 - kl_loss: 0.0446 - beta: 0.2087 - val_loss: 0.5480 - val_reco_loss: 0.5016 - val_kl_loss: 0.0464 - val_beta: 0.2087 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4964 - reco_loss: 0.4488 - kl_loss: 0.0476 - beta: 0.2630 - val_loss: 0.4941 - val_reco_loss: 0.4436 - val_kl_loss: 0.0505 - val_beta: 0.2630 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4343 - reco_loss: 0.3866 - kl_loss: 0.0472 - beta: 0.3169 - val_loss: 0.4377 - val_reco_loss: 0.3853 - val_kl_loss: 0.0525 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3943 - reco_loss: 0.3491 - kl_loss: 0.0450 - beta: 0.3711 - val_loss: 0.3911 - val_reco_loss: 0.3377 - val_kl_loss: 0.0534 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3629 - reco_loss: 0.3198 - kl_loss: 0.0424 - beta: 0.4254 - val_loss: 0.3425 - val_reco_loss: 0.2961 - val_kl_loss: 0.0464 - val_beta: 0.4254 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3302 - reco_loss: 0.2900 - kl_loss: 0.0394 - beta: 0.4795 - val_loss: 0.3122 - val_reco_loss: 0.2679 - val_kl_loss: 0.0443 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2973 - reco_loss: 0.2610 - kl_loss: 0.0356 - beta: 0.5335 - val_loss: 0.2823 - val_reco_loss: 0.2390 - val_kl_loss: 0.0432 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2721 - reco_loss: 0.2399 - kl_loss: 0.0311 - beta: 0.5877 - val_loss: 0.2590 - val_reco_loss: 0.2210 - val_kl_loss: 0.0379 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2435 - reco_loss: 0.2153 - kl_loss: 0.0268 - beta: 0.6417 - val_loss: 0.2317 - val_reco_loss: 0.1997 - val_kl_loss: 0.0321 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2140 - reco_loss: 0.1909 - kl_loss: 0.0218 - beta: 0.6958 - val_loss: 0.1992 - val_reco_loss: 0.1716 - val_kl_loss: 0.0276 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3548 - reco_loss: 0.3322 - kl_loss: 0.0337 - beta: 0.1490 - val_loss: 0.3796 - val_reco_loss: 0.3259 - val_kl_loss: 0.0537 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3866 - reco_loss: 0.3361 - kl_loss: 0.0520 - beta: 0.2033 - val_loss: 0.3643 - val_reco_loss: 0.3034 - val_kl_loss: 0.0609 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3726 - reco_loss: 0.3183 - kl_loss: 0.0543 - beta: 0.2577 - val_loss: 0.3713 - val_reco_loss: 0.3148 - val_kl_loss: 0.0565 - val_beta: 0.2577 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3633 - reco_loss: 0.3104 - kl_loss: 0.0525 - beta: 0.3121 - val_loss: 0.3468 - val_reco_loss: 0.2836 - val_kl_loss: 0.0632 - val_beta: 0.3121 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3486 - reco_loss: 0.2986 - kl_loss: 0.0492 - beta: 0.3661 - val_loss: 0.3343 - val_reco_loss: 0.2785 - val_kl_loss: 0.0558 - val_beta: 0.3661 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3259 - reco_loss: 0.2791 - kl_loss: 0.0460 - beta: 0.4204 - val_loss: 0.3204 - val_reco_loss: 0.2695 - val_kl_loss: 0.0509 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3074 - reco_loss: 0.2642 - kl_loss: 0.0422 - beta: 0.4745 - val_loss: 0.2940 - val_reco_loss: 0.2429 - val_kl_loss: 0.0511 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2836 - reco_loss: 0.2443 - kl_loss: 0.0383 - beta: 0.5286 - val_loss: 0.2735 - val_reco_loss: 0.2284 - val_kl_loss: 0.0450 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2588 - reco_loss: 0.2233 - kl_loss: 0.0343 - beta: 0.5827 - val_loss: 0.2499 - val_reco_loss: 0.2083 - val_kl_loss: 0.0417 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2353 - reco_loss: 0.2047 - kl_loss: 0.0296 - beta: 0.6366\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2352 - reco_loss: 0.2046 - kl_loss: 0.0296 - beta: 0.6368 - val_loss: 0.2252 - val_reco_loss: 0.1897 - val_kl_loss: 0.0356 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2073 - reco_loss: 0.1814 - kl_loss: 0.0248 - beta: 0.6905 - val_loss: 0.1916 - val_reco_loss: 0.1633 - val_kl_loss: 0.0283 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2987 - reco_loss: 0.2740 - kl_loss: 0.0336 - beta: 0.1438 - val_loss: 0.3810 - val_reco_loss: 0.3299 - val_kl_loss: 0.0511 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3660 - reco_loss: 0.3164 - kl_loss: 0.0510 - beta: 0.1981 - val_loss: 0.3550 - val_reco_loss: 0.2944 - val_kl_loss: 0.0606 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3571 - reco_loss: 0.3036 - kl_loss: 0.0542 - beta: 0.2524 - val_loss: 0.3499 - val_reco_loss: 0.2886 - val_kl_loss: 0.0612 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3431 - reco_loss: 0.2892 - kl_loss: 0.0536 - beta: 0.3066 - val_loss: 0.3394 - val_reco_loss: 0.2747 - val_kl_loss: 0.0648 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3346 - reco_loss: 0.2831 - kl_loss: 0.0506 - beta: 0.3609 - val_loss: 0.3266 - val_reco_loss: 0.2709 - val_kl_loss: 0.0557 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3170 - reco_loss: 0.2694 - kl_loss: 0.0470 - beta: 0.4150 - val_loss: 0.3157 - val_reco_loss: 0.2607 - val_kl_loss: 0.0550 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3002 - reco_loss: 0.2552 - kl_loss: 0.0440 - beta: 0.4691 - val_loss: 0.3016 - val_reco_loss: 0.2497 - val_kl_loss: 0.0519 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2821 - reco_loss: 0.2407 - kl_loss: 0.0402 - beta: 0.5232 - val_loss: 0.2733 - val_reco_loss: 0.2251 - val_kl_loss: 0.0483 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2593 - reco_loss: 0.2217 - kl_loss: 0.0364 - beta: 0.5773 - val_loss: 0.2530 - val_reco_loss: 0.2076 - val_kl_loss: 0.0453 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.2326 - reco_loss: 0.2001 - kl_loss: 0.0315 - beta: 0.6300\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2325 - reco_loss: 0.2000 - kl_loss: 0.0315 - beta: 0.6314 - val_loss: 0.2267 - val_reco_loss: 0.1905 - val_kl_loss: 0.0362 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2089 - reco_loss: 0.1814 - kl_loss: 0.0267 - beta: 0.6852 - val_loss: 0.2007 - val_reco_loss: 0.1675 - val_kl_loss: 0.0332 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2623 - reco_loss: 0.2391 - kl_loss: 0.0289 - beta: 0.1388 - val_loss: 0.3565 - val_reco_loss: 0.3085 - val_kl_loss: 0.0480 - val_beta: 0.1388 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3553 - reco_loss: 0.3070 - kl_loss: 0.0504 - beta: 0.1929 - val_loss: 0.3574 - val_reco_loss: 0.2966 - val_kl_loss: 0.0608 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3511 - reco_loss: 0.2971 - kl_loss: 0.0544 - beta: 0.2471 - val_loss: 0.3459 - val_reco_loss: 0.2833 - val_kl_loss: 0.0626 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3445 - reco_loss: 0.2898 - kl_loss: 0.0537 - beta: 0.3014 - val_loss: 0.3397 - val_reco_loss: 0.2773 - val_kl_loss: 0.0624 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3286 - reco_loss: 0.2779 - kl_loss: 0.0500 - beta: 0.3556 - val_loss: 0.3305 - val_reco_loss: 0.2702 - val_kl_loss: 0.0604 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3145 - reco_loss: 0.2663 - kl_loss: 0.0474 - beta: 0.4097 - val_loss: 0.3093 - val_reco_loss: 0.2532 - val_kl_loss: 0.0561 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2989 - reco_loss: 0.2529 - kl_loss: 0.0448 - beta: 0.4638 - val_loss: 0.2945 - val_reco_loss: 0.2435 - val_kl_loss: 0.0510 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2771 - reco_loss: 0.2347 - kl_loss: 0.0415 - beta: 0.5179 - val_loss: 0.2758 - val_reco_loss: 0.2242 - val_kl_loss: 0.0516 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2594 - reco_loss: 0.2203 - kl_loss: 0.0375 - beta: 0.5716\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2593 - reco_loss: 0.2202 - kl_loss: 0.0375 - beta: 0.5720 - val_loss: 0.2452 - val_reco_loss: 0.1990 - val_kl_loss: 0.0462 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2358 - reco_loss: 0.2014 - kl_loss: 0.0331 - beta: 0.6259 - val_loss: 0.2289 - val_reco_loss: 0.1887 - val_kl_loss: 0.0402 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2102 - reco_loss: 0.1800 - kl_loss: 0.0287 - beta: 0.6800 - val_loss: 0.2042 - val_reco_loss: 0.1713 - val_kl_loss: 0.0328 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2419 - reco_loss: 0.2180 - kl_loss: 0.0271 - beta: 0.1337 - val_loss: 0.3578 - val_reco_loss: 0.3111 - val_kl_loss: 0.0467 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3577 - reco_loss: 0.3118 - kl_loss: 0.0486 - beta: 0.1878 - val_loss: 0.3443 - val_reco_loss: 0.2831 - val_kl_loss: 0.0612 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3501 - reco_loss: 0.2963 - kl_loss: 0.0542 - beta: 0.2420 - val_loss: 0.3410 - val_reco_loss: 0.2768 - val_kl_loss: 0.0642 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3393 - reco_loss: 0.2858 - kl_loss: 0.0535 - beta: 0.2962 - val_loss: 0.3326 - val_reco_loss: 0.2723 - val_kl_loss: 0.0603 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3289 - reco_loss: 0.2776 - kl_loss: 0.0508 - beta: 0.3503 - val_loss: 0.3256 - val_reco_loss: 0.2655 - val_kl_loss: 0.0601 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3145 - reco_loss: 0.2656 - kl_loss: 0.0484 - beta: 0.4044 - val_loss: 0.3115 - val_reco_loss: 0.2521 - val_kl_loss: 0.0594 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2984 - reco_loss: 0.2519 - kl_loss: 0.0456 - beta: 0.4585 - val_loss: 0.2908 - val_reco_loss: 0.2377 - val_kl_loss: 0.0531 - val_beta: 0.4585 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2789 - reco_loss: 0.2357 - kl_loss: 0.0423 - beta: 0.5126\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2789 - reco_loss: 0.2357 - kl_loss: 0.0423 - beta: 0.5126 - val_loss: 0.2764 - val_reco_loss: 0.2267 - val_kl_loss: 0.0497 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.8702 - reco_loss: 0.8512 - kl_loss: 0.0307 - beta: 0.1545 - val_loss: 0.6292 - val_reco_loss: 0.5772 - val_kl_loss: 0.0520 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5473 - reco_loss: 0.4960 - kl_loss: 0.0536 - beta: 0.2087 - val_loss: 0.5407 - val_reco_loss: 0.4781 - val_kl_loss: 0.0626 - val_beta: 0.2087 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.4729 - reco_loss: 0.4162 - kl_loss: 0.0563 - beta: 0.2627 - val_loss: 0.4740 - val_reco_loss: 0.4162 - val_kl_loss: 0.0578 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4202 - reco_loss: 0.3665 - kl_loss: 0.0529 - beta: 0.3171 - val_loss: 0.4290 - val_reco_loss: 0.3705 - val_kl_loss: 0.0586 - val_beta: 0.3171 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3881 - reco_loss: 0.3392 - kl_loss: 0.0480 - beta: 0.3712 - val_loss: 0.3889 - val_reco_loss: 0.3352 - val_kl_loss: 0.0537 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3589 - reco_loss: 0.3140 - kl_loss: 0.0441 - beta: 0.4254 - val_loss: 0.3498 - val_reco_loss: 0.3019 - val_kl_loss: 0.0480 - val_beta: 0.4254 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3246 - reco_loss: 0.2836 - kl_loss: 0.0401 - beta: 0.4796 - val_loss: 0.3187 - val_reco_loss: 0.2762 - val_kl_loss: 0.0424 - val_beta: 0.4796 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2981 - reco_loss: 0.2617 - kl_loss: 0.0356 - beta: 0.5336 - val_loss: 0.2909 - val_reco_loss: 0.2517 - val_kl_loss: 0.0392 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2701 - reco_loss: 0.2375 - kl_loss: 0.0313 - beta: 0.5877 - val_loss: 0.2595 - val_reco_loss: 0.2278 - val_kl_loss: 0.0316 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2406 - reco_loss: 0.2126 - kl_loss: 0.0267 - beta: 0.6417 - val_loss: 0.2278 - val_reco_loss: 0.1977 - val_kl_loss: 0.0302 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2093 - reco_loss: 0.1868 - kl_loss: 0.0217 - beta: 0.6958 - val_loss: 0.1961 - val_reco_loss: 0.1708 - val_kl_loss: 0.0253 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3523 - reco_loss: 0.3278 - kl_loss: 0.0359 - beta: 0.1490 - val_loss: 0.3997 - val_reco_loss: 0.3492 - val_kl_loss: 0.0506 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3874 - reco_loss: 0.3365 - kl_loss: 0.0523 - beta: 0.2033 - val_loss: 0.3843 - val_reco_loss: 0.3286 - val_kl_loss: 0.0558 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3671 - reco_loss: 0.3125 - kl_loss: 0.0546 - beta: 0.2576 - val_loss: 0.3764 - val_reco_loss: 0.3125 - val_kl_loss: 0.0639 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3517 - reco_loss: 0.2982 - kl_loss: 0.0526 - beta: 0.3120 - val_loss: 0.3565 - val_reco_loss: 0.2940 - val_kl_loss: 0.0625 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3390 - reco_loss: 0.2891 - kl_loss: 0.0492 - beta: 0.3662 - val_loss: 0.3414 - val_reco_loss: 0.2882 - val_kl_loss: 0.0532 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3208 - reco_loss: 0.2745 - kl_loss: 0.0460 - beta: 0.4203 - val_loss: 0.3145 - val_reco_loss: 0.2683 - val_kl_loss: 0.0462 - val_beta: 0.4203 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2982 - reco_loss: 0.2550 - kl_loss: 0.0427 - beta: 0.4745 - val_loss: 0.2944 - val_reco_loss: 0.2468 - val_kl_loss: 0.0476 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2806 - reco_loss: 0.2407 - kl_loss: 0.0390 - beta: 0.5286 - val_loss: 0.2731 - val_reco_loss: 0.2247 - val_kl_loss: 0.0484 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2553 - reco_loss: 0.2194 - kl_loss: 0.0347 - beta: 0.5827 - val_loss: 0.2483 - val_reco_loss: 0.2067 - val_kl_loss: 0.0416 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2344 - reco_loss: 0.2031 - kl_loss: 0.0298 - beta: 0.6366\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2344 - reco_loss: 0.2030 - kl_loss: 0.0298 - beta: 0.6368 - val_loss: 0.2243 - val_reco_loss: 0.1916 - val_kl_loss: 0.0327 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2056 - reco_loss: 0.1796 - kl_loss: 0.0251 - beta: 0.6905 - val_loss: 0.1984 - val_reco_loss: 0.1659 - val_kl_loss: 0.0325 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2906 - reco_loss: 0.2659 - kl_loss: 0.0338 - beta: 0.1438 - val_loss: 0.3817 - val_reco_loss: 0.3311 - val_kl_loss: 0.0506 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3590 - reco_loss: 0.3091 - kl_loss: 0.0515 - beta: 0.1981 - val_loss: 0.3766 - val_reco_loss: 0.3206 - val_kl_loss: 0.0560 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3526 - reco_loss: 0.2983 - kl_loss: 0.0546 - beta: 0.2523 - val_loss: 0.3616 - val_reco_loss: 0.2969 - val_kl_loss: 0.0646 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3434 - reco_loss: 0.2893 - kl_loss: 0.0532 - beta: 0.3066 - val_loss: 0.3500 - val_reco_loss: 0.2877 - val_kl_loss: 0.0624 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3293 - reco_loss: 0.2783 - kl_loss: 0.0502 - beta: 0.3609 - val_loss: 0.3382 - val_reco_loss: 0.2786 - val_kl_loss: 0.0596 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3163 - reco_loss: 0.2677 - kl_loss: 0.0477 - beta: 0.4150 - val_loss: 0.3191 - val_reco_loss: 0.2606 - val_kl_loss: 0.0585 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2946 - reco_loss: 0.2494 - kl_loss: 0.0443 - beta: 0.4691 - val_loss: 0.3013 - val_reco_loss: 0.2518 - val_kl_loss: 0.0495 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2780 - reco_loss: 0.2353 - kl_loss: 0.0415 - beta: 0.5232 - val_loss: 0.2820 - val_reco_loss: 0.2369 - val_kl_loss: 0.0451 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.2563 - reco_loss: 0.2179 - kl_loss: 0.0370 - beta: 0.5761\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2561 - reco_loss: 0.2178 - kl_loss: 0.0370 - beta: 0.5773 - val_loss: 0.2559 - val_reco_loss: 0.2118 - val_kl_loss: 0.0441 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2313 - reco_loss: 0.1983 - kl_loss: 0.0319 - beta: 0.6311 - val_loss: 0.2308 - val_reco_loss: 0.1986 - val_kl_loss: 0.0322 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2084 - reco_loss: 0.1804 - kl_loss: 0.0267 - beta: 0.6852 - val_loss: 0.1980 - val_reco_loss: 0.1656 - val_kl_loss: 0.0324 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2590 - reco_loss: 0.2351 - kl_loss: 0.0306 - beta: 0.1387 - val_loss: 0.3683 - val_reco_loss: 0.3183 - val_kl_loss: 0.0500 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3564 - reco_loss: 0.3077 - kl_loss: 0.0504 - beta: 0.1929 - val_loss: 0.3625 - val_reco_loss: 0.3034 - val_kl_loss: 0.0591 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3466 - reco_loss: 0.2926 - kl_loss: 0.0542 - beta: 0.2472 - val_loss: 0.3573 - val_reco_loss: 0.2972 - val_kl_loss: 0.0601 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3410 - reco_loss: 0.2867 - kl_loss: 0.0535 - beta: 0.3014 - val_loss: 0.3461 - val_reco_loss: 0.2851 - val_kl_loss: 0.0611 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3284 - reco_loss: 0.2767 - kl_loss: 0.0509 - beta: 0.3555 - val_loss: 0.3402 - val_reco_loss: 0.2784 - val_kl_loss: 0.0618 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3147 - reco_loss: 0.2658 - kl_loss: 0.0482 - beta: 0.4097 - val_loss: 0.3197 - val_reco_loss: 0.2625 - val_kl_loss: 0.0573 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2956 - reco_loss: 0.2492 - kl_loss: 0.0455 - beta: 0.4638 - val_loss: 0.3058 - val_reco_loss: 0.2570 - val_kl_loss: 0.0488 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2772 - reco_loss: 0.2343 - kl_loss: 0.0420 - beta: 0.5172\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2771 - reco_loss: 0.2343 - kl_loss: 0.0420 - beta: 0.5179 - val_loss: 0.2758 - val_reco_loss: 0.2311 - val_kl_loss: 0.0447 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 8s 11ms/step - loss: 0.9244 - reco_loss: 0.9007 - kl_loss: 0.0344 - beta: 0.1545 - val_loss: 0.6155 - val_reco_loss: 0.5662 - val_kl_loss: 0.0492 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5856 - reco_loss: 0.5357 - kl_loss: 0.0517 - beta: 0.2086 - val_loss: 0.5009 - val_reco_loss: 0.4421 - val_kl_loss: 0.0588 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4795 - reco_loss: 0.4255 - kl_loss: 0.0539 - beta: 0.2628 - val_loss: 0.4408 - val_reco_loss: 0.3799 - val_kl_loss: 0.0609 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4272 - reco_loss: 0.3747 - kl_loss: 0.0513 - beta: 0.3171 - val_loss: 0.4002 - val_reco_loss: 0.3491 - val_kl_loss: 0.0511 - val_beta: 0.3171 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4063 - reco_loss: 0.3585 - kl_loss: 0.0471 - beta: 0.3713 - val_loss: 0.3631 - val_reco_loss: 0.3132 - val_kl_loss: 0.0499 - val_beta: 0.3713 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3686 - reco_loss: 0.3250 - kl_loss: 0.0430 - beta: 0.4252 - val_loss: 0.3305 - val_reco_loss: 0.2805 - val_kl_loss: 0.0500 - val_beta: 0.4252 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 0.3352 - reco_loss: 0.2943 - kl_loss: 0.0402 - beta: 0.4795 - val_loss: 0.2973 - val_reco_loss: 0.2522 - val_kl_loss: 0.0452 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3105 - reco_loss: 0.2731 - kl_loss: 0.0364 - beta: 0.5335 - val_loss: 0.2771 - val_reco_loss: 0.2347 - val_kl_loss: 0.0424 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2790 - reco_loss: 0.2461 - kl_loss: 0.0317 - beta: 0.5876 - val_loss: 0.2614 - val_reco_loss: 0.2244 - val_kl_loss: 0.0370 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2468 - reco_loss: 0.2184 - kl_loss: 0.0271 - beta: 0.6417 - val_loss: 0.2263 - val_reco_loss: 0.1961 - val_kl_loss: 0.0303 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2183 - reco_loss: 0.1948 - kl_loss: 0.0222 - beta: 0.6959 - val_loss: 0.1950 - val_reco_loss: 0.1671 - val_kl_loss: 0.0279 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3596 - reco_loss: 0.3343 - kl_loss: 0.0363 - beta: 0.1490 - val_loss: 0.3641 - val_reco_loss: 0.3094 - val_kl_loss: 0.0546 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3753 - reco_loss: 0.3239 - kl_loss: 0.0523 - beta: 0.2033 - val_loss: 0.3573 - val_reco_loss: 0.2935 - val_kl_loss: 0.0638 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3712 - reco_loss: 0.3172 - kl_loss: 0.0539 - beta: 0.2577 - val_loss: 0.3567 - val_reco_loss: 0.2963 - val_kl_loss: 0.0603 - val_beta: 0.2577 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3677 - reco_loss: 0.3151 - kl_loss: 0.0516 - beta: 0.3119 - val_loss: 0.3287 - val_reco_loss: 0.2718 - val_kl_loss: 0.0569 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3450 - reco_loss: 0.2963 - kl_loss: 0.0481 - beta: 0.3662 - val_loss: 0.3296 - val_reco_loss: 0.2826 - val_kl_loss: 0.0470 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3264 - reco_loss: 0.2807 - kl_loss: 0.0451 - beta: 0.4204 - val_loss: 0.3091 - val_reco_loss: 0.2570 - val_kl_loss: 0.0521 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3012 - reco_loss: 0.2585 - kl_loss: 0.0425 - beta: 0.4745 - val_loss: 0.2912 - val_reco_loss: 0.2398 - val_kl_loss: 0.0514 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2839 - reco_loss: 0.2441 - kl_loss: 0.0391 - beta: 0.5286 - val_loss: 0.2660 - val_reco_loss: 0.2211 - val_kl_loss: 0.0449 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2593 - reco_loss: 0.2233 - kl_loss: 0.0347 - beta: 0.5827 - val_loss: 0.2493 - val_reco_loss: 0.2044 - val_kl_loss: 0.0448 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2366 - reco_loss: 0.2052 - kl_loss: 0.0299 - beta: 0.6352\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2364 - reco_loss: 0.2050 - kl_loss: 0.0298 - beta: 0.6367 - val_loss: 0.2228 - val_reco_loss: 0.1903 - val_kl_loss: 0.0325 - val_beta: 0.6367 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2093 - reco_loss: 0.1829 - kl_loss: 0.0250 - beta: 0.6905 - val_loss: 0.1999 - val_reco_loss: 0.1729 - val_kl_loss: 0.0271 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2966 - reco_loss: 0.2719 - kl_loss: 0.0337 - beta: 0.1439 - val_loss: 0.3501 - val_reco_loss: 0.2996 - val_kl_loss: 0.0505 - val_beta: 0.1439 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3668 - reco_loss: 0.3162 - kl_loss: 0.0518 - beta: 0.1980 - val_loss: 0.3533 - val_reco_loss: 0.2951 - val_kl_loss: 0.0582 - val_beta: 0.1980 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3607 - reco_loss: 0.3065 - kl_loss: 0.0543 - beta: 0.2523 - val_loss: 0.3504 - val_reco_loss: 0.2913 - val_kl_loss: 0.0591 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3485 - reco_loss: 0.2950 - kl_loss: 0.0528 - beta: 0.3066 - val_loss: 0.3380 - val_reco_loss: 0.2788 - val_kl_loss: 0.0592 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3334 - reco_loss: 0.2824 - kl_loss: 0.0498 - beta: 0.3608 - val_loss: 0.3263 - val_reco_loss: 0.2677 - val_kl_loss: 0.0586 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3172 - reco_loss: 0.2690 - kl_loss: 0.0475 - beta: 0.4150 - val_loss: 0.3112 - val_reco_loss: 0.2526 - val_kl_loss: 0.0587 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3000 - reco_loss: 0.2544 - kl_loss: 0.0448 - beta: 0.4691 - val_loss: 0.2874 - val_reco_loss: 0.2356 - val_kl_loss: 0.0518 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2781 - reco_loss: 0.2360 - kl_loss: 0.0409 - beta: 0.5232 - val_loss: 0.2822 - val_reco_loss: 0.2373 - val_kl_loss: 0.0449 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2583 - reco_loss: 0.2202 - kl_loss: 0.0368 - beta: 0.5756\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2581 - reco_loss: 0.2200 - kl_loss: 0.0367 - beta: 0.5773 - val_loss: 0.2474 - val_reco_loss: 0.2030 - val_kl_loss: 0.0444 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2339 - reco_loss: 0.2000 - kl_loss: 0.0323 - beta: 0.6311 - val_loss: 0.2205 - val_reco_loss: 0.1805 - val_kl_loss: 0.0400 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2085 - reco_loss: 0.1797 - kl_loss: 0.0271 - beta: 0.6852 - val_loss: 0.1951 - val_reco_loss: 0.1631 - val_kl_loss: 0.0320 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2630 - reco_loss: 0.2389 - kl_loss: 0.0304 - beta: 0.1387 - val_loss: 0.3517 - val_reco_loss: 0.3008 - val_kl_loss: 0.0508 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3576 - reco_loss: 0.3088 - kl_loss: 0.0506 - beta: 0.1929 - val_loss: 0.3499 - val_reco_loss: 0.2905 - val_kl_loss: 0.0595 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3466 - reco_loss: 0.2930 - kl_loss: 0.0541 - beta: 0.2472 - val_loss: 0.3453 - val_reco_loss: 0.2853 - val_kl_loss: 0.0600 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3403 - reco_loss: 0.2861 - kl_loss: 0.0538 - beta: 0.3014 - val_loss: 0.3300 - val_reco_loss: 0.2708 - val_kl_loss: 0.0592 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3298 - reco_loss: 0.2781 - kl_loss: 0.0510 - beta: 0.3555 - val_loss: 0.3207 - val_reco_loss: 0.2615 - val_kl_loss: 0.0593 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3126 - reco_loss: 0.2636 - kl_loss: 0.0484 - beta: 0.4097 - val_loss: 0.3019 - val_reco_loss: 0.2454 - val_kl_loss: 0.0564 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2975 - reco_loss: 0.2507 - kl_loss: 0.0456 - beta: 0.4638 - val_loss: 0.2972 - val_reco_loss: 0.2452 - val_kl_loss: 0.0521 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2774 - reco_loss: 0.2344 - kl_loss: 0.0421 - beta: 0.5176\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2774 - reco_loss: 0.2344 - kl_loss: 0.0421 - beta: 0.5179 - val_loss: 0.2724 - val_reco_loss: 0.2228 - val_kl_loss: 0.0496 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 7s 9ms/step - loss: 1.0345 - reco_loss: 1.0223 - kl_loss: 0.0168 - beta: 0.1545 - val_loss: 0.6980 - val_reco_loss: 0.6676 - val_kl_loss: 0.0304 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.6095 - reco_loss: 0.5755 - kl_loss: 0.0368 - beta: 0.2086 - val_loss: 0.5495 - val_reco_loss: 0.5060 - val_kl_loss: 0.0435 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5231 - reco_loss: 0.4809 - kl_loss: 0.0431 - beta: 0.2627 - val_loss: 0.4507 - val_reco_loss: 0.3992 - val_kl_loss: 0.0515 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4459 - reco_loss: 0.4007 - kl_loss: 0.0455 - beta: 0.3170 - val_loss: 0.4030 - val_reco_loss: 0.3492 - val_kl_loss: 0.0538 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3960 - reco_loss: 0.3507 - kl_loss: 0.0449 - beta: 0.3710 - val_loss: 0.3614 - val_reco_loss: 0.3113 - val_kl_loss: 0.0501 - val_beta: 0.3710 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3628 - reco_loss: 0.3196 - kl_loss: 0.0425 - beta: 0.4253 - val_loss: 0.3275 - val_reco_loss: 0.2775 - val_kl_loss: 0.0500 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3324 - reco_loss: 0.2922 - kl_loss: 0.0393 - beta: 0.4793 - val_loss: 0.3031 - val_reco_loss: 0.2593 - val_kl_loss: 0.0439 - val_beta: 0.4793 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2972 - reco_loss: 0.2619 - kl_loss: 0.0352 - beta: 0.5335 - val_loss: 0.2864 - val_reco_loss: 0.2446 - val_kl_loss: 0.0419 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2776 - reco_loss: 0.2450 - kl_loss: 0.0309 - beta: 0.5877 - val_loss: 0.2544 - val_reco_loss: 0.2183 - val_kl_loss: 0.0361 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2452 - reco_loss: 0.2179 - kl_loss: 0.0263 - beta: 0.6417 - val_loss: 0.2217 - val_reco_loss: 0.1940 - val_kl_loss: 0.0278 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2144 - reco_loss: 0.1917 - kl_loss: 0.0219 - beta: 0.6958 - val_loss: 0.2004 - val_reco_loss: 0.1747 - val_kl_loss: 0.0257 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3530 - reco_loss: 0.3278 - kl_loss: 0.0360 - beta: 0.1490 - val_loss: 0.3832 - val_reco_loss: 0.3305 - val_kl_loss: 0.0527 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3827 - reco_loss: 0.3323 - kl_loss: 0.0513 - beta: 0.2034 - val_loss: 0.3727 - val_reco_loss: 0.3165 - val_kl_loss: 0.0562 - val_beta: 0.2034 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3723 - reco_loss: 0.3192 - kl_loss: 0.0530 - beta: 0.2576 - val_loss: 0.3608 - val_reco_loss: 0.3008 - val_kl_loss: 0.0600 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3584 - reco_loss: 0.3063 - kl_loss: 0.0512 - beta: 0.3120 - val_loss: 0.3521 - val_reco_loss: 0.2965 - val_kl_loss: 0.0556 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3402 - reco_loss: 0.2912 - kl_loss: 0.0482 - beta: 0.3662 - val_loss: 0.3360 - val_reco_loss: 0.2841 - val_kl_loss: 0.0520 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3228 - reco_loss: 0.2767 - kl_loss: 0.0452 - beta: 0.4204 - val_loss: 0.3150 - val_reco_loss: 0.2698 - val_kl_loss: 0.0452 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3063 - reco_loss: 0.2635 - kl_loss: 0.0417 - beta: 0.4745 - val_loss: 0.2945 - val_reco_loss: 0.2532 - val_kl_loss: 0.0413 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2823 - reco_loss: 0.2431 - kl_loss: 0.0385 - beta: 0.5286 - val_loss: 0.2845 - val_reco_loss: 0.2427 - val_kl_loss: 0.0418 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2601 - reco_loss: 0.2252 - kl_loss: 0.0334 - beta: 0.5827 - val_loss: 0.2449 - val_reco_loss: 0.2115 - val_kl_loss: 0.0334 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2349 - reco_loss: 0.2050 - kl_loss: 0.0286 - beta: 0.6352\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2346 - reco_loss: 0.2048 - kl_loss: 0.0286 - beta: 0.6368 - val_loss: 0.2196 - val_reco_loss: 0.1855 - val_kl_loss: 0.0341 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2081 - reco_loss: 0.1831 - kl_loss: 0.0243 - beta: 0.6905 - val_loss: 0.2002 - val_reco_loss: 0.1732 - val_kl_loss: 0.0271 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2941 - reco_loss: 0.2697 - kl_loss: 0.0332 - beta: 0.1438 - val_loss: 0.3698 - val_reco_loss: 0.3212 - val_kl_loss: 0.0486 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3627 - reco_loss: 0.3126 - kl_loss: 0.0516 - beta: 0.1981 - val_loss: 0.3685 - val_reco_loss: 0.3135 - val_kl_loss: 0.0550 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3532 - reco_loss: 0.2984 - kl_loss: 0.0550 - beta: 0.2523 - val_loss: 0.3542 - val_reco_loss: 0.2925 - val_kl_loss: 0.0616 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3458 - reco_loss: 0.2913 - kl_loss: 0.0535 - beta: 0.3066 - val_loss: 0.3411 - val_reco_loss: 0.2800 - val_kl_loss: 0.0611 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3292 - reco_loss: 0.2785 - kl_loss: 0.0499 - beta: 0.3608 - val_loss: 0.3351 - val_reco_loss: 0.2789 - val_kl_loss: 0.0562 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3128 - reco_loss: 0.2652 - kl_loss: 0.0469 - beta: 0.4150 - val_loss: 0.3120 - val_reco_loss: 0.2631 - val_kl_loss: 0.0489 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2999 - reco_loss: 0.2545 - kl_loss: 0.0441 - beta: 0.4691 - val_loss: 0.2935 - val_reco_loss: 0.2444 - val_kl_loss: 0.0491 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2760 - reco_loss: 0.2350 - kl_loss: 0.0401 - beta: 0.5232 - val_loss: 0.2719 - val_reco_loss: 0.2278 - val_kl_loss: 0.0440 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2547 - reco_loss: 0.2180 - kl_loss: 0.0358 - beta: 0.5773 - val_loss: 0.2558 - val_reco_loss: 0.2158 - val_kl_loss: 0.0401 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2310 - reco_loss: 0.1988 - kl_loss: 0.0311 - beta: 0.6307\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2310 - reco_loss: 0.1987 - kl_loss: 0.0311 - beta: 0.6314 - val_loss: 0.2256 - val_reco_loss: 0.1921 - val_kl_loss: 0.0336 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2056 - reco_loss: 0.1784 - kl_loss: 0.0261 - beta: 0.6852 - val_loss: 0.1977 - val_reco_loss: 0.1719 - val_kl_loss: 0.0258 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2631 - reco_loss: 0.2392 - kl_loss: 0.0300 - beta: 0.1388 - val_loss: 0.3671 - val_reco_loss: 0.3208 - val_kl_loss: 0.0463 - val_beta: 0.1388 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3567 - reco_loss: 0.3087 - kl_loss: 0.0502 - beta: 0.1929 - val_loss: 0.3600 - val_reco_loss: 0.2979 - val_kl_loss: 0.0621 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3483 - reco_loss: 0.2937 - kl_loss: 0.0549 - beta: 0.2472 - val_loss: 0.3568 - val_reco_loss: 0.2955 - val_kl_loss: 0.0612 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3365 - reco_loss: 0.2822 - kl_loss: 0.0539 - beta: 0.3014 - val_loss: 0.3427 - val_reco_loss: 0.2807 - val_kl_loss: 0.0620 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3273 - reco_loss: 0.2761 - kl_loss: 0.0504 - beta: 0.3556 - val_loss: 0.3306 - val_reco_loss: 0.2733 - val_kl_loss: 0.0573 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3136 - reco_loss: 0.2657 - kl_loss: 0.0476 - beta: 0.4097 - val_loss: 0.3169 - val_reco_loss: 0.2592 - val_kl_loss: 0.0577 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2950 - reco_loss: 0.2487 - kl_loss: 0.0449 - beta: 0.4638 - val_loss: 0.2906 - val_reco_loss: 0.2440 - val_kl_loss: 0.0466 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2756 - reco_loss: 0.2332 - kl_loss: 0.0413 - beta: 0.5179 - val_loss: 0.2775 - val_reco_loss: 0.2340 - val_kl_loss: 0.0435 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2554 - reco_loss: 0.2174 - kl_loss: 0.0373 - beta: 0.5720 - val_loss: 0.2525 - val_reco_loss: 0.2122 - val_kl_loss: 0.0403 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2330 - reco_loss: 0.1993 - kl_loss: 0.0326 - beta: 0.6245\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2328 - reco_loss: 0.1991 - kl_loss: 0.0325 - beta: 0.6261 - val_loss: 0.2269 - val_reco_loss: 0.1923 - val_kl_loss: 0.0346 - val_beta: 0.6261 - lr: 4.9000e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2084 - reco_loss: 0.1796 - kl_loss: 0.0279 - beta: 0.6800 - val_loss: 0.2039 - val_reco_loss: 0.1733 - val_kl_loss: 0.0306 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2397 - reco_loss: 0.2159 - kl_loss: 0.0267 - beta: 0.1337 - val_loss: 0.3707 - val_reco_loss: 0.3271 - val_kl_loss: 0.0436 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3533 - reco_loss: 0.3073 - kl_loss: 0.0488 - beta: 0.1878 - val_loss: 0.3611 - val_reco_loss: 0.3058 - val_kl_loss: 0.0553 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3428 - reco_loss: 0.2892 - kl_loss: 0.0546 - beta: 0.2420 - val_loss: 0.3514 - val_reco_loss: 0.2905 - val_kl_loss: 0.0609 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3389 - reco_loss: 0.2846 - kl_loss: 0.0539 - beta: 0.2962 - val_loss: 0.3506 - val_reco_loss: 0.2943 - val_kl_loss: 0.0563 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3243 - reco_loss: 0.2725 - kl_loss: 0.0510 - beta: 0.3503 - val_loss: 0.3290 - val_reco_loss: 0.2710 - val_kl_loss: 0.0580 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3138 - reco_loss: 0.2644 - kl_loss: 0.0482 - beta: 0.4045 - val_loss: 0.3151 - val_reco_loss: 0.2607 - val_kl_loss: 0.0544 - val_beta: 0.4045 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2934 - reco_loss: 0.2476 - kl_loss: 0.0454 - beta: 0.4586 - val_loss: 0.2875 - val_reco_loss: 0.2367 - val_kl_loss: 0.0507 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2768 - reco_loss: 0.2332 - kl_loss: 0.0428 - beta: 0.5127 - val_loss: 0.2808 - val_reco_loss: 0.2343 - val_kl_loss: 0.0466 - val_beta: 0.5127 - lr: 3.4300e-04\n",
      "Epoch 53/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.2549 - reco_loss: 0.2159 - kl_loss: 0.0383 - beta: 0.5654\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2548 - reco_loss: 0.2158 - kl_loss: 0.0383 - beta: 0.5667 - val_loss: 0.2582 - val_reco_loss: 0.2157 - val_kl_loss: 0.0425 - val_beta: 0.5667 - lr: 3.4300e-04\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2330 - reco_loss: 0.1985 - kl_loss: 0.0342 - beta: 0.6207 - val_loss: 0.2337 - val_reco_loss: 0.1958 - val_kl_loss: 0.0379 - val_beta: 0.6207 - lr: 2.4010e-04\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2104 - reco_loss: 0.1793 - kl_loss: 0.0298 - beta: 0.6748 - val_loss: 0.2046 - val_reco_loss: 0.1722 - val_kl_loss: 0.0323 - val_beta: 0.6748 - lr: 2.4010e-04\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2264 - reco_loss: 0.2016 - kl_loss: 0.0242 - beta: 0.1286 - val_loss: 0.3745 - val_reco_loss: 0.3346 - val_kl_loss: 0.0399 - val_beta: 0.1286 - lr: 2.4010e-04\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3517 - reco_loss: 0.3085 - kl_loss: 0.0469 - beta: 0.1827 - val_loss: 0.3639 - val_reco_loss: 0.3113 - val_kl_loss: 0.0526 - val_beta: 0.1827 - lr: 2.4010e-04\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3439 - reco_loss: 0.2908 - kl_loss: 0.0540 - beta: 0.2369 - val_loss: 0.3539 - val_reco_loss: 0.2942 - val_kl_loss: 0.0597 - val_beta: 0.2369 - lr: 2.4010e-04\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3382 - reco_loss: 0.2830 - kl_loss: 0.0545 - beta: 0.2910 - val_loss: 0.3412 - val_reco_loss: 0.2797 - val_kl_loss: 0.0615 - val_beta: 0.2910 - lr: 2.4010e-04\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3248 - reco_loss: 0.2724 - kl_loss: 0.0519 - beta: 0.3451 - val_loss: 0.3346 - val_reco_loss: 0.2756 - val_kl_loss: 0.0590 - val_beta: 0.3451 - lr: 2.4010e-04\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3142 - reco_loss: 0.2643 - kl_loss: 0.0490 - beta: 0.3993 - val_loss: 0.3271 - val_reco_loss: 0.2726 - val_kl_loss: 0.0545 - val_beta: 0.3993 - lr: 2.4010e-04\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2980 - reco_loss: 0.2507 - kl_loss: 0.0465 - beta: 0.4534 - val_loss: 0.3008 - val_reco_loss: 0.2501 - val_kl_loss: 0.0507 - val_beta: 0.4534 - lr: 2.4010e-04\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2790 - reco_loss: 0.2349 - kl_loss: 0.0432 - beta: 0.5075\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2790 - reco_loss: 0.2349 - kl_loss: 0.0432 - beta: 0.5075 - val_loss: 0.2888 - val_reco_loss: 0.2377 - val_kl_loss: 0.0511 - val_beta: 0.5075 - lr: 2.4010e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.9177 - reco_loss: 0.9054 - kl_loss: 0.0239 - beta: 0.1543 - val_loss: 0.5848 - val_reco_loss: 0.5348 - val_kl_loss: 0.0500 - val_beta: 0.1543 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5426 - reco_loss: 0.4929 - kl_loss: 0.0516 - beta: 0.2086 - val_loss: 0.4880 - val_reco_loss: 0.4274 - val_kl_loss: 0.0606 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4724 - reco_loss: 0.4175 - kl_loss: 0.0550 - beta: 0.2628 - val_loss: 0.4266 - val_reco_loss: 0.3668 - val_kl_loss: 0.0599 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4210 - reco_loss: 0.3678 - kl_loss: 0.0522 - beta: 0.3169 - val_loss: 0.3791 - val_reco_loss: 0.3240 - val_kl_loss: 0.0552 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3857 - reco_loss: 0.3367 - kl_loss: 0.0479 - beta: 0.3711 - val_loss: 0.3578 - val_reco_loss: 0.3027 - val_kl_loss: 0.0551 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3544 - reco_loss: 0.3092 - kl_loss: 0.0445 - beta: 0.4254 - val_loss: 0.3293 - val_reco_loss: 0.2823 - val_kl_loss: 0.0469 - val_beta: 0.4254 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3355 - reco_loss: 0.2942 - kl_loss: 0.0404 - beta: 0.4794 - val_loss: 0.3013 - val_reco_loss: 0.2593 - val_kl_loss: 0.0420 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3087 - reco_loss: 0.2705 - kl_loss: 0.0370 - beta: 0.5335 - val_loss: 0.2690 - val_reco_loss: 0.2291 - val_kl_loss: 0.0399 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2697 - reco_loss: 0.2363 - kl_loss: 0.0323 - beta: 0.5877 - val_loss: 0.2600 - val_reco_loss: 0.2244 - val_kl_loss: 0.0356 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2421 - reco_loss: 0.2136 - kl_loss: 0.0274 - beta: 0.6418 - val_loss: 0.2370 - val_reco_loss: 0.2052 - val_kl_loss: 0.0318 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2143 - reco_loss: 0.1897 - kl_loss: 0.0230 - beta: 0.6958 - val_loss: 0.1967 - val_reco_loss: 0.1720 - val_kl_loss: 0.0246 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3484 - reco_loss: 0.3222 - kl_loss: 0.0373 - beta: 0.1489 - val_loss: 0.3709 - val_reco_loss: 0.3176 - val_kl_loss: 0.0534 - val_beta: 0.1489 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3804 - reco_loss: 0.3292 - kl_loss: 0.0527 - beta: 0.2033 - val_loss: 0.3682 - val_reco_loss: 0.3109 - val_kl_loss: 0.0573 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3676 - reco_loss: 0.3132 - kl_loss: 0.0544 - beta: 0.2576 - val_loss: 0.3616 - val_reco_loss: 0.2969 - val_kl_loss: 0.0647 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3515 - reco_loss: 0.2974 - kl_loss: 0.0531 - beta: 0.3119 - val_loss: 0.3394 - val_reco_loss: 0.2827 - val_kl_loss: 0.0567 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3369 - reco_loss: 0.2857 - kl_loss: 0.0502 - beta: 0.3662 - val_loss: 0.3292 - val_reco_loss: 0.2695 - val_kl_loss: 0.0597 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3207 - reco_loss: 0.2724 - kl_loss: 0.0472 - beta: 0.4203 - val_loss: 0.3079 - val_reco_loss: 0.2538 - val_kl_loss: 0.0541 - val_beta: 0.4203 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2999 - reco_loss: 0.2547 - kl_loss: 0.0443 - beta: 0.4745 - val_loss: 0.2888 - val_reco_loss: 0.2365 - val_kl_loss: 0.0522 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2784 - reco_loss: 0.2367 - kl_loss: 0.0405 - beta: 0.5286 - val_loss: 0.2736 - val_reco_loss: 0.2258 - val_kl_loss: 0.0477 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2552 - reco_loss: 0.2179 - kl_loss: 0.0362 - beta: 0.5827 - val_loss: 0.2448 - val_reco_loss: 0.2037 - val_kl_loss: 0.0411 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2317 - reco_loss: 0.1998 - kl_loss: 0.0305 - beta: 0.6363\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2316 - reco_loss: 0.1998 - kl_loss: 0.0305 - beta: 0.6368 - val_loss: 0.2195 - val_reco_loss: 0.1835 - val_kl_loss: 0.0360 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2045 - reco_loss: 0.1779 - kl_loss: 0.0258 - beta: 0.6905 - val_loss: 0.2012 - val_reco_loss: 0.1726 - val_kl_loss: 0.0286 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2907 - reco_loss: 0.2657 - kl_loss: 0.0335 - beta: 0.1438 - val_loss: 0.3604 - val_reco_loss: 0.3078 - val_kl_loss: 0.0526 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3559 - reco_loss: 0.3058 - kl_loss: 0.0516 - beta: 0.1981 - val_loss: 0.3583 - val_reco_loss: 0.3018 - val_kl_loss: 0.0565 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3529 - reco_loss: 0.2988 - kl_loss: 0.0542 - beta: 0.2524 - val_loss: 0.3451 - val_reco_loss: 0.2815 - val_kl_loss: 0.0636 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3418 - reco_loss: 0.2878 - kl_loss: 0.0533 - beta: 0.3066 - val_loss: 0.3365 - val_reco_loss: 0.2722 - val_kl_loss: 0.0644 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3302 - reco_loss: 0.2791 - kl_loss: 0.0506 - beta: 0.3608 - val_loss: 0.3236 - val_reco_loss: 0.2649 - val_kl_loss: 0.0587 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3149 - reco_loss: 0.2663 - kl_loss: 0.0476 - beta: 0.4150 - val_loss: 0.3042 - val_reco_loss: 0.2492 - val_kl_loss: 0.0549 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2929 - reco_loss: 0.2478 - kl_loss: 0.0449 - beta: 0.4691 - val_loss: 0.2886 - val_reco_loss: 0.2359 - val_kl_loss: 0.0527 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2739 - reco_loss: 0.2313 - kl_loss: 0.0417 - beta: 0.5232 - val_loss: 0.2785 - val_reco_loss: 0.2320 - val_kl_loss: 0.0465 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2535 - reco_loss: 0.2160 - kl_loss: 0.0368 - beta: 0.5763\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2534 - reco_loss: 0.2159 - kl_loss: 0.0367 - beta: 0.5773 - val_loss: 0.2525 - val_reco_loss: 0.2093 - val_kl_loss: 0.0432 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2314 - reco_loss: 0.1980 - kl_loss: 0.0323 - beta: 0.6311 - val_loss: 0.2238 - val_reco_loss: 0.1868 - val_kl_loss: 0.0370 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2084 - reco_loss: 0.1790 - kl_loss: 0.0277 - beta: 0.6852 - val_loss: 0.1928 - val_reco_loss: 0.1594 - val_kl_loss: 0.0333 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2604 - reco_loss: 0.2357 - kl_loss: 0.0307 - beta: 0.1387 - val_loss: 0.3586 - val_reco_loss: 0.3097 - val_kl_loss: 0.0489 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3520 - reco_loss: 0.3038 - kl_loss: 0.0503 - beta: 0.1929 - val_loss: 0.3483 - val_reco_loss: 0.2886 - val_kl_loss: 0.0597 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3456 - reco_loss: 0.2910 - kl_loss: 0.0548 - beta: 0.2471 - val_loss: 0.3412 - val_reco_loss: 0.2794 - val_kl_loss: 0.0618 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3373 - reco_loss: 0.2829 - kl_loss: 0.0539 - beta: 0.3014 - val_loss: 0.3387 - val_reco_loss: 0.2768 - val_kl_loss: 0.0619 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3272 - reco_loss: 0.2748 - kl_loss: 0.0513 - beta: 0.3555 - val_loss: 0.3237 - val_reco_loss: 0.2669 - val_kl_loss: 0.0568 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3095 - reco_loss: 0.2600 - kl_loss: 0.0491 - beta: 0.4097 - val_loss: 0.3094 - val_reco_loss: 0.2534 - val_kl_loss: 0.0560 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2967 - reco_loss: 0.2493 - kl_loss: 0.0465 - beta: 0.4638 - val_loss: 0.2922 - val_reco_loss: 0.2432 - val_kl_loss: 0.0490 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2747 - reco_loss: 0.2309 - kl_loss: 0.0431 - beta: 0.5179 - val_loss: 0.2691 - val_reco_loss: 0.2202 - val_kl_loss: 0.0489 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2551 - reco_loss: 0.2155 - kl_loss: 0.0383 - beta: 0.5720 - val_loss: 0.2546 - val_reco_loss: 0.2127 - val_kl_loss: 0.0419 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2321 - reco_loss: 0.1978 - kl_loss: 0.0331 - beta: 0.6256\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2320 - reco_loss: 0.1977 - kl_loss: 0.0331 - beta: 0.6261 - val_loss: 0.2296 - val_reco_loss: 0.1935 - val_kl_loss: 0.0361 - val_beta: 0.6261 - lr: 4.9000e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2088 - reco_loss: 0.1792 - kl_loss: 0.0283 - beta: 0.6800 - val_loss: 0.2108 - val_reco_loss: 0.1777 - val_kl_loss: 0.0331 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2401 - reco_loss: 0.2158 - kl_loss: 0.0278 - beta: 0.1337 - val_loss: 0.3605 - val_reco_loss: 0.3148 - val_kl_loss: 0.0457 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3491 - reco_loss: 0.3026 - kl_loss: 0.0490 - beta: 0.1878 - val_loss: 0.3493 - val_reco_loss: 0.2946 - val_kl_loss: 0.0547 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3443 - reco_loss: 0.2907 - kl_loss: 0.0544 - beta: 0.2420 - val_loss: 0.3364 - val_reco_loss: 0.2722 - val_kl_loss: 0.0642 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3379 - reco_loss: 0.2829 - kl_loss: 0.0544 - beta: 0.2962 - val_loss: 0.3316 - val_reco_loss: 0.2698 - val_kl_loss: 0.0618 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3248 - reco_loss: 0.2719 - kl_loss: 0.0521 - beta: 0.3503 - val_loss: 0.3243 - val_reco_loss: 0.2675 - val_kl_loss: 0.0568 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3135 - reco_loss: 0.2640 - kl_loss: 0.0492 - beta: 0.4044 - val_loss: 0.3065 - val_reco_loss: 0.2537 - val_kl_loss: 0.0528 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2953 - reco_loss: 0.2479 - kl_loss: 0.0468 - beta: 0.4586 - val_loss: 0.2895 - val_reco_loss: 0.2360 - val_kl_loss: 0.0535 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2770 - reco_loss: 0.2325 - kl_loss: 0.0434 - beta: 0.5127 - val_loss: 0.2728 - val_reco_loss: 0.2234 - val_kl_loss: 0.0495 - val_beta: 0.5127 - lr: 3.4300e-04\n",
      "Epoch 53/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2536 - reco_loss: 0.2138 - kl_loss: 0.0390 - beta: 0.5662\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2536 - reco_loss: 0.2138 - kl_loss: 0.0389 - beta: 0.5667 - val_loss: 0.2507 - val_reco_loss: 0.2055 - val_kl_loss: 0.0452 - val_beta: 0.5667 - lr: 3.4300e-04\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2334 - reco_loss: 0.1982 - kl_loss: 0.0344 - beta: 0.6207 - val_loss: 0.2317 - val_reco_loss: 0.1934 - val_kl_loss: 0.0383 - val_beta: 0.6207 - lr: 2.4010e-04\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2117 - reco_loss: 0.1806 - kl_loss: 0.0298 - beta: 0.6748 - val_loss: 0.2007 - val_reco_loss: 0.1641 - val_kl_loss: 0.0366 - val_beta: 0.6748 - lr: 2.4010e-04\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2219 - reco_loss: 0.1969 - kl_loss: 0.0263 - beta: 0.1286 - val_loss: 0.3519 - val_reco_loss: 0.3089 - val_kl_loss: 0.0430 - val_beta: 0.1286 - lr: 2.4010e-04\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3521 - reco_loss: 0.3082 - kl_loss: 0.0470 - beta: 0.1827 - val_loss: 0.3446 - val_reco_loss: 0.2881 - val_kl_loss: 0.0565 - val_beta: 0.1827 - lr: 2.4010e-04\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3462 - reco_loss: 0.2935 - kl_loss: 0.0534 - beta: 0.2369 - val_loss: 0.3383 - val_reco_loss: 0.2764 - val_kl_loss: 0.0619 - val_beta: 0.2369 - lr: 2.4010e-04\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3394 - reco_loss: 0.2849 - kl_loss: 0.0542 - beta: 0.2910 - val_loss: 0.3323 - val_reco_loss: 0.2677 - val_kl_loss: 0.0646 - val_beta: 0.2910 - lr: 2.4010e-04\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3293 - reco_loss: 0.2759 - kl_loss: 0.0526 - beta: 0.3451 - val_loss: 0.3224 - val_reco_loss: 0.2582 - val_kl_loss: 0.0642 - val_beta: 0.3451 - lr: 2.4010e-04\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3117 - reco_loss: 0.2604 - kl_loss: 0.0506 - beta: 0.3993 - val_loss: 0.3014 - val_reco_loss: 0.2435 - val_kl_loss: 0.0579 - val_beta: 0.3993 - lr: 2.4010e-04\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2941 - reco_loss: 0.2457 - kl_loss: 0.0478 - beta: 0.4534 - val_loss: 0.2990 - val_reco_loss: 0.2456 - val_kl_loss: 0.0534 - val_beta: 0.4534 - lr: 2.4010e-04\n",
      "Epoch 63/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2778 - reco_loss: 0.2322 - kl_loss: 0.0455 - beta: 0.5069\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2778 - reco_loss: 0.2321 - kl_loss: 0.0455 - beta: 0.5074 - val_loss: 0.2837 - val_reco_loss: 0.2259 - val_kl_loss: 0.0578 - val_beta: 0.5074 - lr: 2.4010e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 7s 9ms/step - loss: 1.0183 - reco_loss: 1.0050 - kl_loss: 0.0228 - beta: 0.1543 - val_loss: 0.6422 - val_reco_loss: 0.5980 - val_kl_loss: 0.0443 - val_beta: 0.1543 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5459 - reco_loss: 0.4982 - kl_loss: 0.0518 - beta: 0.2085 - val_loss: 0.5236 - val_reco_loss: 0.4614 - val_kl_loss: 0.0622 - val_beta: 0.2085 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4780 - reco_loss: 0.4201 - kl_loss: 0.0573 - beta: 0.2627 - val_loss: 0.4451 - val_reco_loss: 0.3791 - val_kl_loss: 0.0659 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4179 - reco_loss: 0.3634 - kl_loss: 0.0533 - beta: 0.3170 - val_loss: 0.3956 - val_reco_loss: 0.3363 - val_kl_loss: 0.0593 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3866 - reco_loss: 0.3379 - kl_loss: 0.0475 - beta: 0.3712 - val_loss: 0.3580 - val_reco_loss: 0.3040 - val_kl_loss: 0.0540 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3640 - reco_loss: 0.3200 - kl_loss: 0.0430 - beta: 0.4253 - val_loss: 0.3346 - val_reco_loss: 0.2841 - val_kl_loss: 0.0505 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3279 - reco_loss: 0.2887 - kl_loss: 0.0381 - beta: 0.4795 - val_loss: 0.3067 - val_reco_loss: 0.2645 - val_kl_loss: 0.0422 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3004 - reco_loss: 0.2648 - kl_loss: 0.0350 - beta: 0.5335 - val_loss: 0.2796 - val_reco_loss: 0.2439 - val_kl_loss: 0.0357 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2679 - reco_loss: 0.2368 - kl_loss: 0.0309 - beta: 0.5876 - val_loss: 0.2523 - val_reco_loss: 0.2164 - val_kl_loss: 0.0359 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2452 - reco_loss: 0.2173 - kl_loss: 0.0267 - beta: 0.6417 - val_loss: 0.2311 - val_reco_loss: 0.2003 - val_kl_loss: 0.0308 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2164 - reco_loss: 0.1933 - kl_loss: 0.0223 - beta: 0.6959 - val_loss: 0.1982 - val_reco_loss: 0.1739 - val_kl_loss: 0.0244 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3506 - reco_loss: 0.3266 - kl_loss: 0.0352 - beta: 0.1490 - val_loss: 0.3854 - val_reco_loss: 0.3337 - val_kl_loss: 0.0517 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3928 - reco_loss: 0.3408 - kl_loss: 0.0534 - beta: 0.2032 - val_loss: 0.3709 - val_reco_loss: 0.3125 - val_kl_loss: 0.0583 - val_beta: 0.2032 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3694 - reco_loss: 0.3144 - kl_loss: 0.0544 - beta: 0.2576 - val_loss: 0.3509 - val_reco_loss: 0.2899 - val_kl_loss: 0.0610 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3533 - reco_loss: 0.3006 - kl_loss: 0.0517 - beta: 0.3120 - val_loss: 0.3351 - val_reco_loss: 0.2809 - val_kl_loss: 0.0542 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3380 - reco_loss: 0.2890 - kl_loss: 0.0480 - beta: 0.3662 - val_loss: 0.3261 - val_reco_loss: 0.2733 - val_kl_loss: 0.0528 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3163 - reco_loss: 0.2706 - kl_loss: 0.0451 - beta: 0.4204 - val_loss: 0.3132 - val_reco_loss: 0.2713 - val_kl_loss: 0.0419 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2981 - reco_loss: 0.2559 - kl_loss: 0.0420 - beta: 0.4745 - val_loss: 0.2916 - val_reco_loss: 0.2406 - val_kl_loss: 0.0510 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2794 - reco_loss: 0.2391 - kl_loss: 0.0387 - beta: 0.5286 - val_loss: 0.2643 - val_reco_loss: 0.2242 - val_kl_loss: 0.0401 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2542 - reco_loss: 0.2189 - kl_loss: 0.0342 - beta: 0.5827 - val_loss: 0.2450 - val_reco_loss: 0.2064 - val_kl_loss: 0.0386 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2310 - reco_loss: 0.2003 - kl_loss: 0.0296 - beta: 0.6368\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2310 - reco_loss: 0.2003 - kl_loss: 0.0296 - beta: 0.6368 - val_loss: 0.2211 - val_reco_loss: 0.1870 - val_kl_loss: 0.0341 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2040 - reco_loss: 0.1780 - kl_loss: 0.0252 - beta: 0.6905 - val_loss: 0.2003 - val_reco_loss: 0.1723 - val_kl_loss: 0.0281 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2887 - reco_loss: 0.2646 - kl_loss: 0.0322 - beta: 0.1439 - val_loss: 0.3623 - val_reco_loss: 0.3085 - val_kl_loss: 0.0538 - val_beta: 0.1439 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3600 - reco_loss: 0.3105 - kl_loss: 0.0511 - beta: 0.1981 - val_loss: 0.3641 - val_reco_loss: 0.3057 - val_kl_loss: 0.0583 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3493 - reco_loss: 0.2954 - kl_loss: 0.0540 - beta: 0.2523 - val_loss: 0.3480 - val_reco_loss: 0.2856 - val_kl_loss: 0.0623 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3383 - reco_loss: 0.2849 - kl_loss: 0.0524 - beta: 0.3066 - val_loss: 0.3310 - val_reco_loss: 0.2735 - val_kl_loss: 0.0575 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3264 - reco_loss: 0.2762 - kl_loss: 0.0491 - beta: 0.3609 - val_loss: 0.3377 - val_reco_loss: 0.2842 - val_kl_loss: 0.0536 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3119 - reco_loss: 0.2651 - kl_loss: 0.0459 - beta: 0.4150 - val_loss: 0.3150 - val_reco_loss: 0.2598 - val_kl_loss: 0.0553 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2944 - reco_loss: 0.2508 - kl_loss: 0.0431 - beta: 0.4691 - val_loss: 0.2822 - val_reco_loss: 0.2307 - val_kl_loss: 0.0515 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2754 - reco_loss: 0.2344 - kl_loss: 0.0401 - beta: 0.5232 - val_loss: 0.2739 - val_reco_loss: 0.2287 - val_kl_loss: 0.0452 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2519 - reco_loss: 0.2153 - kl_loss: 0.0358 - beta: 0.5770\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2519 - reco_loss: 0.2152 - kl_loss: 0.0358 - beta: 0.5773 - val_loss: 0.2497 - val_reco_loss: 0.2077 - val_kl_loss: 0.0420 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2298 - reco_loss: 0.1972 - kl_loss: 0.0313 - beta: 0.6311 - val_loss: 0.2239 - val_reco_loss: 0.1870 - val_kl_loss: 0.0369 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2040 - reco_loss: 0.1763 - kl_loss: 0.0266 - beta: 0.6852 - val_loss: 0.1984 - val_reco_loss: 0.1682 - val_kl_loss: 0.0302 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2589 - reco_loss: 0.2347 - kl_loss: 0.0304 - beta: 0.1387 - val_loss: 0.3585 - val_reco_loss: 0.3112 - val_kl_loss: 0.0473 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3533 - reco_loss: 0.3043 - kl_loss: 0.0513 - beta: 0.1929 - val_loss: 0.3514 - val_reco_loss: 0.2913 - val_kl_loss: 0.0601 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3452 - reco_loss: 0.2907 - kl_loss: 0.0549 - beta: 0.2471 - val_loss: 0.3448 - val_reco_loss: 0.2821 - val_kl_loss: 0.0627 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3348 - reco_loss: 0.2800 - kl_loss: 0.0544 - beta: 0.3014 - val_loss: 0.3359 - val_reco_loss: 0.2772 - val_kl_loss: 0.0587 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3239 - reco_loss: 0.2727 - kl_loss: 0.0505 - beta: 0.3556 - val_loss: 0.3213 - val_reco_loss: 0.2615 - val_kl_loss: 0.0598 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3109 - reco_loss: 0.2627 - kl_loss: 0.0475 - beta: 0.4097 - val_loss: 0.3067 - val_reco_loss: 0.2522 - val_kl_loss: 0.0544 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2951 - reco_loss: 0.2495 - kl_loss: 0.0448 - beta: 0.4638 - val_loss: 0.2896 - val_reco_loss: 0.2360 - val_kl_loss: 0.0536 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2744 - reco_loss: 0.2319 - kl_loss: 0.0419 - beta: 0.5174\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2743 - reco_loss: 0.2319 - kl_loss: 0.0418 - beta: 0.5179 - val_loss: 0.2726 - val_reco_loss: 0.2238 - val_kl_loss: 0.0488 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.9161 - reco_loss: 0.8999 - kl_loss: 0.0301 - beta: 0.1545 - val_loss: 0.6443 - val_reco_loss: 0.5983 - val_kl_loss: 0.0460 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5715 - reco_loss: 0.5229 - kl_loss: 0.0505 - beta: 0.2086 - val_loss: 0.5247 - val_reco_loss: 0.4642 - val_kl_loss: 0.0605 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4847 - reco_loss: 0.4294 - kl_loss: 0.0552 - beta: 0.2627 - val_loss: 0.4662 - val_reco_loss: 0.4037 - val_kl_loss: 0.0625 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4388 - reco_loss: 0.3855 - kl_loss: 0.0520 - beta: 0.3170 - val_loss: 0.4049 - val_reco_loss: 0.3553 - val_kl_loss: 0.0496 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3802 - reco_loss: 0.3317 - kl_loss: 0.0477 - beta: 0.3713 - val_loss: 0.3561 - val_reco_loss: 0.3045 - val_kl_loss: 0.0516 - val_beta: 0.3713 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3507 - reco_loss: 0.3058 - kl_loss: 0.0439 - beta: 0.4253 - val_loss: 0.3345 - val_reco_loss: 0.2862 - val_kl_loss: 0.0483 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3220 - reco_loss: 0.2811 - kl_loss: 0.0402 - beta: 0.4795 - val_loss: 0.3034 - val_reco_loss: 0.2591 - val_kl_loss: 0.0444 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2953 - reco_loss: 0.2577 - kl_loss: 0.0365 - beta: 0.5335 - val_loss: 0.2867 - val_reco_loss: 0.2493 - val_kl_loss: 0.0374 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2656 - reco_loss: 0.2329 - kl_loss: 0.0317 - beta: 0.5877 - val_loss: 0.2578 - val_reco_loss: 0.2264 - val_kl_loss: 0.0314 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2370 - reco_loss: 0.2093 - kl_loss: 0.0271 - beta: 0.6418 - val_loss: 0.2304 - val_reco_loss: 0.2041 - val_kl_loss: 0.0263 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2133 - reco_loss: 0.1900 - kl_loss: 0.0221 - beta: 0.6959 - val_loss: 0.2037 - val_reco_loss: 0.1824 - val_kl_loss: 0.0213 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3462 - reco_loss: 0.3203 - kl_loss: 0.0374 - beta: 0.1490 - val_loss: 0.3889 - val_reco_loss: 0.3380 - val_kl_loss: 0.0509 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3785 - reco_loss: 0.3263 - kl_loss: 0.0531 - beta: 0.2033 - val_loss: 0.3833 - val_reco_loss: 0.3249 - val_kl_loss: 0.0584 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3660 - reco_loss: 0.3113 - kl_loss: 0.0547 - beta: 0.2576 - val_loss: 0.3764 - val_reco_loss: 0.3116 - val_kl_loss: 0.0648 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3606 - reco_loss: 0.3072 - kl_loss: 0.0523 - beta: 0.3119 - val_loss: 0.3517 - val_reco_loss: 0.2973 - val_kl_loss: 0.0544 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3400 - reco_loss: 0.2901 - kl_loss: 0.0490 - beta: 0.3662 - val_loss: 0.3337 - val_reco_loss: 0.2792 - val_kl_loss: 0.0545 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3202 - reco_loss: 0.2735 - kl_loss: 0.0459 - beta: 0.4204 - val_loss: 0.3166 - val_reco_loss: 0.2668 - val_kl_loss: 0.0498 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3012 - reco_loss: 0.2570 - kl_loss: 0.0436 - beta: 0.4745 - val_loss: 0.2989 - val_reco_loss: 0.2504 - val_kl_loss: 0.0485 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2767 - reco_loss: 0.2360 - kl_loss: 0.0395 - beta: 0.5286 - val_loss: 0.2802 - val_reco_loss: 0.2376 - val_kl_loss: 0.0425 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2580 - reco_loss: 0.2220 - kl_loss: 0.0348 - beta: 0.5827 - val_loss: 0.2607 - val_reco_loss: 0.2300 - val_kl_loss: 0.0308 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2297 - reco_loss: 0.1995 - kl_loss: 0.0293 - beta: 0.6368\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2297 - reco_loss: 0.1995 - kl_loss: 0.0293 - beta: 0.6368 - val_loss: 0.2290 - val_reco_loss: 0.1973 - val_kl_loss: 0.0317 - val_beta: 0.6368 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2077 - reco_loss: 0.1816 - kl_loss: 0.0246 - beta: 0.6905 - val_loss: 0.1933 - val_reco_loss: 0.1653 - val_kl_loss: 0.0280 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2905 - reco_loss: 0.2652 - kl_loss: 0.0340 - beta: 0.1438 - val_loss: 0.3772 - val_reco_loss: 0.3235 - val_kl_loss: 0.0538 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3555 - reco_loss: 0.3049 - kl_loss: 0.0520 - beta: 0.1981 - val_loss: 0.3682 - val_reco_loss: 0.3074 - val_kl_loss: 0.0608 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3493 - reco_loss: 0.2944 - kl_loss: 0.0550 - beta: 0.2523 - val_loss: 0.3548 - val_reco_loss: 0.2971 - val_kl_loss: 0.0578 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3399 - reco_loss: 0.2855 - kl_loss: 0.0537 - beta: 0.3066 - val_loss: 0.3505 - val_reco_loss: 0.2908 - val_kl_loss: 0.0597 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3268 - reco_loss: 0.2752 - kl_loss: 0.0507 - beta: 0.3609 - val_loss: 0.3398 - val_reco_loss: 0.2841 - val_kl_loss: 0.0556 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3127 - reco_loss: 0.2642 - kl_loss: 0.0476 - beta: 0.4150 - val_loss: 0.3189 - val_reco_loss: 0.2639 - val_kl_loss: 0.0550 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2951 - reco_loss: 0.2495 - kl_loss: 0.0448 - beta: 0.4691 - val_loss: 0.2976 - val_reco_loss: 0.2526 - val_kl_loss: 0.0451 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2724 - reco_loss: 0.2311 - kl_loss: 0.0406 - beta: 0.5232 - val_loss: 0.2848 - val_reco_loss: 0.2393 - val_kl_loss: 0.0455 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2537 - reco_loss: 0.2165 - kl_loss: 0.0362 - beta: 0.5773 - val_loss: 0.2501 - val_reco_loss: 0.2079 - val_kl_loss: 0.0422 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.2286 - reco_loss: 0.1968 - kl_loss: 0.0311 - beta: 0.6305\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2285 - reco_loss: 0.1967 - kl_loss: 0.0310 - beta: 0.6314 - val_loss: 0.2286 - val_reco_loss: 0.1945 - val_kl_loss: 0.0340 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2050 - reco_loss: 0.1780 - kl_loss: 0.0262 - beta: 0.6852 - val_loss: 0.2017 - val_reco_loss: 0.1707 - val_kl_loss: 0.0310 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2591 - reco_loss: 0.2354 - kl_loss: 0.0302 - beta: 0.1387 - val_loss: 0.3631 - val_reco_loss: 0.3128 - val_kl_loss: 0.0504 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3514 - reco_loss: 0.3024 - kl_loss: 0.0509 - beta: 0.1929 - val_loss: 0.3566 - val_reco_loss: 0.2991 - val_kl_loss: 0.0575 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3467 - reco_loss: 0.2919 - kl_loss: 0.0548 - beta: 0.2472 - val_loss: 0.3571 - val_reco_loss: 0.3012 - val_kl_loss: 0.0560 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3360 - reco_loss: 0.2820 - kl_loss: 0.0537 - beta: 0.3014 - val_loss: 0.3463 - val_reco_loss: 0.2901 - val_kl_loss: 0.0562 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3238 - reco_loss: 0.2724 - kl_loss: 0.0513 - beta: 0.3555 - val_loss: 0.3298 - val_reco_loss: 0.2790 - val_kl_loss: 0.0508 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3135 - reco_loss: 0.2647 - kl_loss: 0.0482 - beta: 0.4097 - val_loss: 0.3169 - val_reco_loss: 0.2639 - val_kl_loss: 0.0529 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2932 - reco_loss: 0.2473 - kl_loss: 0.0454 - beta: 0.4638 - val_loss: 0.2942 - val_reco_loss: 0.2473 - val_kl_loss: 0.0469 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2745 - reco_loss: 0.2314 - kl_loss: 0.0424 - beta: 0.5179 - val_loss: 0.2720 - val_reco_loss: 0.2262 - val_kl_loss: 0.0458 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2551 - reco_loss: 0.2159 - kl_loss: 0.0379 - beta: 0.5715\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2550 - reco_loss: 0.2159 - kl_loss: 0.0379 - beta: 0.5720 - val_loss: 0.2525 - val_reco_loss: 0.2091 - val_kl_loss: 0.0435 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2305 - reco_loss: 0.1958 - kl_loss: 0.0335 - beta: 0.6259 - val_loss: 0.2261 - val_reco_loss: 0.1878 - val_kl_loss: 0.0383 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2070 - reco_loss: 0.1779 - kl_loss: 0.0280 - beta: 0.6800 - val_loss: 0.2008 - val_reco_loss: 0.1697 - val_kl_loss: 0.0311 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2378 - reco_loss: 0.2141 - kl_loss: 0.0277 - beta: 0.1337 - val_loss: 0.3629 - val_reco_loss: 0.3187 - val_kl_loss: 0.0443 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3517 - reco_loss: 0.3049 - kl_loss: 0.0491 - beta: 0.1878 - val_loss: 0.3573 - val_reco_loss: 0.2971 - val_kl_loss: 0.0602 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3435 - reco_loss: 0.2897 - kl_loss: 0.0542 - beta: 0.2420 - val_loss: 0.3558 - val_reco_loss: 0.2900 - val_kl_loss: 0.0657 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3372 - reco_loss: 0.2824 - kl_loss: 0.0544 - beta: 0.2962 - val_loss: 0.3355 - val_reco_loss: 0.2741 - val_kl_loss: 0.0614 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3272 - reco_loss: 0.2748 - kl_loss: 0.0517 - beta: 0.3503 - val_loss: 0.3288 - val_reco_loss: 0.2639 - val_kl_loss: 0.0649 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3130 - reco_loss: 0.2629 - kl_loss: 0.0489 - beta: 0.4045 - val_loss: 0.3133 - val_reco_loss: 0.2533 - val_kl_loss: 0.0600 - val_beta: 0.4045 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2939 - reco_loss: 0.2468 - kl_loss: 0.0466 - beta: 0.4586 - val_loss: 0.2993 - val_reco_loss: 0.2455 - val_kl_loss: 0.0537 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.2782 - reco_loss: 0.2340 - kl_loss: 0.0431 - beta: 0.5118\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2781 - reco_loss: 0.2338 - kl_loss: 0.0431 - beta: 0.5126 - val_loss: 0.2711 - val_reco_loss: 0.2236 - val_kl_loss: 0.0475 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 10ms/step - loss: 0.9862 - reco_loss: 0.9555 - kl_loss: 0.0357 - beta: 0.1546 - val_loss: 0.6122 - val_reco_loss: 0.5702 - val_kl_loss: 0.0420 - val_beta: 0.1546 - lr: 0.0010\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5811 - reco_loss: 0.5389 - kl_loss: 0.0439 - beta: 0.2086 - val_loss: 0.5102 - val_reco_loss: 0.4589 - val_kl_loss: 0.0513 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5091 - reco_loss: 0.4607 - kl_loss: 0.0492 - beta: 0.2628 - val_loss: 0.4360 - val_reco_loss: 0.3826 - val_kl_loss: 0.0534 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4439 - reco_loss: 0.3940 - kl_loss: 0.0497 - beta: 0.3169 - val_loss: 0.3851 - val_reco_loss: 0.3294 - val_kl_loss: 0.0557 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4043 - reco_loss: 0.3573 - kl_loss: 0.0460 - beta: 0.3712 - val_loss: 0.3723 - val_reco_loss: 0.3200 - val_kl_loss: 0.0522 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3621 - reco_loss: 0.3190 - kl_loss: 0.0422 - beta: 0.4253 - val_loss: 0.3404 - val_reco_loss: 0.2916 - val_kl_loss: 0.0488 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3314 - reco_loss: 0.2921 - kl_loss: 0.0384 - beta: 0.4795 - val_loss: 0.3043 - val_reco_loss: 0.2614 - val_kl_loss: 0.0429 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3024 - reco_loss: 0.2656 - kl_loss: 0.0354 - beta: 0.5336 - val_loss: 0.2735 - val_reco_loss: 0.2301 - val_kl_loss: 0.0433 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2692 - reco_loss: 0.2360 - kl_loss: 0.0319 - beta: 0.5877 - val_loss: 0.2536 - val_reco_loss: 0.2156 - val_kl_loss: 0.0380 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2413 - reco_loss: 0.2129 - kl_loss: 0.0272 - beta: 0.6417 - val_loss: 0.2215 - val_reco_loss: 0.1896 - val_kl_loss: 0.0319 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2124 - reco_loss: 0.1886 - kl_loss: 0.0225 - beta: 0.6958 - val_loss: 0.1893 - val_reco_loss: 0.1623 - val_kl_loss: 0.0270 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3499 - reco_loss: 0.3267 - kl_loss: 0.0334 - beta: 0.1490 - val_loss: 0.3687 - val_reco_loss: 0.3191 - val_kl_loss: 0.0496 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3810 - reco_loss: 0.3309 - kl_loss: 0.0518 - beta: 0.2033 - val_loss: 0.3589 - val_reco_loss: 0.2974 - val_kl_loss: 0.0616 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3673 - reco_loss: 0.3133 - kl_loss: 0.0540 - beta: 0.2577 - val_loss: 0.3532 - val_reco_loss: 0.2903 - val_kl_loss: 0.0629 - val_beta: 0.2577 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3576 - reco_loss: 0.3044 - kl_loss: 0.0523 - beta: 0.3119 - val_loss: 0.3460 - val_reco_loss: 0.2898 - val_kl_loss: 0.0562 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3398 - reco_loss: 0.2901 - kl_loss: 0.0489 - beta: 0.3662 - val_loss: 0.3288 - val_reco_loss: 0.2710 - val_kl_loss: 0.0579 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3212 - reco_loss: 0.2748 - kl_loss: 0.0456 - beta: 0.4204 - val_loss: 0.3165 - val_reco_loss: 0.2637 - val_kl_loss: 0.0528 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3024 - reco_loss: 0.2590 - kl_loss: 0.0423 - beta: 0.4745 - val_loss: 0.2888 - val_reco_loss: 0.2403 - val_kl_loss: 0.0484 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2797 - reco_loss: 0.2400 - kl_loss: 0.0391 - beta: 0.5286 - val_loss: 0.2708 - val_reco_loss: 0.2235 - val_kl_loss: 0.0473 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2543 - reco_loss: 0.2185 - kl_loss: 0.0350 - beta: 0.5827 - val_loss: 0.2464 - val_reco_loss: 0.2048 - val_kl_loss: 0.0416 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2343 - reco_loss: 0.2022 - kl_loss: 0.0304 - beta: 0.6366\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2343 - reco_loss: 0.2022 - kl_loss: 0.0304 - beta: 0.6367 - val_loss: 0.2234 - val_reco_loss: 0.1870 - val_kl_loss: 0.0364 - val_beta: 0.6367 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2049 - reco_loss: 0.1787 - kl_loss: 0.0253 - beta: 0.6905 - val_loss: 0.1952 - val_reco_loss: 0.1666 - val_kl_loss: 0.0285 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2906 - reco_loss: 0.2667 - kl_loss: 0.0321 - beta: 0.1438 - val_loss: 0.3514 - val_reco_loss: 0.2961 - val_kl_loss: 0.0553 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3576 - reco_loss: 0.3074 - kl_loss: 0.0517 - beta: 0.1980 - val_loss: 0.3462 - val_reco_loss: 0.2862 - val_kl_loss: 0.0600 - val_beta: 0.1980 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3504 - reco_loss: 0.2958 - kl_loss: 0.0548 - beta: 0.2523 - val_loss: 0.3442 - val_reco_loss: 0.2819 - val_kl_loss: 0.0623 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3446 - reco_loss: 0.2897 - kl_loss: 0.0537 - beta: 0.3066 - val_loss: 0.3401 - val_reco_loss: 0.2810 - val_kl_loss: 0.0591 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3292 - reco_loss: 0.2776 - kl_loss: 0.0503 - beta: 0.3609 - val_loss: 0.3286 - val_reco_loss: 0.2761 - val_kl_loss: 0.0524 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3119 - reco_loss: 0.2637 - kl_loss: 0.0473 - beta: 0.4150 - val_loss: 0.2992 - val_reco_loss: 0.2452 - val_kl_loss: 0.0539 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2960 - reco_loss: 0.2508 - kl_loss: 0.0442 - beta: 0.4691 - val_loss: 0.2898 - val_reco_loss: 0.2347 - val_kl_loss: 0.0551 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2748 - reco_loss: 0.2331 - kl_loss: 0.0408 - beta: 0.5232 - val_loss: 0.2709 - val_reco_loss: 0.2259 - val_kl_loss: 0.0449 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2538 - reco_loss: 0.2162 - kl_loss: 0.0369 - beta: 0.5756\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2536 - reco_loss: 0.2160 - kl_loss: 0.0368 - beta: 0.5773 - val_loss: 0.2485 - val_reco_loss: 0.2072 - val_kl_loss: 0.0413 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2326 - reco_loss: 0.1984 - kl_loss: 0.0326 - beta: 0.6311 - val_loss: 0.2223 - val_reco_loss: 0.1870 - val_kl_loss: 0.0353 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2061 - reco_loss: 0.1774 - kl_loss: 0.0275 - beta: 0.6852 - val_loss: 0.2023 - val_reco_loss: 0.1724 - val_kl_loss: 0.0299 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2583 - reco_loss: 0.2343 - kl_loss: 0.0299 - beta: 0.1387 - val_loss: 0.3506 - val_reco_loss: 0.3001 - val_kl_loss: 0.0505 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3522 - reco_loss: 0.3044 - kl_loss: 0.0502 - beta: 0.1929 - val_loss: 0.3427 - val_reco_loss: 0.2859 - val_kl_loss: 0.0568 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3463 - reco_loss: 0.2933 - kl_loss: 0.0532 - beta: 0.2472 - val_loss: 0.3382 - val_reco_loss: 0.2726 - val_kl_loss: 0.0655 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3387 - reco_loss: 0.2857 - kl_loss: 0.0527 - beta: 0.3014 - val_loss: 0.3338 - val_reco_loss: 0.2751 - val_kl_loss: 0.0587 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3260 - reco_loss: 0.2750 - kl_loss: 0.0503 - beta: 0.3556 - val_loss: 0.3192 - val_reco_loss: 0.2572 - val_kl_loss: 0.0620 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3121 - reco_loss: 0.2637 - kl_loss: 0.0478 - beta: 0.4097 - val_loss: 0.3025 - val_reco_loss: 0.2482 - val_kl_loss: 0.0543 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2937 - reco_loss: 0.2481 - kl_loss: 0.0451 - beta: 0.4638 - val_loss: 0.2877 - val_reco_loss: 0.2351 - val_kl_loss: 0.0525 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.2761 - reco_loss: 0.2331 - kl_loss: 0.0418 - beta: 0.5171\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2760 - reco_loss: 0.2329 - kl_loss: 0.0417 - beta: 0.5179 - val_loss: 0.2692 - val_reco_loss: 0.2212 - val_kl_loss: 0.0480 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 7s 9ms/step - loss: 0.9269 - reco_loss: 0.9058 - kl_loss: 0.0300 - beta: 0.1546 - val_loss: 0.6560 - val_reco_loss: 0.6117 - val_kl_loss: 0.0443 - val_beta: 0.1546 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5783 - reco_loss: 0.5331 - kl_loss: 0.0476 - beta: 0.2086 - val_loss: 0.5486 - val_reco_loss: 0.4921 - val_kl_loss: 0.0565 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5004 - reco_loss: 0.4470 - kl_loss: 0.0536 - beta: 0.2628 - val_loss: 0.4700 - val_reco_loss: 0.4140 - val_kl_loss: 0.0560 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4491 - reco_loss: 0.3970 - kl_loss: 0.0515 - beta: 0.3170 - val_loss: 0.4137 - val_reco_loss: 0.3581 - val_kl_loss: 0.0555 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3965 - reco_loss: 0.3485 - kl_loss: 0.0473 - beta: 0.3711 - val_loss: 0.3676 - val_reco_loss: 0.3154 - val_kl_loss: 0.0521 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3629 - reco_loss: 0.3183 - kl_loss: 0.0438 - beta: 0.4253 - val_loss: 0.3335 - val_reco_loss: 0.2829 - val_kl_loss: 0.0506 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3340 - reco_loss: 0.2919 - kl_loss: 0.0407 - beta: 0.4794 - val_loss: 0.3035 - val_reco_loss: 0.2585 - val_kl_loss: 0.0450 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2982 - reco_loss: 0.2602 - kl_loss: 0.0368 - beta: 0.5336 - val_loss: 0.2822 - val_reco_loss: 0.2415 - val_kl_loss: 0.0407 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2690 - reco_loss: 0.2353 - kl_loss: 0.0324 - beta: 0.5877 - val_loss: 0.2515 - val_reco_loss: 0.2159 - val_kl_loss: 0.0356 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2428 - reco_loss: 0.2142 - kl_loss: 0.0274 - beta: 0.6418 - val_loss: 0.2268 - val_reco_loss: 0.1963 - val_kl_loss: 0.0305 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2117 - reco_loss: 0.1879 - kl_loss: 0.0229 - beta: 0.6958 - val_loss: 0.1988 - val_reco_loss: 0.1736 - val_kl_loss: 0.0251 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3538 - reco_loss: 0.3279 - kl_loss: 0.0367 - beta: 0.1490 - val_loss: 0.3812 - val_reco_loss: 0.3284 - val_kl_loss: 0.0528 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3806 - reco_loss: 0.3291 - kl_loss: 0.0524 - beta: 0.2032 - val_loss: 0.3657 - val_reco_loss: 0.3058 - val_kl_loss: 0.0599 - val_beta: 0.2032 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3690 - reco_loss: 0.3154 - kl_loss: 0.0532 - beta: 0.2576 - val_loss: 0.3587 - val_reco_loss: 0.2990 - val_kl_loss: 0.0598 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3514 - reco_loss: 0.2993 - kl_loss: 0.0517 - beta: 0.3120 - val_loss: 0.3417 - val_reco_loss: 0.2876 - val_kl_loss: 0.0541 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3384 - reco_loss: 0.2895 - kl_loss: 0.0482 - beta: 0.3662 - val_loss: 0.3355 - val_reco_loss: 0.2807 - val_kl_loss: 0.0548 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3238 - reco_loss: 0.2772 - kl_loss: 0.0455 - beta: 0.4204 - val_loss: 0.3077 - val_reco_loss: 0.2577 - val_kl_loss: 0.0500 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3038 - reco_loss: 0.2601 - kl_loss: 0.0427 - beta: 0.4745 - val_loss: 0.2916 - val_reco_loss: 0.2454 - val_kl_loss: 0.0462 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2780 - reco_loss: 0.2381 - kl_loss: 0.0388 - beta: 0.5286 - val_loss: 0.2712 - val_reco_loss: 0.2318 - val_kl_loss: 0.0395 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2554 - reco_loss: 0.2195 - kl_loss: 0.0347 - beta: 0.5827 - val_loss: 0.2416 - val_reco_loss: 0.2013 - val_kl_loss: 0.0403 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.2321 - reco_loss: 0.2004 - kl_loss: 0.0299 - beta: 0.6359\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2320 - reco_loss: 0.2003 - kl_loss: 0.0299 - beta: 0.6368 - val_loss: 0.2193 - val_reco_loss: 0.1868 - val_kl_loss: 0.0324 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2050 - reco_loss: 0.1788 - kl_loss: 0.0250 - beta: 0.6905 - val_loss: 0.1864 - val_reco_loss: 0.1593 - val_kl_loss: 0.0271 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2906 - reco_loss: 0.2663 - kl_loss: 0.0331 - beta: 0.1438 - val_loss: 0.3646 - val_reco_loss: 0.3142 - val_kl_loss: 0.0504 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3561 - reco_loss: 0.3068 - kl_loss: 0.0508 - beta: 0.1981 - val_loss: 0.3593 - val_reco_loss: 0.3028 - val_kl_loss: 0.0565 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3497 - reco_loss: 0.2964 - kl_loss: 0.0537 - beta: 0.2524 - val_loss: 0.3514 - val_reco_loss: 0.2889 - val_kl_loss: 0.0625 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3418 - reco_loss: 0.2883 - kl_loss: 0.0529 - beta: 0.3066 - val_loss: 0.3384 - val_reco_loss: 0.2779 - val_kl_loss: 0.0605 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3256 - reco_loss: 0.2747 - kl_loss: 0.0501 - beta: 0.3608 - val_loss: 0.3188 - val_reco_loss: 0.2622 - val_kl_loss: 0.0566 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3108 - reco_loss: 0.2630 - kl_loss: 0.0471 - beta: 0.4150 - val_loss: 0.3086 - val_reco_loss: 0.2617 - val_kl_loss: 0.0469 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2935 - reco_loss: 0.2489 - kl_loss: 0.0438 - beta: 0.4691 - val_loss: 0.2883 - val_reco_loss: 0.2441 - val_kl_loss: 0.0442 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2749 - reco_loss: 0.2337 - kl_loss: 0.0406 - beta: 0.5232 - val_loss: 0.2748 - val_reco_loss: 0.2274 - val_kl_loss: 0.0474 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2543 - reco_loss: 0.2166 - kl_loss: 0.0366 - beta: 0.5773 - val_loss: 0.2493 - val_reco_loss: 0.2095 - val_kl_loss: 0.0398 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2306 - reco_loss: 0.1976 - kl_loss: 0.0322 - beta: 0.6297\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2305 - reco_loss: 0.1974 - kl_loss: 0.0321 - beta: 0.6314 - val_loss: 0.2192 - val_reco_loss: 0.1861 - val_kl_loss: 0.0330 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2069 - reco_loss: 0.1788 - kl_loss: 0.0271 - beta: 0.6852 - val_loss: 0.1947 - val_reco_loss: 0.1623 - val_kl_loss: 0.0324 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2597 - reco_loss: 0.2358 - kl_loss: 0.0298 - beta: 0.1387 - val_loss: 0.3645 - val_reco_loss: 0.3177 - val_kl_loss: 0.0468 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3530 - reco_loss: 0.3049 - kl_loss: 0.0499 - beta: 0.1929 - val_loss: 0.3462 - val_reco_loss: 0.2890 - val_kl_loss: 0.0572 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3448 - reco_loss: 0.2911 - kl_loss: 0.0540 - beta: 0.2471 - val_loss: 0.3382 - val_reco_loss: 0.2779 - val_kl_loss: 0.0603 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3371 - reco_loss: 0.2829 - kl_loss: 0.0538 - beta: 0.3014 - val_loss: 0.3430 - val_reco_loss: 0.2866 - val_kl_loss: 0.0563 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3258 - reco_loss: 0.2733 - kl_loss: 0.0516 - beta: 0.3556 - val_loss: 0.3295 - val_reco_loss: 0.2707 - val_kl_loss: 0.0588 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3124 - reco_loss: 0.2631 - kl_loss: 0.0484 - beta: 0.4097 - val_loss: 0.3049 - val_reco_loss: 0.2473 - val_kl_loss: 0.0576 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2947 - reco_loss: 0.2488 - kl_loss: 0.0449 - beta: 0.4638 - val_loss: 0.2867 - val_reco_loss: 0.2369 - val_kl_loss: 0.0498 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2759 - reco_loss: 0.2325 - kl_loss: 0.0420 - beta: 0.5179 - val_loss: 0.2671 - val_reco_loss: 0.2199 - val_kl_loss: 0.0472 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2553 - reco_loss: 0.2164 - kl_loss: 0.0378 - beta: 0.5704\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2551 - reco_loss: 0.2163 - kl_loss: 0.0378 - beta: 0.5720 - val_loss: 0.2425 - val_reco_loss: 0.2010 - val_kl_loss: 0.0415 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2316 - reco_loss: 0.1980 - kl_loss: 0.0330 - beta: 0.6259 - val_loss: 0.2244 - val_reco_loss: 0.1860 - val_kl_loss: 0.0385 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2094 - reco_loss: 0.1794 - kl_loss: 0.0285 - beta: 0.6799 - val_loss: 0.1917 - val_reco_loss: 0.1601 - val_kl_loss: 0.0316 - val_beta: 0.6799 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2406 - reco_loss: 0.2161 - kl_loss: 0.0273 - beta: 0.1337 - val_loss: 0.3574 - val_reco_loss: 0.3101 - val_kl_loss: 0.0473 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3503 - reco_loss: 0.3038 - kl_loss: 0.0487 - beta: 0.1878 - val_loss: 0.3462 - val_reco_loss: 0.2907 - val_kl_loss: 0.0556 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3449 - reco_loss: 0.2918 - kl_loss: 0.0535 - beta: 0.2420 - val_loss: 0.3381 - val_reco_loss: 0.2825 - val_kl_loss: 0.0557 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3389 - reco_loss: 0.2850 - kl_loss: 0.0536 - beta: 0.2962 - val_loss: 0.3309 - val_reco_loss: 0.2740 - val_kl_loss: 0.0569 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3248 - reco_loss: 0.2728 - kl_loss: 0.0517 - beta: 0.3503 - val_loss: 0.3237 - val_reco_loss: 0.2720 - val_kl_loss: 0.0517 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3088 - reco_loss: 0.2596 - kl_loss: 0.0492 - beta: 0.4045 - val_loss: 0.3102 - val_reco_loss: 0.2498 - val_kl_loss: 0.0603 - val_beta: 0.4045 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2987 - reco_loss: 0.2510 - kl_loss: 0.0464 - beta: 0.4585 - val_loss: 0.2919 - val_reco_loss: 0.2352 - val_kl_loss: 0.0567 - val_beta: 0.4585 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2814 - reco_loss: 0.2369 - kl_loss: 0.0434 - beta: 0.5120\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2812 - reco_loss: 0.2368 - kl_loss: 0.0434 - beta: 0.5126 - val_loss: 0.2767 - val_reco_loss: 0.2315 - val_kl_loss: 0.0452 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.9218 - reco_loss: 0.9009 - kl_loss: 0.0303 - beta: 0.1544 - val_loss: 0.6350 - val_reco_loss: 0.5905 - val_kl_loss: 0.0445 - val_beta: 0.1544 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5549 - reco_loss: 0.5079 - kl_loss: 0.0488 - beta: 0.2087 - val_loss: 0.5310 - val_reco_loss: 0.4760 - val_kl_loss: 0.0550 - val_beta: 0.2087 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4913 - reco_loss: 0.4391 - kl_loss: 0.0522 - beta: 0.2628 - val_loss: 0.4600 - val_reco_loss: 0.4005 - val_kl_loss: 0.0595 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4398 - reco_loss: 0.3877 - kl_loss: 0.0510 - beta: 0.3169 - val_loss: 0.4097 - val_reco_loss: 0.3572 - val_kl_loss: 0.0525 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3885 - reco_loss: 0.3409 - kl_loss: 0.0468 - beta: 0.3713 - val_loss: 0.3666 - val_reco_loss: 0.3146 - val_kl_loss: 0.0519 - val_beta: 0.3713 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3663 - reco_loss: 0.3219 - kl_loss: 0.0439 - beta: 0.4252 - val_loss: 0.3414 - val_reco_loss: 0.2908 - val_kl_loss: 0.0506 - val_beta: 0.4252 - lr: 0.0010\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3266 - reco_loss: 0.2855 - kl_loss: 0.0407 - beta: 0.4795 - val_loss: 0.3125 - val_reco_loss: 0.2646 - val_kl_loss: 0.0479 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3015 - reco_loss: 0.2648 - kl_loss: 0.0360 - beta: 0.5335 - val_loss: 0.2866 - val_reco_loss: 0.2433 - val_kl_loss: 0.0432 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2726 - reco_loss: 0.2398 - kl_loss: 0.0319 - beta: 0.5876 - val_loss: 0.2535 - val_reco_loss: 0.2145 - val_kl_loss: 0.0390 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2406 - reco_loss: 0.2119 - kl_loss: 0.0277 - beta: 0.6418 - val_loss: 0.2217 - val_reco_loss: 0.1871 - val_kl_loss: 0.0346 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2138 - reco_loss: 0.1896 - kl_loss: 0.0232 - beta: 0.6959 - val_loss: 0.2001 - val_reco_loss: 0.1738 - val_kl_loss: 0.0264 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3472 - reco_loss: 0.3226 - kl_loss: 0.0357 - beta: 0.1490 - val_loss: 0.3772 - val_reco_loss: 0.3200 - val_kl_loss: 0.0573 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3765 - reco_loss: 0.3258 - kl_loss: 0.0514 - beta: 0.2033 - val_loss: 0.3696 - val_reco_loss: 0.3157 - val_kl_loss: 0.0539 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3662 - reco_loss: 0.3134 - kl_loss: 0.0529 - beta: 0.2576 - val_loss: 0.3554 - val_reco_loss: 0.2984 - val_kl_loss: 0.0570 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3470 - reco_loss: 0.2949 - kl_loss: 0.0519 - beta: 0.3119 - val_loss: 0.3527 - val_reco_loss: 0.2936 - val_kl_loss: 0.0591 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3338 - reco_loss: 0.2836 - kl_loss: 0.0497 - beta: 0.3661 - val_loss: 0.3371 - val_reco_loss: 0.2800 - val_kl_loss: 0.0570 - val_beta: 0.3661 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3202 - reco_loss: 0.2729 - kl_loss: 0.0460 - beta: 0.4204 - val_loss: 0.3145 - val_reco_loss: 0.2604 - val_kl_loss: 0.0541 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2967 - reco_loss: 0.2522 - kl_loss: 0.0435 - beta: 0.4745 - val_loss: 0.2992 - val_reco_loss: 0.2495 - val_kl_loss: 0.0497 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2765 - reco_loss: 0.2364 - kl_loss: 0.0392 - beta: 0.5286 - val_loss: 0.2762 - val_reco_loss: 0.2330 - val_kl_loss: 0.0432 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2539 - reco_loss: 0.2181 - kl_loss: 0.0347 - beta: 0.5827 - val_loss: 0.2440 - val_reco_loss: 0.2036 - val_kl_loss: 0.0403 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2310 - reco_loss: 0.2003 - kl_loss: 0.0297 - beta: 0.6366\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2310 - reco_loss: 0.2002 - kl_loss: 0.0297 - beta: 0.6368 - val_loss: 0.2247 - val_reco_loss: 0.1920 - val_kl_loss: 0.0327 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2062 - reco_loss: 0.1799 - kl_loss: 0.0250 - beta: 0.6905 - val_loss: 0.1949 - val_reco_loss: 0.1656 - val_kl_loss: 0.0293 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2877 - reco_loss: 0.2628 - kl_loss: 0.0333 - beta: 0.1438 - val_loss: 0.3574 - val_reco_loss: 0.3070 - val_kl_loss: 0.0503 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3552 - reco_loss: 0.3067 - kl_loss: 0.0500 - beta: 0.1981 - val_loss: 0.3566 - val_reco_loss: 0.2975 - val_kl_loss: 0.0591 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3508 - reco_loss: 0.2982 - kl_loss: 0.0526 - beta: 0.2524 - val_loss: 0.3561 - val_reco_loss: 0.2952 - val_kl_loss: 0.0609 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3386 - reco_loss: 0.2858 - kl_loss: 0.0526 - beta: 0.3066 - val_loss: 0.3423 - val_reco_loss: 0.2835 - val_kl_loss: 0.0588 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3220 - reco_loss: 0.2718 - kl_loss: 0.0501 - beta: 0.3609 - val_loss: 0.3280 - val_reco_loss: 0.2702 - val_kl_loss: 0.0579 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3120 - reco_loss: 0.2641 - kl_loss: 0.0474 - beta: 0.4150 - val_loss: 0.3068 - val_reco_loss: 0.2482 - val_kl_loss: 0.0586 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2975 - reco_loss: 0.2515 - kl_loss: 0.0446 - beta: 0.4691 - val_loss: 0.2948 - val_reco_loss: 0.2427 - val_kl_loss: 0.0521 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2752 - reco_loss: 0.2329 - kl_loss: 0.0411 - beta: 0.5232 - val_loss: 0.2708 - val_reco_loss: 0.2234 - val_kl_loss: 0.0474 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2535 - reco_loss: 0.2159 - kl_loss: 0.0366 - beta: 0.5773 - val_loss: 0.2534 - val_reco_loss: 0.2124 - val_kl_loss: 0.0410 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2324 - reco_loss: 0.1991 - kl_loss: 0.0320 - beta: 0.6304\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2322 - reco_loss: 0.1990 - kl_loss: 0.0320 - beta: 0.6314 - val_loss: 0.2222 - val_reco_loss: 0.1879 - val_kl_loss: 0.0343 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2047 - reco_loss: 0.1768 - kl_loss: 0.0275 - beta: 0.6852 - val_loss: 0.2005 - val_reco_loss: 0.1698 - val_kl_loss: 0.0307 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2616 - reco_loss: 0.2358 - kl_loss: 0.0308 - beta: 0.1387 - val_loss: 0.3613 - val_reco_loss: 0.3129 - val_kl_loss: 0.0485 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3536 - reco_loss: 0.3058 - kl_loss: 0.0494 - beta: 0.1929 - val_loss: 0.3557 - val_reco_loss: 0.3011 - val_kl_loss: 0.0546 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3486 - reco_loss: 0.2964 - kl_loss: 0.0527 - beta: 0.2471 - val_loss: 0.3537 - val_reco_loss: 0.2928 - val_kl_loss: 0.0609 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3355 - reco_loss: 0.2828 - kl_loss: 0.0525 - beta: 0.3014 - val_loss: 0.3404 - val_reco_loss: 0.2824 - val_kl_loss: 0.0580 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3226 - reco_loss: 0.2713 - kl_loss: 0.0513 - beta: 0.3555 - val_loss: 0.3311 - val_reco_loss: 0.2739 - val_kl_loss: 0.0571 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3114 - reco_loss: 0.2618 - kl_loss: 0.0490 - beta: 0.4097 - val_loss: 0.3128 - val_reco_loss: 0.2588 - val_kl_loss: 0.0540 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2912 - reco_loss: 0.2450 - kl_loss: 0.0461 - beta: 0.4638 - val_loss: 0.2966 - val_reco_loss: 0.2454 - val_kl_loss: 0.0512 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2757 - reco_loss: 0.2326 - kl_loss: 0.0420 - beta: 0.5179 - val_loss: 0.2708 - val_reco_loss: 0.2224 - val_kl_loss: 0.0484 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2549 - reco_loss: 0.2163 - kl_loss: 0.0375 - beta: 0.5718\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2548 - reco_loss: 0.2162 - kl_loss: 0.0375 - beta: 0.5720 - val_loss: 0.2574 - val_reco_loss: 0.2180 - val_kl_loss: 0.0394 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2318 - reco_loss: 0.1974 - kl_loss: 0.0330 - beta: 0.6259 - val_loss: 0.2271 - val_reco_loss: 0.1899 - val_kl_loss: 0.0372 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2071 - reco_loss: 0.1773 - kl_loss: 0.0287 - beta: 0.6799 - val_loss: 0.2065 - val_reco_loss: 0.1722 - val_kl_loss: 0.0343 - val_beta: 0.6799 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2400 - reco_loss: 0.2158 - kl_loss: 0.0274 - beta: 0.1337 - val_loss: 0.3618 - val_reco_loss: 0.3169 - val_kl_loss: 0.0449 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3542 - reco_loss: 0.3079 - kl_loss: 0.0483 - beta: 0.1878 - val_loss: 0.3511 - val_reco_loss: 0.2943 - val_kl_loss: 0.0568 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3460 - reco_loss: 0.2938 - kl_loss: 0.0525 - beta: 0.2420 - val_loss: 0.3590 - val_reco_loss: 0.3018 - val_kl_loss: 0.0572 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3359 - reco_loss: 0.2828 - kl_loss: 0.0528 - beta: 0.2962 - val_loss: 0.3444 - val_reco_loss: 0.2823 - val_kl_loss: 0.0621 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3236 - reco_loss: 0.2721 - kl_loss: 0.0512 - beta: 0.3503 - val_loss: 0.3287 - val_reco_loss: 0.2683 - val_kl_loss: 0.0604 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3138 - reco_loss: 0.2635 - kl_loss: 0.0493 - beta: 0.4045 - val_loss: 0.3197 - val_reco_loss: 0.2660 - val_kl_loss: 0.0537 - val_beta: 0.4045 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2963 - reco_loss: 0.2491 - kl_loss: 0.0466 - beta: 0.4585 - val_loss: 0.2979 - val_reco_loss: 0.2457 - val_kl_loss: 0.0522 - val_beta: 0.4585 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2781 - reco_loss: 0.2335 - kl_loss: 0.0433 - beta: 0.5123\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2780 - reco_loss: 0.2335 - kl_loss: 0.0433 - beta: 0.5126 - val_loss: 0.2811 - val_reco_loss: 0.2352 - val_kl_loss: 0.0459 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.9866 - reco_loss: 0.9746 - kl_loss: 0.0154 - beta: 0.1545 - val_loss: 0.6609 - val_reco_loss: 0.6337 - val_kl_loss: 0.0272 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.6151 - reco_loss: 0.5851 - kl_loss: 0.0339 - beta: 0.2087 - val_loss: 0.5039 - val_reco_loss: 0.4567 - val_kl_loss: 0.0472 - val_beta: 0.2087 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4789 - reco_loss: 0.4320 - kl_loss: 0.0491 - beta: 0.2628 - val_loss: 0.4192 - val_reco_loss: 0.3621 - val_kl_loss: 0.0571 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4328 - reco_loss: 0.3824 - kl_loss: 0.0497 - beta: 0.3169 - val_loss: 0.3918 - val_reco_loss: 0.3354 - val_kl_loss: 0.0563 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3910 - reco_loss: 0.3433 - kl_loss: 0.0467 - beta: 0.3711 - val_loss: 0.3536 - val_reco_loss: 0.3049 - val_kl_loss: 0.0487 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3552 - reco_loss: 0.3115 - kl_loss: 0.0432 - beta: 0.4253 - val_loss: 0.3225 - val_reco_loss: 0.2761 - val_kl_loss: 0.0464 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3293 - reco_loss: 0.2894 - kl_loss: 0.0394 - beta: 0.4794 - val_loss: 0.3084 - val_reco_loss: 0.2645 - val_kl_loss: 0.0438 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3023 - reco_loss: 0.2658 - kl_loss: 0.0354 - beta: 0.5336 - val_loss: 0.2785 - val_reco_loss: 0.2406 - val_kl_loss: 0.0380 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2785 - reco_loss: 0.2462 - kl_loss: 0.0307 - beta: 0.5876 - val_loss: 0.2530 - val_reco_loss: 0.2191 - val_kl_loss: 0.0339 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2421 - reco_loss: 0.2147 - kl_loss: 0.0264 - beta: 0.6418 - val_loss: 0.2283 - val_reco_loss: 0.1979 - val_kl_loss: 0.0304 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2169 - reco_loss: 0.1937 - kl_loss: 0.0218 - beta: 0.6958 - val_loss: 0.1954 - val_reco_loss: 0.1722 - val_kl_loss: 0.0232 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3567 - reco_loss: 0.3318 - kl_loss: 0.0357 - beta: 0.1490 - val_loss: 0.3833 - val_reco_loss: 0.3285 - val_kl_loss: 0.0548 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3887 - reco_loss: 0.3374 - kl_loss: 0.0524 - beta: 0.2033 - val_loss: 0.3617 - val_reco_loss: 0.3036 - val_kl_loss: 0.0581 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3680 - reco_loss: 0.3142 - kl_loss: 0.0540 - beta: 0.2576 - val_loss: 0.3516 - val_reco_loss: 0.2940 - val_kl_loss: 0.0576 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3614 - reco_loss: 0.3091 - kl_loss: 0.0515 - beta: 0.3119 - val_loss: 0.3401 - val_reco_loss: 0.2802 - val_kl_loss: 0.0599 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3423 - reco_loss: 0.2932 - kl_loss: 0.0486 - beta: 0.3661 - val_loss: 0.3298 - val_reco_loss: 0.2738 - val_kl_loss: 0.0560 - val_beta: 0.3661 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3277 - reco_loss: 0.2818 - kl_loss: 0.0452 - beta: 0.4204 - val_loss: 0.3018 - val_reco_loss: 0.2536 - val_kl_loss: 0.0482 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3049 - reco_loss: 0.2624 - kl_loss: 0.0419 - beta: 0.4745 - val_loss: 0.2928 - val_reco_loss: 0.2501 - val_kl_loss: 0.0427 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2815 - reco_loss: 0.2424 - kl_loss: 0.0380 - beta: 0.5286 - val_loss: 0.2706 - val_reco_loss: 0.2263 - val_kl_loss: 0.0442 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2598 - reco_loss: 0.2250 - kl_loss: 0.0338 - beta: 0.5826 - val_loss: 0.2428 - val_reco_loss: 0.2083 - val_kl_loss: 0.0345 - val_beta: 0.5826 - lr: 0.0010\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/320 [============================>.] - ETA: 0s - loss: 0.2333 - reco_loss: 0.2030 - kl_loss: 0.0291 - beta: 0.6360\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2332 - reco_loss: 0.2029 - kl_loss: 0.0291 - beta: 0.6368 - val_loss: 0.2175 - val_reco_loss: 0.1864 - val_kl_loss: 0.0310 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2074 - reco_loss: 0.1818 - kl_loss: 0.0245 - beta: 0.6905 - val_loss: 0.1947 - val_reco_loss: 0.1639 - val_kl_loss: 0.0308 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2939 - reco_loss: 0.2694 - kl_loss: 0.0329 - beta: 0.1438 - val_loss: 0.3614 - val_reco_loss: 0.3065 - val_kl_loss: 0.0549 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3619 - reco_loss: 0.3117 - kl_loss: 0.0513 - beta: 0.1981 - val_loss: 0.3497 - val_reco_loss: 0.2905 - val_kl_loss: 0.0592 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3540 - reco_loss: 0.3002 - kl_loss: 0.0541 - beta: 0.2524 - val_loss: 0.3457 - val_reco_loss: 0.2871 - val_kl_loss: 0.0585 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3412 - reco_loss: 0.2880 - kl_loss: 0.0527 - beta: 0.3066 - val_loss: 0.3309 - val_reco_loss: 0.2704 - val_kl_loss: 0.0606 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3291 - reco_loss: 0.2792 - kl_loss: 0.0492 - beta: 0.3608 - val_loss: 0.3262 - val_reco_loss: 0.2680 - val_kl_loss: 0.0582 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3153 - reco_loss: 0.2676 - kl_loss: 0.0466 - beta: 0.4150 - val_loss: 0.3190 - val_reco_loss: 0.2676 - val_kl_loss: 0.0514 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2957 - reco_loss: 0.2519 - kl_loss: 0.0431 - beta: 0.4691 - val_loss: 0.2853 - val_reco_loss: 0.2366 - val_kl_loss: 0.0487 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2788 - reco_loss: 0.2373 - kl_loss: 0.0403 - beta: 0.5232 - val_loss: 0.2624 - val_reco_loss: 0.2199 - val_kl_loss: 0.0425 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2542 - reco_loss: 0.2170 - kl_loss: 0.0359 - beta: 0.5773 - val_loss: 0.2481 - val_reco_loss: 0.2063 - val_kl_loss: 0.0418 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2317 - reco_loss: 0.1992 - kl_loss: 0.0315 - beta: 0.6307\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2316 - reco_loss: 0.1991 - kl_loss: 0.0314 - beta: 0.6314 - val_loss: 0.2197 - val_reco_loss: 0.1846 - val_kl_loss: 0.0351 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2065 - reco_loss: 0.1785 - kl_loss: 0.0267 - beta: 0.6852 - val_loss: 0.1937 - val_reco_loss: 0.1602 - val_kl_loss: 0.0335 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2619 - reco_loss: 0.2386 - kl_loss: 0.0294 - beta: 0.1387 - val_loss: 0.3562 - val_reco_loss: 0.3046 - val_kl_loss: 0.0516 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3527 - reco_loss: 0.3038 - kl_loss: 0.0508 - beta: 0.1929 - val_loss: 0.3433 - val_reco_loss: 0.2848 - val_kl_loss: 0.0585 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3524 - reco_loss: 0.2986 - kl_loss: 0.0541 - beta: 0.2471 - val_loss: 0.3413 - val_reco_loss: 0.2829 - val_kl_loss: 0.0584 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3421 - reco_loss: 0.2880 - kl_loss: 0.0534 - beta: 0.3014 - val_loss: 0.3359 - val_reco_loss: 0.2739 - val_kl_loss: 0.0621 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3266 - reco_loss: 0.2753 - kl_loss: 0.0507 - beta: 0.3555 - val_loss: 0.3132 - val_reco_loss: 0.2573 - val_kl_loss: 0.0559 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3118 - reco_loss: 0.2631 - kl_loss: 0.0475 - beta: 0.4097 - val_loss: 0.3070 - val_reco_loss: 0.2558 - val_kl_loss: 0.0511 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2960 - reco_loss: 0.2504 - kl_loss: 0.0446 - beta: 0.4638 - val_loss: 0.2884 - val_reco_loss: 0.2405 - val_kl_loss: 0.0479 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2770 - reco_loss: 0.2345 - kl_loss: 0.0412 - beta: 0.5179 - val_loss: 0.2683 - val_reco_loss: 0.2239 - val_kl_loss: 0.0444 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2554 - reco_loss: 0.2173 - kl_loss: 0.0368 - beta: 0.5720 - val_loss: 0.2421 - val_reco_loss: 0.2025 - val_kl_loss: 0.0396 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.2336 - reco_loss: 0.1999 - kl_loss: 0.0323 - beta: 0.6249\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2335 - reco_loss: 0.1998 - kl_loss: 0.0322 - beta: 0.6261 - val_loss: 0.2219 - val_reco_loss: 0.1872 - val_kl_loss: 0.0347 - val_beta: 0.6261 - lr: 4.9000e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2072 - reco_loss: 0.1785 - kl_loss: 0.0275 - beta: 0.6800 - val_loss: 0.1974 - val_reco_loss: 0.1657 - val_kl_loss: 0.0317 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2393 - reco_loss: 0.2153 - kl_loss: 0.0281 - beta: 0.1337 - val_loss: 0.3528 - val_reco_loss: 0.3037 - val_kl_loss: 0.0492 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3517 - reco_loss: 0.3043 - kl_loss: 0.0496 - beta: 0.1878 - val_loss: 0.3447 - val_reco_loss: 0.2835 - val_kl_loss: 0.0612 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3477 - reco_loss: 0.2940 - kl_loss: 0.0539 - beta: 0.2420 - val_loss: 0.3391 - val_reco_loss: 0.2777 - val_kl_loss: 0.0614 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3397 - reco_loss: 0.2858 - kl_loss: 0.0537 - beta: 0.2962 - val_loss: 0.3352 - val_reco_loss: 0.2755 - val_kl_loss: 0.0597 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3262 - reco_loss: 0.2745 - kl_loss: 0.0514 - beta: 0.3503 - val_loss: 0.3205 - val_reco_loss: 0.2655 - val_kl_loss: 0.0550 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3154 - reco_loss: 0.2659 - kl_loss: 0.0485 - beta: 0.4044 - val_loss: 0.3043 - val_reco_loss: 0.2461 - val_kl_loss: 0.0582 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2970 - reco_loss: 0.2504 - kl_loss: 0.0455 - beta: 0.4585 - val_loss: 0.2897 - val_reco_loss: 0.2364 - val_kl_loss: 0.0533 - val_beta: 0.4585 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2770 - reco_loss: 0.2345 - kl_loss: 0.0417 - beta: 0.5126 - val_loss: 0.2727 - val_reco_loss: 0.2290 - val_kl_loss: 0.0437 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/320 [============================>.] - ETA: 0s - loss: 0.2541 - reco_loss: 0.2153 - kl_loss: 0.0380 - beta: 0.5662\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2540 - reco_loss: 0.2153 - kl_loss: 0.0380 - beta: 0.5667 - val_loss: 0.2541 - val_reco_loss: 0.2189 - val_kl_loss: 0.0352 - val_beta: 0.5667 - lr: 3.4300e-04\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2349 - reco_loss: 0.2001 - kl_loss: 0.0337 - beta: 0.6207 - val_loss: 0.2279 - val_reco_loss: 0.1921 - val_kl_loss: 0.0358 - val_beta: 0.6207 - lr: 2.4010e-04\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2097 - reco_loss: 0.1798 - kl_loss: 0.0290 - beta: 0.6748 - val_loss: 0.1986 - val_reco_loss: 0.1684 - val_kl_loss: 0.0301 - val_beta: 0.6748 - lr: 2.4010e-04\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2228 - reco_loss: 0.1983 - kl_loss: 0.0257 - beta: 0.1286 - val_loss: 0.3519 - val_reco_loss: 0.3108 - val_kl_loss: 0.0410 - val_beta: 0.1286 - lr: 2.4010e-04\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3526 - reco_loss: 0.3085 - kl_loss: 0.0474 - beta: 0.1827 - val_loss: 0.3427 - val_reco_loss: 0.2854 - val_kl_loss: 0.0573 - val_beta: 0.1827 - lr: 2.4010e-04\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3463 - reco_loss: 0.2931 - kl_loss: 0.0536 - beta: 0.2369 - val_loss: 0.3438 - val_reco_loss: 0.2845 - val_kl_loss: 0.0593 - val_beta: 0.2369 - lr: 2.4010e-04\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3383 - reco_loss: 0.2843 - kl_loss: 0.0536 - beta: 0.2910 - val_loss: 0.3362 - val_reco_loss: 0.2780 - val_kl_loss: 0.0581 - val_beta: 0.2910 - lr: 2.4010e-04\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3247 - reco_loss: 0.2725 - kl_loss: 0.0518 - beta: 0.3451 - val_loss: 0.3205 - val_reco_loss: 0.2620 - val_kl_loss: 0.0585 - val_beta: 0.3451 - lr: 2.4010e-04\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3148 - reco_loss: 0.2651 - kl_loss: 0.0490 - beta: 0.3993 - val_loss: 0.3004 - val_reco_loss: 0.2449 - val_kl_loss: 0.0555 - val_beta: 0.3993 - lr: 2.4010e-04\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2931 - reco_loss: 0.2465 - kl_loss: 0.0464 - beta: 0.4534 - val_loss: 0.2938 - val_reco_loss: 0.2425 - val_kl_loss: 0.0514 - val_beta: 0.4534 - lr: 2.4010e-04\n",
      "Epoch 63/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2778 - reco_loss: 0.2340 - kl_loss: 0.0428 - beta: 0.5068\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2777 - reco_loss: 0.2339 - kl_loss: 0.0427 - beta: 0.5075 - val_loss: 0.2725 - val_reco_loss: 0.2240 - val_kl_loss: 0.0485 - val_beta: 0.5075 - lr: 2.4010e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 7s 9ms/step - loss: 0.9413 - reco_loss: 0.9226 - kl_loss: 0.0297 - beta: 0.1543 - val_loss: 0.6327 - val_reco_loss: 0.5827 - val_kl_loss: 0.0500 - val_beta: 0.1543 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5791 - reco_loss: 0.5302 - kl_loss: 0.0498 - beta: 0.2085 - val_loss: 0.5077 - val_reco_loss: 0.4472 - val_kl_loss: 0.0605 - val_beta: 0.2085 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4881 - reco_loss: 0.4345 - kl_loss: 0.0542 - beta: 0.2628 - val_loss: 0.4308 - val_reco_loss: 0.3680 - val_kl_loss: 0.0628 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4323 - reco_loss: 0.3790 - kl_loss: 0.0520 - beta: 0.3170 - val_loss: 0.3816 - val_reco_loss: 0.3233 - val_kl_loss: 0.0583 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3893 - reco_loss: 0.3407 - kl_loss: 0.0474 - beta: 0.3711 - val_loss: 0.3572 - val_reco_loss: 0.3055 - val_kl_loss: 0.0517 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3570 - reco_loss: 0.3133 - kl_loss: 0.0433 - beta: 0.4253 - val_loss: 0.3280 - val_reco_loss: 0.2805 - val_kl_loss: 0.0475 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3226 - reco_loss: 0.2827 - kl_loss: 0.0392 - beta: 0.4796 - val_loss: 0.3051 - val_reco_loss: 0.2657 - val_kl_loss: 0.0393 - val_beta: 0.4796 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3044 - reco_loss: 0.2681 - kl_loss: 0.0354 - beta: 0.5335 - val_loss: 0.2781 - val_reco_loss: 0.2443 - val_kl_loss: 0.0338 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2762 - reco_loss: 0.2438 - kl_loss: 0.0311 - beta: 0.5877 - val_loss: 0.2479 - val_reco_loss: 0.2152 - val_kl_loss: 0.0327 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2442 - reco_loss: 0.2165 - kl_loss: 0.0266 - beta: 0.6417 - val_loss: 0.2267 - val_reco_loss: 0.1996 - val_kl_loss: 0.0271 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2158 - reco_loss: 0.1927 - kl_loss: 0.0223 - beta: 0.6958 - val_loss: 0.1938 - val_reco_loss: 0.1702 - val_kl_loss: 0.0237 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3526 - reco_loss: 0.3266 - kl_loss: 0.0371 - beta: 0.1490 - val_loss: 0.3769 - val_reco_loss: 0.3235 - val_kl_loss: 0.0534 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3807 - reco_loss: 0.3289 - kl_loss: 0.0528 - beta: 0.2033 - val_loss: 0.3734 - val_reco_loss: 0.3136 - val_kl_loss: 0.0598 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3702 - reco_loss: 0.3163 - kl_loss: 0.0540 - beta: 0.2578 - val_loss: 0.3586 - val_reco_loss: 0.3011 - val_kl_loss: 0.0575 - val_beta: 0.2578 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3544 - reco_loss: 0.3018 - kl_loss: 0.0516 - beta: 0.3120 - val_loss: 0.3414 - val_reco_loss: 0.2820 - val_kl_loss: 0.0594 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3389 - reco_loss: 0.2898 - kl_loss: 0.0478 - beta: 0.3662 - val_loss: 0.3252 - val_reco_loss: 0.2718 - val_kl_loss: 0.0534 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3160 - reco_loss: 0.2706 - kl_loss: 0.0450 - beta: 0.4204 - val_loss: 0.3148 - val_reco_loss: 0.2675 - val_kl_loss: 0.0473 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2953 - reco_loss: 0.2525 - kl_loss: 0.0425 - beta: 0.4745 - val_loss: 0.2884 - val_reco_loss: 0.2336 - val_kl_loss: 0.0549 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2751 - reco_loss: 0.2352 - kl_loss: 0.0393 - beta: 0.5287 - val_loss: 0.2715 - val_reco_loss: 0.2293 - val_kl_loss: 0.0422 - val_beta: 0.5287 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2546 - reco_loss: 0.2181 - kl_loss: 0.0350 - beta: 0.5827 - val_loss: 0.2439 - val_reco_loss: 0.2078 - val_kl_loss: 0.0361 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.2318 - reco_loss: 0.2007 - kl_loss: 0.0299 - beta: 0.6356\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2316 - reco_loss: 0.2005 - kl_loss: 0.0298 - beta: 0.6368 - val_loss: 0.2255 - val_reco_loss: 0.1905 - val_kl_loss: 0.0350 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2051 - reco_loss: 0.1783 - kl_loss: 0.0257 - beta: 0.6905 - val_loss: 0.1959 - val_reco_loss: 0.1687 - val_kl_loss: 0.0272 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2897 - reco_loss: 0.2649 - kl_loss: 0.0329 - beta: 0.1438 - val_loss: 0.3608 - val_reco_loss: 0.3091 - val_kl_loss: 0.0517 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3548 - reco_loss: 0.3059 - kl_loss: 0.0506 - beta: 0.1981 - val_loss: 0.3503 - val_reco_loss: 0.2899 - val_kl_loss: 0.0605 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3498 - reco_loss: 0.2967 - kl_loss: 0.0533 - beta: 0.2524 - val_loss: 0.3459 - val_reco_loss: 0.2892 - val_kl_loss: 0.0567 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3388 - reco_loss: 0.2854 - kl_loss: 0.0529 - beta: 0.3067 - val_loss: 0.3430 - val_reco_loss: 0.2890 - val_kl_loss: 0.0540 - val_beta: 0.3067 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3264 - reco_loss: 0.2755 - kl_loss: 0.0503 - beta: 0.3608 - val_loss: 0.3250 - val_reco_loss: 0.2663 - val_kl_loss: 0.0587 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3111 - reco_loss: 0.2631 - kl_loss: 0.0474 - beta: 0.4150 - val_loss: 0.3038 - val_reco_loss: 0.2467 - val_kl_loss: 0.0572 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2939 - reco_loss: 0.2483 - kl_loss: 0.0450 - beta: 0.4691 - val_loss: 0.2900 - val_reco_loss: 0.2456 - val_kl_loss: 0.0444 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2763 - reco_loss: 0.2335 - kl_loss: 0.0419 - beta: 0.5232 - val_loss: 0.2701 - val_reco_loss: 0.2223 - val_kl_loss: 0.0479 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2534 - reco_loss: 0.2151 - kl_loss: 0.0372 - beta: 0.5768\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2534 - reco_loss: 0.2150 - kl_loss: 0.0371 - beta: 0.5773 - val_loss: 0.2369 - val_reco_loss: 0.1931 - val_kl_loss: 0.0438 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2297 - reco_loss: 0.1962 - kl_loss: 0.0326 - beta: 0.6311 - val_loss: 0.2235 - val_reco_loss: 0.1887 - val_kl_loss: 0.0348 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2058 - reco_loss: 0.1767 - kl_loss: 0.0277 - beta: 0.6852 - val_loss: 0.2023 - val_reco_loss: 0.1708 - val_kl_loss: 0.0314 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2589 - reco_loss: 0.2348 - kl_loss: 0.0302 - beta: 0.1387 - val_loss: 0.3498 - val_reco_loss: 0.3021 - val_kl_loss: 0.0477 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3531 - reco_loss: 0.3057 - kl_loss: 0.0495 - beta: 0.1929 - val_loss: 0.3444 - val_reco_loss: 0.2874 - val_kl_loss: 0.0570 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3456 - reco_loss: 0.2918 - kl_loss: 0.0540 - beta: 0.2472 - val_loss: 0.3387 - val_reco_loss: 0.2764 - val_kl_loss: 0.0623 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3398 - reco_loss: 0.2861 - kl_loss: 0.0531 - beta: 0.3014 - val_loss: 0.3277 - val_reco_loss: 0.2693 - val_kl_loss: 0.0584 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3247 - reco_loss: 0.2733 - kl_loss: 0.0506 - beta: 0.3556 - val_loss: 0.3250 - val_reco_loss: 0.2726 - val_kl_loss: 0.0524 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3092 - reco_loss: 0.2612 - kl_loss: 0.0476 - beta: 0.4097 - val_loss: 0.3037 - val_reco_loss: 0.2456 - val_kl_loss: 0.0582 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2946 - reco_loss: 0.2484 - kl_loss: 0.0455 - beta: 0.4638 - val_loss: 0.2875 - val_reco_loss: 0.2292 - val_kl_loss: 0.0583 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2781 - reco_loss: 0.2345 - kl_loss: 0.0423 - beta: 0.5162\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2778 - reco_loss: 0.2342 - kl_loss: 0.0422 - beta: 0.5179 - val_loss: 0.2660 - val_reco_loss: 0.2169 - val_kl_loss: 0.0491 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.8812 - reco_loss: 0.8623 - kl_loss: 0.0300 - beta: 0.1544 - val_loss: 0.6160 - val_reco_loss: 0.5673 - val_kl_loss: 0.0488 - val_beta: 0.1544 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5567 - reco_loss: 0.5077 - kl_loss: 0.0513 - beta: 0.2087 - val_loss: 0.4902 - val_reco_loss: 0.4282 - val_kl_loss: 0.0620 - val_beta: 0.2087 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4808 - reco_loss: 0.4269 - kl_loss: 0.0536 - beta: 0.2631 - val_loss: 0.4177 - val_reco_loss: 0.3585 - val_kl_loss: 0.0591 - val_beta: 0.2631 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4228 - reco_loss: 0.3711 - kl_loss: 0.0506 - beta: 0.3171 - val_loss: 0.3779 - val_reco_loss: 0.3197 - val_kl_loss: 0.0582 - val_beta: 0.3171 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3839 - reco_loss: 0.3361 - kl_loss: 0.0466 - beta: 0.3713 - val_loss: 0.3418 - val_reco_loss: 0.2904 - val_kl_loss: 0.0514 - val_beta: 0.3713 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3557 - reco_loss: 0.3119 - kl_loss: 0.0432 - beta: 0.4253 - val_loss: 0.3290 - val_reco_loss: 0.2828 - val_kl_loss: 0.0462 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3231 - reco_loss: 0.2823 - kl_loss: 0.0399 - beta: 0.4795 - val_loss: 0.3068 - val_reco_loss: 0.2649 - val_kl_loss: 0.0419 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2984 - reco_loss: 0.2616 - kl_loss: 0.0358 - beta: 0.5336 - val_loss: 0.2774 - val_reco_loss: 0.2328 - val_kl_loss: 0.0446 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2672 - reco_loss: 0.2346 - kl_loss: 0.0314 - beta: 0.5877 - val_loss: 0.2553 - val_reco_loss: 0.2179 - val_kl_loss: 0.0374 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2418 - reco_loss: 0.2134 - kl_loss: 0.0271 - beta: 0.6418 - val_loss: 0.2278 - val_reco_loss: 0.1959 - val_kl_loss: 0.0319 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2113 - reco_loss: 0.1881 - kl_loss: 0.0223 - beta: 0.6959 - val_loss: 0.2039 - val_reco_loss: 0.1738 - val_kl_loss: 0.0301 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3524 - reco_loss: 0.3265 - kl_loss: 0.0360 - beta: 0.1490 - val_loss: 0.3793 - val_reco_loss: 0.3228 - val_kl_loss: 0.0565 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3775 - reco_loss: 0.3271 - kl_loss: 0.0514 - beta: 0.2033 - val_loss: 0.3778 - val_reco_loss: 0.3200 - val_kl_loss: 0.0578 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3654 - reco_loss: 0.3120 - kl_loss: 0.0534 - beta: 0.2577 - val_loss: 0.3710 - val_reco_loss: 0.3163 - val_kl_loss: 0.0547 - val_beta: 0.2577 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3503 - reco_loss: 0.2976 - kl_loss: 0.0521 - beta: 0.3120 - val_loss: 0.3415 - val_reco_loss: 0.2801 - val_kl_loss: 0.0614 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3325 - reco_loss: 0.2826 - kl_loss: 0.0498 - beta: 0.3662 - val_loss: 0.3264 - val_reco_loss: 0.2643 - val_kl_loss: 0.0621 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3176 - reco_loss: 0.2698 - kl_loss: 0.0464 - beta: 0.4204 - val_loss: 0.3123 - val_reco_loss: 0.2565 - val_kl_loss: 0.0558 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2968 - reco_loss: 0.2531 - kl_loss: 0.0427 - beta: 0.4745 - val_loss: 0.2931 - val_reco_loss: 0.2434 - val_kl_loss: 0.0497 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2760 - reco_loss: 0.2353 - kl_loss: 0.0395 - beta: 0.5286 - val_loss: 0.2688 - val_reco_loss: 0.2244 - val_kl_loss: 0.0444 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2513 - reco_loss: 0.2161 - kl_loss: 0.0346 - beta: 0.5827 - val_loss: 0.2489 - val_reco_loss: 0.2111 - val_kl_loss: 0.0377 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2294 - reco_loss: 0.1987 - kl_loss: 0.0300 - beta: 0.6353\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2293 - reco_loss: 0.1986 - kl_loss: 0.0300 - beta: 0.6368 - val_loss: 0.2230 - val_reco_loss: 0.1850 - val_kl_loss: 0.0380 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2061 - reco_loss: 0.1790 - kl_loss: 0.0256 - beta: 0.6905 - val_loss: 0.2012 - val_reco_loss: 0.1698 - val_kl_loss: 0.0314 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2880 - reco_loss: 0.2631 - kl_loss: 0.0336 - beta: 0.1438 - val_loss: 0.3676 - val_reco_loss: 0.3137 - val_kl_loss: 0.0539 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3559 - reco_loss: 0.3056 - kl_loss: 0.0517 - beta: 0.1981 - val_loss: 0.3564 - val_reco_loss: 0.2980 - val_kl_loss: 0.0585 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3501 - reco_loss: 0.2961 - kl_loss: 0.0543 - beta: 0.2523 - val_loss: 0.3517 - val_reco_loss: 0.2872 - val_kl_loss: 0.0644 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3403 - reco_loss: 0.2861 - kl_loss: 0.0535 - beta: 0.3066 - val_loss: 0.3336 - val_reco_loss: 0.2727 - val_kl_loss: 0.0609 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3295 - reco_loss: 0.2782 - kl_loss: 0.0504 - beta: 0.3609 - val_loss: 0.3312 - val_reco_loss: 0.2661 - val_kl_loss: 0.0651 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3125 - reco_loss: 0.2638 - kl_loss: 0.0473 - beta: 0.4150 - val_loss: 0.3110 - val_reco_loss: 0.2551 - val_kl_loss: 0.0559 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2952 - reco_loss: 0.2501 - kl_loss: 0.0440 - beta: 0.4691 - val_loss: 0.2967 - val_reco_loss: 0.2426 - val_kl_loss: 0.0541 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2736 - reco_loss: 0.2317 - kl_loss: 0.0408 - beta: 0.5232 - val_loss: 0.2734 - val_reco_loss: 0.2264 - val_kl_loss: 0.0469 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2534 - reco_loss: 0.2162 - kl_loss: 0.0359 - beta: 0.5773 - val_loss: 0.2498 - val_reco_loss: 0.2044 - val_kl_loss: 0.0454 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2305 - reco_loss: 0.1978 - kl_loss: 0.0314 - beta: 0.6312\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2305 - reco_loss: 0.1978 - kl_loss: 0.0314 - beta: 0.6314 - val_loss: 0.2250 - val_reco_loss: 0.1873 - val_kl_loss: 0.0377 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2054 - reco_loss: 0.1775 - kl_loss: 0.0265 - beta: 0.6852 - val_loss: 0.1998 - val_reco_loss: 0.1645 - val_kl_loss: 0.0353 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2573 - reco_loss: 0.2339 - kl_loss: 0.0299 - beta: 0.1387 - val_loss: 0.3625 - val_reco_loss: 0.3115 - val_kl_loss: 0.0510 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3505 - reco_loss: 0.3023 - kl_loss: 0.0498 - beta: 0.1929 - val_loss: 0.3590 - val_reco_loss: 0.3003 - val_kl_loss: 0.0587 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3445 - reco_loss: 0.2917 - kl_loss: 0.0531 - beta: 0.2472 - val_loss: 0.3441 - val_reco_loss: 0.2850 - val_kl_loss: 0.0591 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3374 - reco_loss: 0.2843 - kl_loss: 0.0529 - beta: 0.3014 - val_loss: 0.3485 - val_reco_loss: 0.2859 - val_kl_loss: 0.0626 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3245 - reco_loss: 0.2729 - kl_loss: 0.0509 - beta: 0.3556 - val_loss: 0.3326 - val_reco_loss: 0.2755 - val_kl_loss: 0.0571 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3101 - reco_loss: 0.2619 - kl_loss: 0.0476 - beta: 0.4097 - val_loss: 0.3154 - val_reco_loss: 0.2596 - val_kl_loss: 0.0558 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2939 - reco_loss: 0.2486 - kl_loss: 0.0446 - beta: 0.4638 - val_loss: 0.2969 - val_reco_loss: 0.2478 - val_kl_loss: 0.0491 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2747 - reco_loss: 0.2328 - kl_loss: 0.0411 - beta: 0.5179 - val_loss: 0.2731 - val_reco_loss: 0.2267 - val_kl_loss: 0.0464 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2551 - reco_loss: 0.2169 - kl_loss: 0.0370 - beta: 0.5720 - val_loss: 0.2508 - val_reco_loss: 0.2086 - val_kl_loss: 0.0422 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2304 - reco_loss: 0.1972 - kl_loss: 0.0324 - beta: 0.6260\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2303 - reco_loss: 0.1972 - kl_loss: 0.0324 - beta: 0.6260 - val_loss: 0.2295 - val_reco_loss: 0.1929 - val_kl_loss: 0.0367 - val_beta: 0.6260 - lr: 4.9000e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2053 - reco_loss: 0.1766 - kl_loss: 0.0279 - beta: 0.6800 - val_loss: 0.2003 - val_reco_loss: 0.1652 - val_kl_loss: 0.0351 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2367 - reco_loss: 0.2129 - kl_loss: 0.0272 - beta: 0.1337 - val_loss: 0.3661 - val_reco_loss: 0.3175 - val_kl_loss: 0.0486 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3496 - reco_loss: 0.3033 - kl_loss: 0.0482 - beta: 0.1878 - val_loss: 0.3606 - val_reco_loss: 0.3050 - val_kl_loss: 0.0556 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3447 - reco_loss: 0.2926 - kl_loss: 0.0528 - beta: 0.2420 - val_loss: 0.3482 - val_reco_loss: 0.2881 - val_kl_loss: 0.0602 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3345 - reco_loss: 0.2813 - kl_loss: 0.0531 - beta: 0.2962 - val_loss: 0.3437 - val_reco_loss: 0.2802 - val_kl_loss: 0.0636 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3260 - reco_loss: 0.2740 - kl_loss: 0.0513 - beta: 0.3503 - val_loss: 0.3364 - val_reco_loss: 0.2756 - val_kl_loss: 0.0607 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3113 - reco_loss: 0.2617 - kl_loss: 0.0489 - beta: 0.4044 - val_loss: 0.3109 - val_reco_loss: 0.2495 - val_kl_loss: 0.0613 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2938 - reco_loss: 0.2473 - kl_loss: 0.0458 - beta: 0.4586 - val_loss: 0.3032 - val_reco_loss: 0.2486 - val_kl_loss: 0.0546 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2759 - reco_loss: 0.2331 - kl_loss: 0.0421 - beta: 0.5126 - val_loss: 0.2728 - val_reco_loss: 0.2205 - val_kl_loss: 0.0523 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 53/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2554 - reco_loss: 0.2165 - kl_loss: 0.0379 - beta: 0.5660\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2554 - reco_loss: 0.2164 - kl_loss: 0.0378 - beta: 0.5667 - val_loss: 0.2462 - val_reco_loss: 0.2034 - val_kl_loss: 0.0428 - val_beta: 0.5667 - lr: 3.4300e-04\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2321 - reco_loss: 0.1978 - kl_loss: 0.0336 - beta: 0.6207 - val_loss: 0.2200 - val_reco_loss: 0.1793 - val_kl_loss: 0.0407 - val_beta: 0.6207 - lr: 2.4010e-04\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2080 - reco_loss: 0.1778 - kl_loss: 0.0295 - beta: 0.6748 - val_loss: 0.2050 - val_reco_loss: 0.1668 - val_kl_loss: 0.0382 - val_beta: 0.6748 - lr: 2.4010e-04\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2236 - reco_loss: 0.1988 - kl_loss: 0.0252 - beta: 0.1286 - val_loss: 0.3673 - val_reco_loss: 0.3235 - val_kl_loss: 0.0438 - val_beta: 0.1286 - lr: 2.4010e-04\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3504 - reco_loss: 0.3069 - kl_loss: 0.0467 - beta: 0.1827 - val_loss: 0.3605 - val_reco_loss: 0.3052 - val_kl_loss: 0.0553 - val_beta: 0.1827 - lr: 2.4010e-04\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3446 - reco_loss: 0.2925 - kl_loss: 0.0527 - beta: 0.2369 - val_loss: 0.3484 - val_reco_loss: 0.2881 - val_kl_loss: 0.0603 - val_beta: 0.2369 - lr: 2.4010e-04\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3343 - reco_loss: 0.2812 - kl_loss: 0.0532 - beta: 0.2910 - val_loss: 0.3438 - val_reco_loss: 0.2823 - val_kl_loss: 0.0615 - val_beta: 0.2910 - lr: 2.4010e-04\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3250 - reco_loss: 0.2732 - kl_loss: 0.0514 - beta: 0.3451 - val_loss: 0.3300 - val_reco_loss: 0.2719 - val_kl_loss: 0.0581 - val_beta: 0.3451 - lr: 2.4010e-04\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3110 - reco_loss: 0.2619 - kl_loss: 0.0489 - beta: 0.3992 - val_loss: 0.3089 - val_reco_loss: 0.2489 - val_kl_loss: 0.0599 - val_beta: 0.3992 - lr: 2.4010e-04\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2958 - reco_loss: 0.2485 - kl_loss: 0.0462 - beta: 0.4534 - val_loss: 0.2963 - val_reco_loss: 0.2469 - val_kl_loss: 0.0494 - val_beta: 0.4534 - lr: 2.4010e-04\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2779 - reco_loss: 0.2344 - kl_loss: 0.0428 - beta: 0.5074\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2779 - reco_loss: 0.2344 - kl_loss: 0.0428 - beta: 0.5074 - val_loss: 0.2824 - val_reco_loss: 0.2285 - val_kl_loss: 0.0539 - val_beta: 0.5074 - lr: 2.4010e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 11ms/step - loss: 1.0116 - reco_loss: 1.0005 - kl_loss: 0.0198 - beta: 0.1545 - val_loss: 0.6415 - val_reco_loss: 0.6009 - val_kl_loss: 0.0405 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5784 - reco_loss: 0.5351 - kl_loss: 0.0472 - beta: 0.2086 - val_loss: 0.5236 - val_reco_loss: 0.4670 - val_kl_loss: 0.0567 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5017 - reco_loss: 0.4483 - kl_loss: 0.0536 - beta: 0.2627 - val_loss: 0.4665 - val_reco_loss: 0.4068 - val_kl_loss: 0.0597 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4419 - reco_loss: 0.3897 - kl_loss: 0.0516 - beta: 0.3170 - val_loss: 0.4209 - val_reco_loss: 0.3685 - val_kl_loss: 0.0524 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4065 - reco_loss: 0.3578 - kl_loss: 0.0473 - beta: 0.3713 - val_loss: 0.3761 - val_reco_loss: 0.3245 - val_kl_loss: 0.0516 - val_beta: 0.3713 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3646 - reco_loss: 0.3208 - kl_loss: 0.0430 - beta: 0.4254 - val_loss: 0.3387 - val_reco_loss: 0.2890 - val_kl_loss: 0.0496 - val_beta: 0.4254 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3326 - reco_loss: 0.2923 - kl_loss: 0.0393 - beta: 0.4794 - val_loss: 0.3129 - val_reco_loss: 0.2664 - val_kl_loss: 0.0465 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3031 - reco_loss: 0.2663 - kl_loss: 0.0360 - beta: 0.5336 - val_loss: 0.2841 - val_reco_loss: 0.2408 - val_kl_loss: 0.0433 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2766 - reco_loss: 0.2431 - kl_loss: 0.0318 - beta: 0.5876 - val_loss: 0.2599 - val_reco_loss: 0.2216 - val_kl_loss: 0.0383 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2434 - reco_loss: 0.2152 - kl_loss: 0.0270 - beta: 0.6417 - val_loss: 0.2314 - val_reco_loss: 0.2000 - val_kl_loss: 0.0314 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2152 - reco_loss: 0.1916 - kl_loss: 0.0224 - beta: 0.6959 - val_loss: 0.1980 - val_reco_loss: 0.1722 - val_kl_loss: 0.0258 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3545 - reco_loss: 0.3288 - kl_loss: 0.0367 - beta: 0.1490 - val_loss: 0.3811 - val_reco_loss: 0.3288 - val_kl_loss: 0.0523 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3834 - reco_loss: 0.3317 - kl_loss: 0.0529 - beta: 0.2032 - val_loss: 0.3777 - val_reco_loss: 0.3193 - val_kl_loss: 0.0584 - val_beta: 0.2032 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3718 - reco_loss: 0.3180 - kl_loss: 0.0541 - beta: 0.2576 - val_loss: 0.3643 - val_reco_loss: 0.3050 - val_kl_loss: 0.0593 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3543 - reco_loss: 0.3017 - kl_loss: 0.0516 - beta: 0.3119 - val_loss: 0.3612 - val_reco_loss: 0.3024 - val_kl_loss: 0.0588 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3355 - reco_loss: 0.2861 - kl_loss: 0.0487 - beta: 0.3662 - val_loss: 0.3388 - val_reco_loss: 0.2809 - val_kl_loss: 0.0579 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3178 - reco_loss: 0.2706 - kl_loss: 0.0463 - beta: 0.4203 - val_loss: 0.3157 - val_reco_loss: 0.2606 - val_kl_loss: 0.0551 - val_beta: 0.4203 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2961 - reco_loss: 0.2526 - kl_loss: 0.0430 - beta: 0.4745 - val_loss: 0.3045 - val_reco_loss: 0.2533 - val_kl_loss: 0.0511 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2787 - reco_loss: 0.2390 - kl_loss: 0.0389 - beta: 0.5286 - val_loss: 0.2792 - val_reco_loss: 0.2372 - val_kl_loss: 0.0421 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2551 - reco_loss: 0.2192 - kl_loss: 0.0347 - beta: 0.5827 - val_loss: 0.2502 - val_reco_loss: 0.2105 - val_kl_loss: 0.0397 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2320 - reco_loss: 0.2007 - kl_loss: 0.0301 - beta: 0.6353\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2318 - reco_loss: 0.2005 - kl_loss: 0.0301 - beta: 0.6368 - val_loss: 0.2220 - val_reco_loss: 0.1890 - val_kl_loss: 0.0331 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.2031 - reco_loss: 0.1769 - kl_loss: 0.0251 - beta: 0.6905 - val_loss: 0.1975 - val_reco_loss: 0.1704 - val_kl_loss: 0.0270 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2906 - reco_loss: 0.2654 - kl_loss: 0.0338 - beta: 0.1438 - val_loss: 0.3673 - val_reco_loss: 0.3174 - val_kl_loss: 0.0499 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3591 - reco_loss: 0.3085 - kl_loss: 0.0517 - beta: 0.1981 - val_loss: 0.3613 - val_reco_loss: 0.3004 - val_kl_loss: 0.0609 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3505 - reco_loss: 0.2960 - kl_loss: 0.0543 - beta: 0.2524 - val_loss: 0.3520 - val_reco_loss: 0.2907 - val_kl_loss: 0.0613 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3380 - reco_loss: 0.2848 - kl_loss: 0.0528 - beta: 0.3066 - val_loss: 0.3479 - val_reco_loss: 0.2892 - val_kl_loss: 0.0587 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3250 - reco_loss: 0.2748 - kl_loss: 0.0498 - beta: 0.3608 - val_loss: 0.3269 - val_reco_loss: 0.2723 - val_kl_loss: 0.0547 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3123 - reco_loss: 0.2649 - kl_loss: 0.0467 - beta: 0.4150 - val_loss: 0.3178 - val_reco_loss: 0.2652 - val_kl_loss: 0.0526 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2939 - reco_loss: 0.2496 - kl_loss: 0.0438 - beta: 0.4691 - val_loss: 0.2980 - val_reco_loss: 0.2490 - val_kl_loss: 0.0490 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2754 - reco_loss: 0.2344 - kl_loss: 0.0402 - beta: 0.5232 - val_loss: 0.2731 - val_reco_loss: 0.2286 - val_kl_loss: 0.0445 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2525 - reco_loss: 0.2154 - kl_loss: 0.0360 - beta: 0.5773 - val_loss: 0.2516 - val_reco_loss: 0.2168 - val_kl_loss: 0.0348 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2297 - reco_loss: 0.1979 - kl_loss: 0.0308 - beta: 0.6311\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2297 - reco_loss: 0.1979 - kl_loss: 0.0308 - beta: 0.6314 - val_loss: 0.2307 - val_reco_loss: 0.1972 - val_kl_loss: 0.0335 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2062 - reco_loss: 0.1784 - kl_loss: 0.0265 - beta: 0.6852 - val_loss: 0.1955 - val_reco_loss: 0.1661 - val_kl_loss: 0.0294 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2603 - reco_loss: 0.2365 - kl_loss: 0.0301 - beta: 0.1387 - val_loss: 0.3569 - val_reco_loss: 0.3081 - val_kl_loss: 0.0487 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3528 - reco_loss: 0.3045 - kl_loss: 0.0503 - beta: 0.1929 - val_loss: 0.3603 - val_reco_loss: 0.3027 - val_kl_loss: 0.0576 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3468 - reco_loss: 0.2933 - kl_loss: 0.0539 - beta: 0.2471 - val_loss: 0.3486 - val_reco_loss: 0.2875 - val_kl_loss: 0.0611 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3375 - reco_loss: 0.2833 - kl_loss: 0.0536 - beta: 0.3014 - val_loss: 0.3403 - val_reco_loss: 0.2840 - val_kl_loss: 0.0563 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3247 - reco_loss: 0.2733 - kl_loss: 0.0508 - beta: 0.3555 - val_loss: 0.3236 - val_reco_loss: 0.2638 - val_kl_loss: 0.0597 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3108 - reco_loss: 0.2622 - kl_loss: 0.0480 - beta: 0.4097 - val_loss: 0.3101 - val_reco_loss: 0.2557 - val_kl_loss: 0.0544 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2926 - reco_loss: 0.2470 - kl_loss: 0.0449 - beta: 0.4638 - val_loss: 0.2994 - val_reco_loss: 0.2452 - val_kl_loss: 0.0542 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2760 - reco_loss: 0.2334 - kl_loss: 0.0415 - beta: 0.5179 - val_loss: 0.2740 - val_reco_loss: 0.2278 - val_kl_loss: 0.0462 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2566 - reco_loss: 0.2181 - kl_loss: 0.0375 - beta: 0.5720 - val_loss: 0.2570 - val_reco_loss: 0.2186 - val_kl_loss: 0.0384 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2312 - reco_loss: 0.1976 - kl_loss: 0.0326 - beta: 0.6256\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2312 - reco_loss: 0.1975 - kl_loss: 0.0326 - beta: 0.6261 - val_loss: 0.2280 - val_reco_loss: 0.1925 - val_kl_loss: 0.0355 - val_beta: 0.6261 - lr: 4.9000e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2069 - reco_loss: 0.1776 - kl_loss: 0.0284 - beta: 0.6800 - val_loss: 0.1955 - val_reco_loss: 0.1632 - val_kl_loss: 0.0323 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2402 - reco_loss: 0.2163 - kl_loss: 0.0266 - beta: 0.1337 - val_loss: 0.3660 - val_reco_loss: 0.3184 - val_kl_loss: 0.0476 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3513 - reco_loss: 0.3050 - kl_loss: 0.0488 - beta: 0.1878 - val_loss: 0.3584 - val_reco_loss: 0.3009 - val_kl_loss: 0.0575 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3469 - reco_loss: 0.2936 - kl_loss: 0.0537 - beta: 0.2420 - val_loss: 0.3475 - val_reco_loss: 0.2847 - val_kl_loss: 0.0628 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3370 - reco_loss: 0.2829 - kl_loss: 0.0538 - beta: 0.2962 - val_loss: 0.3402 - val_reco_loss: 0.2771 - val_kl_loss: 0.0631 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3258 - reco_loss: 0.2730 - kl_loss: 0.0516 - beta: 0.3503 - val_loss: 0.3329 - val_reco_loss: 0.2728 - val_kl_loss: 0.0601 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3118 - reco_loss: 0.2620 - kl_loss: 0.0492 - beta: 0.4044 - val_loss: 0.3190 - val_reco_loss: 0.2658 - val_kl_loss: 0.0532 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2946 - reco_loss: 0.2483 - kl_loss: 0.0460 - beta: 0.4586 - val_loss: 0.2946 - val_reco_loss: 0.2426 - val_kl_loss: 0.0520 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2752 - reco_loss: 0.2320 - kl_loss: 0.0423 - beta: 0.5127 - val_loss: 0.2762 - val_reco_loss: 0.2311 - val_kl_loss: 0.0451 - val_beta: 0.5127 - lr: 3.4300e-04\n",
      "Epoch 53/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2550 - reco_loss: 0.2162 - kl_loss: 0.0380 - beta: 0.5664\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2550 - reco_loss: 0.2162 - kl_loss: 0.0380 - beta: 0.5667 - val_loss: 0.2440 - val_reco_loss: 0.1972 - val_kl_loss: 0.0468 - val_beta: 0.5667 - lr: 3.4300e-04\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2342 - reco_loss: 0.1985 - kl_loss: 0.0342 - beta: 0.6207 - val_loss: 0.2269 - val_reco_loss: 0.1878 - val_kl_loss: 0.0391 - val_beta: 0.6207 - lr: 2.4010e-04\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2095 - reco_loss: 0.1782 - kl_loss: 0.0300 - beta: 0.6748 - val_loss: 0.2085 - val_reco_loss: 0.1756 - val_kl_loss: 0.0329 - val_beta: 0.6748 - lr: 2.4010e-04\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2241 - reco_loss: 0.1995 - kl_loss: 0.0245 - beta: 0.1286 - val_loss: 0.3684 - val_reco_loss: 0.3276 - val_kl_loss: 0.0408 - val_beta: 0.1286 - lr: 2.4010e-04\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3507 - reco_loss: 0.3081 - kl_loss: 0.0462 - beta: 0.1827 - val_loss: 0.3572 - val_reco_loss: 0.3031 - val_kl_loss: 0.0541 - val_beta: 0.1827 - lr: 2.4010e-04\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3437 - reco_loss: 0.2914 - kl_loss: 0.0528 - beta: 0.2369 - val_loss: 0.3561 - val_reco_loss: 0.2978 - val_kl_loss: 0.0583 - val_beta: 0.2369 - lr: 2.4010e-04\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3367 - reco_loss: 0.2830 - kl_loss: 0.0537 - beta: 0.2910 - val_loss: 0.3381 - val_reco_loss: 0.2753 - val_kl_loss: 0.0627 - val_beta: 0.2910 - lr: 2.4010e-04\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3249 - reco_loss: 0.2725 - kl_loss: 0.0518 - beta: 0.3451 - val_loss: 0.3215 - val_reco_loss: 0.2600 - val_kl_loss: 0.0616 - val_beta: 0.3451 - lr: 2.4010e-04\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3143 - reco_loss: 0.2640 - kl_loss: 0.0498 - beta: 0.3993 - val_loss: 0.3147 - val_reco_loss: 0.2582 - val_kl_loss: 0.0565 - val_beta: 0.3993 - lr: 2.4010e-04\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2948 - reco_loss: 0.2470 - kl_loss: 0.0474 - beta: 0.4534 - val_loss: 0.2935 - val_reco_loss: 0.2444 - val_kl_loss: 0.0491 - val_beta: 0.4534 - lr: 2.4010e-04\n",
      "Epoch 63/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2787 - reco_loss: 0.2343 - kl_loss: 0.0433 - beta: 0.5058\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2785 - reco_loss: 0.2342 - kl_loss: 0.0432 - beta: 0.5074 - val_loss: 0.2715 - val_reco_loss: 0.2227 - val_kl_loss: 0.0487 - val_beta: 0.5074 - lr: 2.4010e-04\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2586 - reco_loss: 0.2177 - kl_loss: 0.0398 - beta: 0.5614 - val_loss: 0.2525 - val_reco_loss: 0.2104 - val_kl_loss: 0.0421 - val_beta: 0.5614 - lr: 1.6807e-04\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2365 - reco_loss: 0.1994 - kl_loss: 0.0357 - beta: 0.6155 - val_loss: 0.2268 - val_reco_loss: 0.1891 - val_kl_loss: 0.0376 - val_beta: 0.6155 - lr: 1.6807e-04\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2128 - reco_loss: 0.1801 - kl_loss: 0.0316 - beta: 0.6696 - val_loss: 0.2084 - val_reco_loss: 0.1758 - val_kl_loss: 0.0326 - val_beta: 0.6696 - lr: 1.6807e-04\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2137 - reco_loss: 0.1877 - kl_loss: 0.0228 - beta: 0.1236 - val_loss: 0.3714 - val_reco_loss: 0.3365 - val_kl_loss: 0.0348 - val_beta: 0.1236 - lr: 1.6807e-04\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3540 - reco_loss: 0.3164 - kl_loss: 0.0428 - beta: 0.1776 - val_loss: 0.3560 - val_reco_loss: 0.3029 - val_kl_loss: 0.0530 - val_beta: 0.1776 - lr: 1.6807e-04\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3413 - reco_loss: 0.2905 - kl_loss: 0.0524 - beta: 0.2317 - val_loss: 0.3437 - val_reco_loss: 0.2833 - val_kl_loss: 0.0605 - val_beta: 0.2317 - lr: 1.6807e-04\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3369 - reco_loss: 0.2828 - kl_loss: 0.0537 - beta: 0.2859 - val_loss: 0.3411 - val_reco_loss: 0.2773 - val_kl_loss: 0.0638 - val_beta: 0.2859 - lr: 1.6807e-04\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3261 - reco_loss: 0.2729 - kl_loss: 0.0526 - beta: 0.3400 - val_loss: 0.3272 - val_reco_loss: 0.2684 - val_kl_loss: 0.0587 - val_beta: 0.3400 - lr: 1.6807e-04\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3110 - reco_loss: 0.2603 - kl_loss: 0.0500 - beta: 0.3941 - val_loss: 0.3119 - val_reco_loss: 0.2530 - val_kl_loss: 0.0588 - val_beta: 0.3941 - lr: 1.6807e-04\n",
      "Epoch 73/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2968 - reco_loss: 0.2490 - kl_loss: 0.0473 - beta: 0.4475\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2968 - reco_loss: 0.2489 - kl_loss: 0.0473 - beta: 0.4482 - val_loss: 0.2924 - val_reco_loss: 0.2370 - val_kl_loss: 0.0555 - val_beta: 0.4482 - lr: 1.6807e-04\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2783 - reco_loss: 0.2331 - kl_loss: 0.0441 - beta: 0.5022 - val_loss: 0.2763 - val_reco_loss: 0.2285 - val_kl_loss: 0.0478 - val_beta: 0.5022 - lr: 1.1765e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 10ms/step - loss: 0.9514 - reco_loss: 0.9419 - kl_loss: 0.0195 - beta: 0.1544 - val_loss: 0.6412 - val_reco_loss: 0.5985 - val_kl_loss: 0.0427 - val_beta: 0.1544 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5591 - reco_loss: 0.5108 - kl_loss: 0.0513 - beta: 0.2086 - val_loss: 0.5028 - val_reco_loss: 0.4459 - val_kl_loss: 0.0569 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4713 - reco_loss: 0.4170 - kl_loss: 0.0549 - beta: 0.2627 - val_loss: 0.4180 - val_reco_loss: 0.3554 - val_kl_loss: 0.0627 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4343 - reco_loss: 0.3805 - kl_loss: 0.0526 - beta: 0.3169 - val_loss: 0.3822 - val_reco_loss: 0.3245 - val_kl_loss: 0.0577 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3776 - reco_loss: 0.3291 - kl_loss: 0.0477 - beta: 0.3713 - val_loss: 0.3489 - val_reco_loss: 0.2967 - val_kl_loss: 0.0522 - val_beta: 0.3713 - lr: 0.0010\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3616 - reco_loss: 0.3172 - kl_loss: 0.0439 - beta: 0.4253 - val_loss: 0.3322 - val_reco_loss: 0.2875 - val_kl_loss: 0.0447 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3279 - reco_loss: 0.2881 - kl_loss: 0.0394 - beta: 0.4794 - val_loss: 0.3032 - val_reco_loss: 0.2589 - val_kl_loss: 0.0443 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3017 - reco_loss: 0.2644 - kl_loss: 0.0359 - beta: 0.5335 - val_loss: 0.2835 - val_reco_loss: 0.2438 - val_kl_loss: 0.0397 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2760 - reco_loss: 0.2434 - kl_loss: 0.0313 - beta: 0.5876 - val_loss: 0.2479 - val_reco_loss: 0.2150 - val_kl_loss: 0.0329 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2392 - reco_loss: 0.2116 - kl_loss: 0.0265 - beta: 0.6418 - val_loss: 0.2233 - val_reco_loss: 0.1955 - val_kl_loss: 0.0279 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2131 - reco_loss: 0.1899 - kl_loss: 0.0223 - beta: 0.6959 - val_loss: 0.1971 - val_reco_loss: 0.1720 - val_kl_loss: 0.0251 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3511 - reco_loss: 0.3266 - kl_loss: 0.0355 - beta: 0.1490 - val_loss: 0.3703 - val_reco_loss: 0.3195 - val_kl_loss: 0.0508 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3809 - reco_loss: 0.3296 - kl_loss: 0.0523 - beta: 0.2033 - val_loss: 0.3709 - val_reco_loss: 0.3135 - val_kl_loss: 0.0574 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3730 - reco_loss: 0.3185 - kl_loss: 0.0543 - beta: 0.2576 - val_loss: 0.3562 - val_reco_loss: 0.2940 - val_kl_loss: 0.0622 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3531 - reco_loss: 0.2995 - kl_loss: 0.0527 - beta: 0.3119 - val_loss: 0.3419 - val_reco_loss: 0.2824 - val_kl_loss: 0.0596 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3393 - reco_loss: 0.2887 - kl_loss: 0.0493 - beta: 0.3662 - val_loss: 0.3270 - val_reco_loss: 0.2701 - val_kl_loss: 0.0569 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3183 - reco_loss: 0.2713 - kl_loss: 0.0460 - beta: 0.4205 - val_loss: 0.3139 - val_reco_loss: 0.2597 - val_kl_loss: 0.0542 - val_beta: 0.4205 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3008 - reco_loss: 0.2570 - kl_loss: 0.0430 - beta: 0.4744 - val_loss: 0.2934 - val_reco_loss: 0.2422 - val_kl_loss: 0.0512 - val_beta: 0.4744 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2775 - reco_loss: 0.2376 - kl_loss: 0.0389 - beta: 0.5286 - val_loss: 0.2687 - val_reco_loss: 0.2245 - val_kl_loss: 0.0442 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2569 - reco_loss: 0.2211 - kl_loss: 0.0346 - beta: 0.5827 - val_loss: 0.2446 - val_reco_loss: 0.2054 - val_kl_loss: 0.0392 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2314 - reco_loss: 0.2006 - kl_loss: 0.0297 - beta: 0.6368\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2314 - reco_loss: 0.2006 - kl_loss: 0.0297 - beta: 0.6368 - val_loss: 0.2216 - val_reco_loss: 0.1853 - val_kl_loss: 0.0364 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2038 - reco_loss: 0.1784 - kl_loss: 0.0248 - beta: 0.6905 - val_loss: 0.1916 - val_reco_loss: 0.1628 - val_kl_loss: 0.0288 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2923 - reco_loss: 0.2687 - kl_loss: 0.0324 - beta: 0.1438 - val_loss: 0.3555 - val_reco_loss: 0.3043 - val_kl_loss: 0.0512 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3560 - reco_loss: 0.3065 - kl_loss: 0.0512 - beta: 0.1981 - val_loss: 0.3517 - val_reco_loss: 0.2943 - val_kl_loss: 0.0574 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3528 - reco_loss: 0.2992 - kl_loss: 0.0539 - beta: 0.2523 - val_loss: 0.3437 - val_reco_loss: 0.2826 - val_kl_loss: 0.0611 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3414 - reco_loss: 0.2879 - kl_loss: 0.0530 - beta: 0.3066 - val_loss: 0.3366 - val_reco_loss: 0.2769 - val_kl_loss: 0.0598 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3293 - reco_loss: 0.2779 - kl_loss: 0.0507 - beta: 0.3608 - val_loss: 0.3248 - val_reco_loss: 0.2680 - val_kl_loss: 0.0568 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3182 - reco_loss: 0.2696 - kl_loss: 0.0475 - beta: 0.4150 - val_loss: 0.3056 - val_reco_loss: 0.2523 - val_kl_loss: 0.0533 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2968 - reco_loss: 0.2515 - kl_loss: 0.0447 - beta: 0.4691 - val_loss: 0.2927 - val_reco_loss: 0.2449 - val_kl_loss: 0.0478 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2779 - reco_loss: 0.2357 - kl_loss: 0.0411 - beta: 0.5232 - val_loss: 0.2731 - val_reco_loss: 0.2298 - val_kl_loss: 0.0433 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2547 - reco_loss: 0.2171 - kl_loss: 0.0367 - beta: 0.5773 - val_loss: 0.2503 - val_reco_loss: 0.2077 - val_kl_loss: 0.0425 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2314 - reco_loss: 0.1985 - kl_loss: 0.0316 - beta: 0.6304\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2313 - reco_loss: 0.1984 - kl_loss: 0.0316 - beta: 0.6314 - val_loss: 0.2240 - val_reco_loss: 0.1884 - val_kl_loss: 0.0356 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2065 - reco_loss: 0.1788 - kl_loss: 0.0267 - beta: 0.6852 - val_loss: 0.2039 - val_reco_loss: 0.1733 - val_kl_loss: 0.0306 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2627 - reco_loss: 0.2393 - kl_loss: 0.0287 - beta: 0.1387 - val_loss: 0.3579 - val_reco_loss: 0.3063 - val_kl_loss: 0.0515 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3512 - reco_loss: 0.3035 - kl_loss: 0.0498 - beta: 0.1929 - val_loss: 0.3482 - val_reco_loss: 0.2885 - val_kl_loss: 0.0597 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3472 - reco_loss: 0.2936 - kl_loss: 0.0539 - beta: 0.2472 - val_loss: 0.3474 - val_reco_loss: 0.2842 - val_kl_loss: 0.0632 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3400 - reco_loss: 0.2860 - kl_loss: 0.0537 - beta: 0.3014 - val_loss: 0.3308 - val_reco_loss: 0.2716 - val_kl_loss: 0.0592 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3286 - reco_loss: 0.2767 - kl_loss: 0.0511 - beta: 0.3556 - val_loss: 0.3182 - val_reco_loss: 0.2598 - val_kl_loss: 0.0584 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3146 - reco_loss: 0.2653 - kl_loss: 0.0486 - beta: 0.4097 - val_loss: 0.3127 - val_reco_loss: 0.2628 - val_kl_loss: 0.0500 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2969 - reco_loss: 0.2506 - kl_loss: 0.0450 - beta: 0.4638 - val_loss: 0.2931 - val_reco_loss: 0.2381 - val_kl_loss: 0.0550 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2749 - reco_loss: 0.2321 - kl_loss: 0.0418 - beta: 0.5179 - val_loss: 0.2744 - val_reco_loss: 0.2289 - val_kl_loss: 0.0456 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2560 - reco_loss: 0.2171 - kl_loss: 0.0379 - beta: 0.5720\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2560 - reco_loss: 0.2171 - kl_loss: 0.0379 - beta: 0.5720 - val_loss: 0.2500 - val_reco_loss: 0.2097 - val_kl_loss: 0.0403 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2325 - reco_loss: 0.1987 - kl_loss: 0.0328 - beta: 0.6259 - val_loss: 0.2331 - val_reco_loss: 0.1954 - val_kl_loss: 0.0377 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2081 - reco_loss: 0.1789 - kl_loss: 0.0283 - beta: 0.6800 - val_loss: 0.1982 - val_reco_loss: 0.1667 - val_kl_loss: 0.0314 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2408 - reco_loss: 0.2166 - kl_loss: 0.0271 - beta: 0.1337 - val_loss: 0.3630 - val_reco_loss: 0.3174 - val_kl_loss: 0.0456 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3517 - reco_loss: 0.3051 - kl_loss: 0.0486 - beta: 0.1878 - val_loss: 0.3525 - val_reco_loss: 0.2923 - val_kl_loss: 0.0602 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3475 - reco_loss: 0.2946 - kl_loss: 0.0533 - beta: 0.2420 - val_loss: 0.3494 - val_reco_loss: 0.2859 - val_kl_loss: 0.0636 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3387 - reco_loss: 0.2847 - kl_loss: 0.0537 - beta: 0.2962 - val_loss: 0.3406 - val_reco_loss: 0.2816 - val_kl_loss: 0.0590 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3282 - reco_loss: 0.2759 - kl_loss: 0.0518 - beta: 0.3503 - val_loss: 0.3268 - val_reco_loss: 0.2672 - val_kl_loss: 0.0596 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3115 - reco_loss: 0.2616 - kl_loss: 0.0494 - beta: 0.4044 - val_loss: 0.3108 - val_reco_loss: 0.2585 - val_kl_loss: 0.0523 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2995 - reco_loss: 0.2528 - kl_loss: 0.0461 - beta: 0.4586 - val_loss: 0.2951 - val_reco_loss: 0.2459 - val_kl_loss: 0.0493 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2773 - reco_loss: 0.2337 - kl_loss: 0.0427 - beta: 0.5121\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2772 - reco_loss: 0.2337 - kl_loss: 0.0427 - beta: 0.5127 - val_loss: 0.2691 - val_reco_loss: 0.2210 - val_kl_loss: 0.0481 - val_beta: 0.5127 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 10ms/step - loss: 0.9694 - reco_loss: 0.9556 - kl_loss: 0.0220 - beta: 0.1547 - val_loss: 0.6871 - val_reco_loss: 0.6529 - val_kl_loss: 0.0342 - val_beta: 0.1547 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5956 - reco_loss: 0.5574 - kl_loss: 0.0422 - beta: 0.2087 - val_loss: 0.5164 - val_reco_loss: 0.4630 - val_kl_loss: 0.0534 - val_beta: 0.2087 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4966 - reco_loss: 0.4456 - kl_loss: 0.0516 - beta: 0.2627 - val_loss: 0.4054 - val_reco_loss: 0.3455 - val_kl_loss: 0.0600 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4220 - reco_loss: 0.3704 - kl_loss: 0.0508 - beta: 0.3169 - val_loss: 0.3778 - val_reco_loss: 0.3183 - val_kl_loss: 0.0595 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3896 - reco_loss: 0.3427 - kl_loss: 0.0462 - beta: 0.3711 - val_loss: 0.3489 - val_reco_loss: 0.2980 - val_kl_loss: 0.0510 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3676 - reco_loss: 0.3244 - kl_loss: 0.0418 - beta: 0.4254 - val_loss: 0.3267 - val_reco_loss: 0.2821 - val_kl_loss: 0.0446 - val_beta: 0.4254 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3276 - reco_loss: 0.2886 - kl_loss: 0.0382 - beta: 0.4794 - val_loss: 0.3073 - val_reco_loss: 0.2636 - val_kl_loss: 0.0437 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3015 - reco_loss: 0.2658 - kl_loss: 0.0345 - beta: 0.5335 - val_loss: 0.2676 - val_reco_loss: 0.2300 - val_kl_loss: 0.0376 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2704 - reco_loss: 0.2391 - kl_loss: 0.0305 - beta: 0.5877 - val_loss: 0.2552 - val_reco_loss: 0.2214 - val_kl_loss: 0.0338 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2457 - reco_loss: 0.2185 - kl_loss: 0.0259 - beta: 0.6417 - val_loss: 0.2252 - val_reco_loss: 0.1958 - val_kl_loss: 0.0294 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2123 - reco_loss: 0.1897 - kl_loss: 0.0219 - beta: 0.6959 - val_loss: 0.1975 - val_reco_loss: 0.1687 - val_kl_loss: 0.0288 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3524 - reco_loss: 0.3280 - kl_loss: 0.0353 - beta: 0.1490 - val_loss: 0.3785 - val_reco_loss: 0.3263 - val_kl_loss: 0.0521 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3912 - reco_loss: 0.3399 - kl_loss: 0.0526 - beta: 0.2034 - val_loss: 0.3778 - val_reco_loss: 0.3200 - val_kl_loss: 0.0578 - val_beta: 0.2034 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3773 - reco_loss: 0.3224 - kl_loss: 0.0548 - beta: 0.2576 - val_loss: 0.3656 - val_reco_loss: 0.3050 - val_kl_loss: 0.0605 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3610 - reco_loss: 0.3075 - kl_loss: 0.0525 - beta: 0.3119 - val_loss: 0.3480 - val_reco_loss: 0.2879 - val_kl_loss: 0.0600 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3454 - reco_loss: 0.2959 - kl_loss: 0.0487 - beta: 0.3661 - val_loss: 0.3361 - val_reco_loss: 0.2800 - val_kl_loss: 0.0562 - val_beta: 0.3661 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3272 - reco_loss: 0.2818 - kl_loss: 0.0451 - beta: 0.4203 - val_loss: 0.3200 - val_reco_loss: 0.2673 - val_kl_loss: 0.0527 - val_beta: 0.4203 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3107 - reco_loss: 0.2673 - kl_loss: 0.0423 - beta: 0.4744 - val_loss: 0.2963 - val_reco_loss: 0.2493 - val_kl_loss: 0.0470 - val_beta: 0.4744 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2839 - reco_loss: 0.2441 - kl_loss: 0.0386 - beta: 0.5286 - val_loss: 0.2670 - val_reco_loss: 0.2221 - val_kl_loss: 0.0449 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2606 - reco_loss: 0.2256 - kl_loss: 0.0340 - beta: 0.5826 - val_loss: 0.2468 - val_reco_loss: 0.2079 - val_kl_loss: 0.0388 - val_beta: 0.5826 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2364 - reco_loss: 0.2060 - kl_loss: 0.0295 - beta: 0.6367\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2364 - reco_loss: 0.2060 - kl_loss: 0.0295 - beta: 0.6367 - val_loss: 0.2271 - val_reco_loss: 0.1924 - val_kl_loss: 0.0347 - val_beta: 0.6367 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2102 - reco_loss: 0.1841 - kl_loss: 0.0247 - beta: 0.6905 - val_loss: 0.1880 - val_reco_loss: 0.1560 - val_kl_loss: 0.0321 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3015 - reco_loss: 0.2771 - kl_loss: 0.0322 - beta: 0.1438 - val_loss: 0.3699 - val_reco_loss: 0.3204 - val_kl_loss: 0.0495 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3640 - reco_loss: 0.3145 - kl_loss: 0.0515 - beta: 0.1981 - val_loss: 0.3699 - val_reco_loss: 0.3124 - val_kl_loss: 0.0575 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3588 - reco_loss: 0.3045 - kl_loss: 0.0545 - beta: 0.2524 - val_loss: 0.3674 - val_reco_loss: 0.3068 - val_kl_loss: 0.0606 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3482 - reco_loss: 0.2937 - kl_loss: 0.0537 - beta: 0.3066 - val_loss: 0.3461 - val_reco_loss: 0.2846 - val_kl_loss: 0.0616 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3332 - reco_loss: 0.2826 - kl_loss: 0.0500 - beta: 0.3608 - val_loss: 0.3332 - val_reco_loss: 0.2757 - val_kl_loss: 0.0576 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3192 - reco_loss: 0.2713 - kl_loss: 0.0470 - beta: 0.4150 - val_loss: 0.3157 - val_reco_loss: 0.2606 - val_kl_loss: 0.0551 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3008 - reco_loss: 0.2558 - kl_loss: 0.0439 - beta: 0.4691 - val_loss: 0.2980 - val_reco_loss: 0.2461 - val_kl_loss: 0.0519 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2815 - reco_loss: 0.2397 - kl_loss: 0.0408 - beta: 0.5232 - val_loss: 0.2708 - val_reco_loss: 0.2231 - val_kl_loss: 0.0477 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2548 - reco_loss: 0.2172 - kl_loss: 0.0366 - beta: 0.5773 - val_loss: 0.2437 - val_reco_loss: 0.2021 - val_kl_loss: 0.0416 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.2327 - reco_loss: 0.2000 - kl_loss: 0.0316 - beta: 0.6300\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2325 - reco_loss: 0.1999 - kl_loss: 0.0315 - beta: 0.6313 - val_loss: 0.2274 - val_reco_loss: 0.1894 - val_kl_loss: 0.0380 - val_beta: 0.6313 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2076 - reco_loss: 0.1794 - kl_loss: 0.0272 - beta: 0.6852 - val_loss: 0.1996 - val_reco_loss: 0.1661 - val_kl_loss: 0.0335 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2618 - reco_loss: 0.2378 - kl_loss: 0.0295 - beta: 0.1387 - val_loss: 0.3661 - val_reco_loss: 0.3167 - val_kl_loss: 0.0494 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3564 - reco_loss: 0.3093 - kl_loss: 0.0494 - beta: 0.1929 - val_loss: 0.3501 - val_reco_loss: 0.2955 - val_kl_loss: 0.0546 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3491 - reco_loss: 0.2952 - kl_loss: 0.0543 - beta: 0.2472 - val_loss: 0.3542 - val_reco_loss: 0.2885 - val_kl_loss: 0.0657 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3395 - reco_loss: 0.2851 - kl_loss: 0.0538 - beta: 0.3014 - val_loss: 0.3351 - val_reco_loss: 0.2740 - val_kl_loss: 0.0611 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3281 - reco_loss: 0.2757 - kl_loss: 0.0511 - beta: 0.3556 - val_loss: 0.3218 - val_reco_loss: 0.2613 - val_kl_loss: 0.0605 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3142 - reco_loss: 0.2651 - kl_loss: 0.0484 - beta: 0.4097 - val_loss: 0.3110 - val_reco_loss: 0.2550 - val_kl_loss: 0.0560 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2942 - reco_loss: 0.2478 - kl_loss: 0.0454 - beta: 0.4638 - val_loss: 0.2897 - val_reco_loss: 0.2384 - val_kl_loss: 0.0513 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2739 - reco_loss: 0.2313 - kl_loss: 0.0415 - beta: 0.5179 - val_loss: 0.2721 - val_reco_loss: 0.2235 - val_kl_loss: 0.0486 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2552 - reco_loss: 0.2164 - kl_loss: 0.0373 - beta: 0.5715\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2552 - reco_loss: 0.2164 - kl_loss: 0.0373 - beta: 0.5720 - val_loss: 0.2500 - val_reco_loss: 0.2091 - val_kl_loss: 0.0410 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2316 - reco_loss: 0.1975 - kl_loss: 0.0334 - beta: 0.6259 - val_loss: 0.2411 - val_reco_loss: 0.2071 - val_kl_loss: 0.0340 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2071 - reco_loss: 0.1779 - kl_loss: 0.0286 - beta: 0.6800 - val_loss: 0.2047 - val_reco_loss: 0.1700 - val_kl_loss: 0.0347 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2393 - reco_loss: 0.2150 - kl_loss: 0.0265 - beta: 0.1337 - val_loss: 0.3563 - val_reco_loss: 0.3100 - val_kl_loss: 0.0463 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3515 - reco_loss: 0.3058 - kl_loss: 0.0489 - beta: 0.1878 - val_loss: 0.3478 - val_reco_loss: 0.2884 - val_kl_loss: 0.0594 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3468 - reco_loss: 0.2926 - kl_loss: 0.0545 - beta: 0.2420 - val_loss: 0.3376 - val_reco_loss: 0.2758 - val_kl_loss: 0.0618 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3354 - reco_loss: 0.2804 - kl_loss: 0.0548 - beta: 0.2962 - val_loss: 0.3337 - val_reco_loss: 0.2708 - val_kl_loss: 0.0629 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3243 - reco_loss: 0.2715 - kl_loss: 0.0523 - beta: 0.3503 - val_loss: 0.3303 - val_reco_loss: 0.2718 - val_kl_loss: 0.0585 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3107 - reco_loss: 0.2609 - kl_loss: 0.0493 - beta: 0.4045 - val_loss: 0.3095 - val_reco_loss: 0.2519 - val_kl_loss: 0.0575 - val_beta: 0.4045 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2930 - reco_loss: 0.2461 - kl_loss: 0.0461 - beta: 0.4586 - val_loss: 0.2911 - val_reco_loss: 0.2383 - val_kl_loss: 0.0528 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/320 [============================>.] - ETA: 0s - loss: 0.2752 - reco_loss: 0.2318 - kl_loss: 0.0426 - beta: 0.5125\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2751 - reco_loss: 0.2318 - kl_loss: 0.0426 - beta: 0.5126 - val_loss: 0.2768 - val_reco_loss: 0.2266 - val_kl_loss: 0.0501 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 12ms/step - loss: 0.9923 - reco_loss: 0.9804 - kl_loss: 0.0167 - beta: 0.1547 - val_loss: 0.6361 - val_reco_loss: 0.6078 - val_kl_loss: 0.0283 - val_beta: 0.1547 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5896 - reco_loss: 0.5571 - kl_loss: 0.0356 - beta: 0.2087 - val_loss: 0.5648 - val_reco_loss: 0.5206 - val_kl_loss: 0.0442 - val_beta: 0.2087 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5078 - reco_loss: 0.4650 - kl_loss: 0.0453 - beta: 0.2627 - val_loss: 0.4900 - val_reco_loss: 0.4344 - val_kl_loss: 0.0556 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4492 - reco_loss: 0.4000 - kl_loss: 0.0486 - beta: 0.3169 - val_loss: 0.4231 - val_reco_loss: 0.3703 - val_kl_loss: 0.0528 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4089 - reco_loss: 0.3620 - kl_loss: 0.0458 - beta: 0.3711 - val_loss: 0.3733 - val_reco_loss: 0.3207 - val_kl_loss: 0.0526 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3644 - reco_loss: 0.3216 - kl_loss: 0.0425 - beta: 0.4253 - val_loss: 0.3532 - val_reco_loss: 0.3048 - val_kl_loss: 0.0484 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3267 - reco_loss: 0.2870 - kl_loss: 0.0390 - beta: 0.4794 - val_loss: 0.3110 - val_reco_loss: 0.2699 - val_kl_loss: 0.0411 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3023 - reco_loss: 0.2655 - kl_loss: 0.0356 - beta: 0.5335 - val_loss: 0.2791 - val_reco_loss: 0.2386 - val_kl_loss: 0.0404 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2775 - reco_loss: 0.2448 - kl_loss: 0.0315 - beta: 0.5876 - val_loss: 0.2621 - val_reco_loss: 0.2274 - val_kl_loss: 0.0347 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2433 - reco_loss: 0.2153 - kl_loss: 0.0270 - beta: 0.6417 - val_loss: 0.2309 - val_reco_loss: 0.1975 - val_kl_loss: 0.0334 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2176 - reco_loss: 0.1942 - kl_loss: 0.0224 - beta: 0.6958 - val_loss: 0.1988 - val_reco_loss: 0.1715 - val_kl_loss: 0.0273 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3573 - reco_loss: 0.3350 - kl_loss: 0.0324 - beta: 0.1490 - val_loss: 0.4023 - val_reco_loss: 0.3516 - val_kl_loss: 0.0507 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3811 - reco_loss: 0.3320 - kl_loss: 0.0506 - beta: 0.2033 - val_loss: 0.3882 - val_reco_loss: 0.3312 - val_kl_loss: 0.0570 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3720 - reco_loss: 0.3191 - kl_loss: 0.0528 - beta: 0.2575 - val_loss: 0.3884 - val_reco_loss: 0.3312 - val_kl_loss: 0.0572 - val_beta: 0.2575 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3551 - reco_loss: 0.3030 - kl_loss: 0.0513 - beta: 0.3119 - val_loss: 0.3573 - val_reco_loss: 0.2975 - val_kl_loss: 0.0598 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3395 - reco_loss: 0.2899 - kl_loss: 0.0487 - beta: 0.3662 - val_loss: 0.3418 - val_reco_loss: 0.2891 - val_kl_loss: 0.0527 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3225 - reco_loss: 0.2767 - kl_loss: 0.0455 - beta: 0.4204 - val_loss: 0.3222 - val_reco_loss: 0.2692 - val_kl_loss: 0.0530 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2990 - reco_loss: 0.2559 - kl_loss: 0.0422 - beta: 0.4746 - val_loss: 0.3060 - val_reco_loss: 0.2565 - val_kl_loss: 0.0496 - val_beta: 0.4746 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2791 - reco_loss: 0.2399 - kl_loss: 0.0385 - beta: 0.5286 - val_loss: 0.2776 - val_reco_loss: 0.2283 - val_kl_loss: 0.0492 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2552 - reco_loss: 0.2196 - kl_loss: 0.0344 - beta: 0.5827 - val_loss: 0.2522 - val_reco_loss: 0.2117 - val_kl_loss: 0.0406 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2311 - reco_loss: 0.2002 - kl_loss: 0.0296 - beta: 0.6361\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2310 - reco_loss: 0.2002 - kl_loss: 0.0296 - beta: 0.6368 - val_loss: 0.2212 - val_reco_loss: 0.1861 - val_kl_loss: 0.0351 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2075 - reco_loss: 0.1808 - kl_loss: 0.0251 - beta: 0.6905 - val_loss: 0.1954 - val_reco_loss: 0.1635 - val_kl_loss: 0.0319 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2938 - reco_loss: 0.2705 - kl_loss: 0.0309 - beta: 0.1439 - val_loss: 0.3748 - val_reco_loss: 0.3207 - val_kl_loss: 0.0541 - val_beta: 0.1439 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3575 - reco_loss: 0.3076 - kl_loss: 0.0511 - beta: 0.1981 - val_loss: 0.3718 - val_reco_loss: 0.3165 - val_kl_loss: 0.0553 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3520 - reco_loss: 0.2985 - kl_loss: 0.0543 - beta: 0.2523 - val_loss: 0.3623 - val_reco_loss: 0.2958 - val_kl_loss: 0.0665 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3447 - reco_loss: 0.2912 - kl_loss: 0.0526 - beta: 0.3066 - val_loss: 0.3543 - val_reco_loss: 0.2964 - val_kl_loss: 0.0579 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3334 - reco_loss: 0.2831 - kl_loss: 0.0495 - beta: 0.3608 - val_loss: 0.3417 - val_reco_loss: 0.2870 - val_kl_loss: 0.0546 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3163 - reco_loss: 0.2688 - kl_loss: 0.0470 - beta: 0.4150 - val_loss: 0.3189 - val_reco_loss: 0.2624 - val_kl_loss: 0.0565 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2956 - reco_loss: 0.2514 - kl_loss: 0.0438 - beta: 0.4691 - val_loss: 0.3014 - val_reco_loss: 0.2490 - val_kl_loss: 0.0524 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2773 - reco_loss: 0.2362 - kl_loss: 0.0403 - beta: 0.5232 - val_loss: 0.2817 - val_reco_loss: 0.2328 - val_kl_loss: 0.0490 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2547 - reco_loss: 0.2176 - kl_loss: 0.0363 - beta: 0.5773 - val_loss: 0.2493 - val_reco_loss: 0.2079 - val_kl_loss: 0.0414 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2343 - reco_loss: 0.2021 - kl_loss: 0.0310 - beta: 0.6307\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2342 - reco_loss: 0.2020 - kl_loss: 0.0309 - beta: 0.6314 - val_loss: 0.2267 - val_reco_loss: 0.1886 - val_kl_loss: 0.0381 - val_beta: 0.6314 - lr: 7.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2083 - reco_loss: 0.1804 - kl_loss: 0.0266 - beta: 0.6852 - val_loss: 0.1971 - val_reco_loss: 0.1619 - val_kl_loss: 0.0352 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2609 - reco_loss: 0.2382 - kl_loss: 0.0277 - beta: 0.1388 - val_loss: 0.3737 - val_reco_loss: 0.3273 - val_kl_loss: 0.0464 - val_beta: 0.1388 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.3584 - reco_loss: 0.3118 - kl_loss: 0.0489 - beta: 0.1929 - val_loss: 0.3628 - val_reco_loss: 0.3065 - val_kl_loss: 0.0563 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3491 - reco_loss: 0.2964 - kl_loss: 0.0531 - beta: 0.2472 - val_loss: 0.3589 - val_reco_loss: 0.3012 - val_kl_loss: 0.0577 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3418 - reco_loss: 0.2884 - kl_loss: 0.0529 - beta: 0.3014 - val_loss: 0.3488 - val_reco_loss: 0.2872 - val_kl_loss: 0.0617 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3301 - reco_loss: 0.2783 - kl_loss: 0.0508 - beta: 0.3556 - val_loss: 0.3369 - val_reco_loss: 0.2720 - val_kl_loss: 0.0649 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3137 - reco_loss: 0.2653 - kl_loss: 0.0477 - beta: 0.4097 - val_loss: 0.3147 - val_reco_loss: 0.2594 - val_kl_loss: 0.0553 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2963 - reco_loss: 0.2505 - kl_loss: 0.0449 - beta: 0.4638 - val_loss: 0.2929 - val_reco_loss: 0.2417 - val_kl_loss: 0.0512 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2770 - reco_loss: 0.2347 - kl_loss: 0.0411 - beta: 0.5179 - val_loss: 0.2763 - val_reco_loss: 0.2317 - val_kl_loss: 0.0446 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2559 - reco_loss: 0.2182 - kl_loss: 0.0369 - beta: 0.5705\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2557 - reco_loss: 0.2180 - kl_loss: 0.0369 - beta: 0.5720 - val_loss: 0.2590 - val_reco_loss: 0.2136 - val_kl_loss: 0.0454 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2353 - reco_loss: 0.2008 - kl_loss: 0.0328 - beta: 0.6259 - val_loss: 0.2310 - val_reco_loss: 0.1955 - val_kl_loss: 0.0355 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2071 - reco_loss: 0.1777 - kl_loss: 0.0285 - beta: 0.6800 - val_loss: 0.2074 - val_reco_loss: 0.1753 - val_kl_loss: 0.0320 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2409 - reco_loss: 0.2171 - kl_loss: 0.0257 - beta: 0.1337 - val_loss: 0.3714 - val_reco_loss: 0.3313 - val_kl_loss: 0.0401 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3550 - reco_loss: 0.3115 - kl_loss: 0.0467 - beta: 0.1878 - val_loss: 0.3594 - val_reco_loss: 0.3053 - val_kl_loss: 0.0541 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3478 - reco_loss: 0.2958 - kl_loss: 0.0527 - beta: 0.2420 - val_loss: 0.3573 - val_reco_loss: 0.2919 - val_kl_loss: 0.0655 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3448 - reco_loss: 0.2905 - kl_loss: 0.0533 - beta: 0.2962 - val_loss: 0.3471 - val_reco_loss: 0.2867 - val_kl_loss: 0.0604 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3266 - reco_loss: 0.2748 - kl_loss: 0.0512 - beta: 0.3503 - val_loss: 0.3312 - val_reco_loss: 0.2771 - val_kl_loss: 0.0540 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3136 - reco_loss: 0.2643 - kl_loss: 0.0485 - beta: 0.4044 - val_loss: 0.3221 - val_reco_loss: 0.2692 - val_kl_loss: 0.0529 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2991 - reco_loss: 0.2523 - kl_loss: 0.0456 - beta: 0.4585 - val_loss: 0.2919 - val_reco_loss: 0.2388 - val_kl_loss: 0.0530 - val_beta: 0.4585 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.2776 - reco_loss: 0.2343 - kl_loss: 0.0426 - beta: 0.5115\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2775 - reco_loss: 0.2342 - kl_loss: 0.0425 - beta: 0.5126 - val_loss: 0.2787 - val_reco_loss: 0.2288 - val_kl_loss: 0.0499 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 10ms/step - loss: 1.1572 - reco_loss: 1.1332 - kl_loss: 0.0304 - beta: 0.1545 - val_loss: 0.6485 - val_reco_loss: 0.6002 - val_kl_loss: 0.0482 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5951 - reco_loss: 0.5452 - kl_loss: 0.0523 - beta: 0.2085 - val_loss: 0.5166 - val_reco_loss: 0.4565 - val_kl_loss: 0.0602 - val_beta: 0.2085 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4909 - reco_loss: 0.4347 - kl_loss: 0.0560 - beta: 0.2629 - val_loss: 0.4629 - val_reco_loss: 0.4005 - val_kl_loss: 0.0624 - val_beta: 0.2629 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4351 - reco_loss: 0.3805 - kl_loss: 0.0533 - beta: 0.3169 - val_loss: 0.4037 - val_reco_loss: 0.3458 - val_kl_loss: 0.0579 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4026 - reco_loss: 0.3536 - kl_loss: 0.0476 - beta: 0.3712 - val_loss: 0.3795 - val_reco_loss: 0.3256 - val_kl_loss: 0.0539 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3756 - reco_loss: 0.3312 - kl_loss: 0.0434 - beta: 0.4254 - val_loss: 0.3339 - val_reco_loss: 0.2812 - val_kl_loss: 0.0527 - val_beta: 0.4254 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3404 - reco_loss: 0.2998 - kl_loss: 0.0395 - beta: 0.4795 - val_loss: 0.3088 - val_reco_loss: 0.2636 - val_kl_loss: 0.0453 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3110 - reco_loss: 0.2744 - kl_loss: 0.0356 - beta: 0.5336 - val_loss: 0.2847 - val_reco_loss: 0.2433 - val_kl_loss: 0.0414 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2768 - reco_loss: 0.2447 - kl_loss: 0.0310 - beta: 0.5876 - val_loss: 0.2566 - val_reco_loss: 0.2240 - val_kl_loss: 0.0325 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2504 - reco_loss: 0.2230 - kl_loss: 0.0259 - beta: 0.6418 - val_loss: 0.2307 - val_reco_loss: 0.1989 - val_kl_loss: 0.0319 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2184 - reco_loss: 0.1960 - kl_loss: 0.0211 - beta: 0.6958 - val_loss: 0.1969 - val_reco_loss: 0.1704 - val_kl_loss: 0.0265 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3594 - reco_loss: 0.3347 - kl_loss: 0.0360 - beta: 0.1490 - val_loss: 0.3848 - val_reco_loss: 0.3287 - val_kl_loss: 0.0561 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3896 - reco_loss: 0.3376 - kl_loss: 0.0528 - beta: 0.2034 - val_loss: 0.3758 - val_reco_loss: 0.3150 - val_kl_loss: 0.0609 - val_beta: 0.2034 - lr: 0.0010\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3778 - reco_loss: 0.3237 - kl_loss: 0.0541 - beta: 0.2576 - val_loss: 0.3582 - val_reco_loss: 0.2993 - val_kl_loss: 0.0588 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3601 - reco_loss: 0.3079 - kl_loss: 0.0518 - beta: 0.3119 - val_loss: 0.3443 - val_reco_loss: 0.2835 - val_kl_loss: 0.0608 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3477 - reco_loss: 0.2982 - kl_loss: 0.0484 - beta: 0.3662 - val_loss: 0.3397 - val_reco_loss: 0.2884 - val_kl_loss: 0.0513 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3341 - reco_loss: 0.2879 - kl_loss: 0.0452 - beta: 0.4204 - val_loss: 0.3166 - val_reco_loss: 0.2626 - val_kl_loss: 0.0540 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3063 - reco_loss: 0.2635 - kl_loss: 0.0418 - beta: 0.4745 - val_loss: 0.2949 - val_reco_loss: 0.2439 - val_kl_loss: 0.0510 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2848 - reco_loss: 0.2458 - kl_loss: 0.0380 - beta: 0.5286 - val_loss: 0.2773 - val_reco_loss: 0.2324 - val_kl_loss: 0.0449 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2619 - reco_loss: 0.2265 - kl_loss: 0.0338 - beta: 0.5827 - val_loss: 0.2475 - val_reco_loss: 0.2047 - val_kl_loss: 0.0428 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2376 - reco_loss: 0.2075 - kl_loss: 0.0289 - beta: 0.6353\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2374 - reco_loss: 0.2073 - kl_loss: 0.0288 - beta: 0.6368 - val_loss: 0.2251 - val_reco_loss: 0.1925 - val_kl_loss: 0.0326 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2096 - reco_loss: 0.1838 - kl_loss: 0.0245 - beta: 0.6905 - val_loss: 0.1989 - val_reco_loss: 0.1680 - val_kl_loss: 0.0310 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2953 - reco_loss: 0.2713 - kl_loss: 0.0326 - beta: 0.1439 - val_loss: 0.3673 - val_reco_loss: 0.3142 - val_kl_loss: 0.0530 - val_beta: 0.1439 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3631 - reco_loss: 0.3140 - kl_loss: 0.0506 - beta: 0.1981 - val_loss: 0.3598 - val_reco_loss: 0.3004 - val_kl_loss: 0.0595 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3551 - reco_loss: 0.3018 - kl_loss: 0.0535 - beta: 0.2523 - val_loss: 0.3473 - val_reco_loss: 0.2856 - val_kl_loss: 0.0617 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3438 - reco_loss: 0.2905 - kl_loss: 0.0529 - beta: 0.3066 - val_loss: 0.3457 - val_reco_loss: 0.2864 - val_kl_loss: 0.0593 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3317 - reco_loss: 0.2813 - kl_loss: 0.0499 - beta: 0.3608 - val_loss: 0.3267 - val_reco_loss: 0.2721 - val_kl_loss: 0.0546 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3182 - reco_loss: 0.2702 - kl_loss: 0.0471 - beta: 0.4150 - val_loss: 0.3160 - val_reco_loss: 0.2567 - val_kl_loss: 0.0593 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2982 - reco_loss: 0.2534 - kl_loss: 0.0439 - beta: 0.4692 - val_loss: 0.2897 - val_reco_loss: 0.2370 - val_kl_loss: 0.0527 - val_beta: 0.4692 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2775 - reco_loss: 0.2359 - kl_loss: 0.0405 - beta: 0.5232 - val_loss: 0.2725 - val_reco_loss: 0.2250 - val_kl_loss: 0.0475 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.2565 - reco_loss: 0.2189 - kl_loss: 0.0364 - beta: 0.5759\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2563 - reco_loss: 0.2187 - kl_loss: 0.0363 - beta: 0.5773 - val_loss: 0.2528 - val_reco_loss: 0.2100 - val_kl_loss: 0.0428 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2324 - reco_loss: 0.2000 - kl_loss: 0.0313 - beta: 0.6311 - val_loss: 0.2171 - val_reco_loss: 0.1799 - val_kl_loss: 0.0372 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2070 - reco_loss: 0.1786 - kl_loss: 0.0268 - beta: 0.6852 - val_loss: 0.1987 - val_reco_loss: 0.1688 - val_kl_loss: 0.0299 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2599 - reco_loss: 0.2359 - kl_loss: 0.0301 - beta: 0.1388 - val_loss: 0.3563 - val_reco_loss: 0.3064 - val_kl_loss: 0.0499 - val_beta: 0.1388 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3536 - reco_loss: 0.3062 - kl_loss: 0.0495 - beta: 0.1929 - val_loss: 0.3614 - val_reco_loss: 0.3059 - val_kl_loss: 0.0555 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3483 - reco_loss: 0.2951 - kl_loss: 0.0534 - beta: 0.2471 - val_loss: 0.3525 - val_reco_loss: 0.2878 - val_kl_loss: 0.0647 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3372 - reco_loss: 0.2838 - kl_loss: 0.0528 - beta: 0.3014 - val_loss: 0.3438 - val_reco_loss: 0.2829 - val_kl_loss: 0.0609 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3257 - reco_loss: 0.2747 - kl_loss: 0.0505 - beta: 0.3555 - val_loss: 0.3298 - val_reco_loss: 0.2701 - val_kl_loss: 0.0597 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3150 - reco_loss: 0.2660 - kl_loss: 0.0476 - beta: 0.4097 - val_loss: 0.3169 - val_reco_loss: 0.2564 - val_kl_loss: 0.0605 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2933 - reco_loss: 0.2480 - kl_loss: 0.0448 - beta: 0.4638 - val_loss: 0.2925 - val_reco_loss: 0.2427 - val_kl_loss: 0.0498 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2753 - reco_loss: 0.2329 - kl_loss: 0.0413 - beta: 0.5162\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2751 - reco_loss: 0.2328 - kl_loss: 0.0412 - beta: 0.5179 - val_loss: 0.2746 - val_reco_loss: 0.2260 - val_kl_loss: 0.0486 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.9046 - reco_loss: 0.8909 - kl_loss: 0.0231 - beta: 0.1544 - val_loss: 0.6308 - val_reco_loss: 0.5882 - val_kl_loss: 0.0426 - val_beta: 0.1544 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5696 - reco_loss: 0.5272 - kl_loss: 0.0439 - beta: 0.2088 - val_loss: 0.5254 - val_reco_loss: 0.4752 - val_kl_loss: 0.0502 - val_beta: 0.2088 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4909 - reco_loss: 0.4465 - kl_loss: 0.0444 - beta: 0.2629 - val_loss: 0.4520 - val_reco_loss: 0.4003 - val_kl_loss: 0.0518 - val_beta: 0.2629 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4465 - reco_loss: 0.4014 - kl_loss: 0.0455 - beta: 0.3169 - val_loss: 0.4089 - val_reco_loss: 0.3557 - val_kl_loss: 0.0532 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3907 - reco_loss: 0.3460 - kl_loss: 0.0442 - beta: 0.3712 - val_loss: 0.3646 - val_reco_loss: 0.3168 - val_kl_loss: 0.0478 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3627 - reco_loss: 0.3209 - kl_loss: 0.0412 - beta: 0.4252 - val_loss: 0.3346 - val_reco_loss: 0.2924 - val_kl_loss: 0.0422 - val_beta: 0.4252 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3238 - reco_loss: 0.2847 - kl_loss: 0.0384 - beta: 0.4795 - val_loss: 0.3040 - val_reco_loss: 0.2592 - val_kl_loss: 0.0448 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3012 - reco_loss: 0.2654 - kl_loss: 0.0347 - beta: 0.5335 - val_loss: 0.2728 - val_reco_loss: 0.2325 - val_kl_loss: 0.0403 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2731 - reco_loss: 0.2415 - kl_loss: 0.0307 - beta: 0.5877 - val_loss: 0.2571 - val_reco_loss: 0.2211 - val_kl_loss: 0.0360 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2420 - reco_loss: 0.2142 - kl_loss: 0.0265 - beta: 0.6417 - val_loss: 0.2223 - val_reco_loss: 0.1929 - val_kl_loss: 0.0294 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2128 - reco_loss: 0.1896 - kl_loss: 0.0218 - beta: 0.6959 - val_loss: 0.1938 - val_reco_loss: 0.1701 - val_kl_loss: 0.0237 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3467 - reco_loss: 0.3215 - kl_loss: 0.0362 - beta: 0.1490 - val_loss: 0.3772 - val_reco_loss: 0.3257 - val_kl_loss: 0.0514 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3819 - reco_loss: 0.3308 - kl_loss: 0.0523 - beta: 0.2032 - val_loss: 0.3575 - val_reco_loss: 0.3012 - val_kl_loss: 0.0564 - val_beta: 0.2032 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3711 - reco_loss: 0.3171 - kl_loss: 0.0541 - beta: 0.2576 - val_loss: 0.3584 - val_reco_loss: 0.2975 - val_kl_loss: 0.0609 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3580 - reco_loss: 0.3047 - kl_loss: 0.0525 - beta: 0.3119 - val_loss: 0.3427 - val_reco_loss: 0.2810 - val_kl_loss: 0.0617 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3367 - reco_loss: 0.2868 - kl_loss: 0.0489 - beta: 0.3662 - val_loss: 0.3268 - val_reco_loss: 0.2744 - val_kl_loss: 0.0524 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3218 - reco_loss: 0.2750 - kl_loss: 0.0461 - beta: 0.4204 - val_loss: 0.3158 - val_reco_loss: 0.2648 - val_kl_loss: 0.0510 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3023 - reco_loss: 0.2588 - kl_loss: 0.0428 - beta: 0.4745 - val_loss: 0.2933 - val_reco_loss: 0.2435 - val_kl_loss: 0.0498 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2786 - reco_loss: 0.2386 - kl_loss: 0.0390 - beta: 0.5286 - val_loss: 0.2697 - val_reco_loss: 0.2230 - val_kl_loss: 0.0467 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2556 - reco_loss: 0.2201 - kl_loss: 0.0343 - beta: 0.5827 - val_loss: 0.2462 - val_reco_loss: 0.2073 - val_kl_loss: 0.0388 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2312 - reco_loss: 0.2005 - kl_loss: 0.0296 - beta: 0.6368\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2312 - reco_loss: 0.2005 - kl_loss: 0.0296 - beta: 0.6368 - val_loss: 0.2250 - val_reco_loss: 0.1891 - val_kl_loss: 0.0359 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2053 - reco_loss: 0.1789 - kl_loss: 0.0253 - beta: 0.6905 - val_loss: 0.1917 - val_reco_loss: 0.1627 - val_kl_loss: 0.0290 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2897 - reco_loss: 0.2657 - kl_loss: 0.0323 - beta: 0.1439 - val_loss: 0.3624 - val_reco_loss: 0.3133 - val_kl_loss: 0.0491 - val_beta: 0.1439 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.3613 - reco_loss: 0.3117 - kl_loss: 0.0511 - beta: 0.1981 - val_loss: 0.3531 - val_reco_loss: 0.2927 - val_kl_loss: 0.0604 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3510 - reco_loss: 0.2967 - kl_loss: 0.0541 - beta: 0.2523 - val_loss: 0.3482 - val_reco_loss: 0.2897 - val_kl_loss: 0.0585 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3403 - reco_loss: 0.2866 - kl_loss: 0.0528 - beta: 0.3066 - val_loss: 0.3385 - val_reco_loss: 0.2748 - val_kl_loss: 0.0636 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3289 - reco_loss: 0.2787 - kl_loss: 0.0494 - beta: 0.3608 - val_loss: 0.3236 - val_reco_loss: 0.2613 - val_kl_loss: 0.0623 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3112 - reco_loss: 0.2634 - kl_loss: 0.0468 - beta: 0.4150 - val_loss: 0.3163 - val_reco_loss: 0.2630 - val_kl_loss: 0.0533 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2913 - reco_loss: 0.2472 - kl_loss: 0.0440 - beta: 0.4691 - val_loss: 0.2868 - val_reco_loss: 0.2365 - val_kl_loss: 0.0503 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2755 - reco_loss: 0.2338 - kl_loss: 0.0408 - beta: 0.5232 - val_loss: 0.2707 - val_reco_loss: 0.2207 - val_kl_loss: 0.0500 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2528 - reco_loss: 0.2159 - kl_loss: 0.0361 - beta: 0.5773 - val_loss: 0.2428 - val_reco_loss: 0.2005 - val_kl_loss: 0.0424 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2320 - reco_loss: 0.1986 - kl_loss: 0.0315 - beta: 0.6309\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2319 - reco_loss: 0.1986 - kl_loss: 0.0315 - beta: 0.6314 - val_loss: 0.2205 - val_reco_loss: 0.1874 - val_kl_loss: 0.0331 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2050 - reco_loss: 0.1774 - kl_loss: 0.0266 - beta: 0.6852 - val_loss: 0.1921 - val_reco_loss: 0.1623 - val_kl_loss: 0.0298 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2606 - reco_loss: 0.2365 - kl_loss: 0.0290 - beta: 0.1388 - val_loss: 0.3544 - val_reco_loss: 0.3089 - val_kl_loss: 0.0456 - val_beta: 0.1388 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3544 - reco_loss: 0.3085 - kl_loss: 0.0482 - beta: 0.1929 - val_loss: 0.3527 - val_reco_loss: 0.2970 - val_kl_loss: 0.0558 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3447 - reco_loss: 0.2921 - kl_loss: 0.0532 - beta: 0.2472 - val_loss: 0.3499 - val_reco_loss: 0.2847 - val_kl_loss: 0.0653 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3388 - reco_loss: 0.2848 - kl_loss: 0.0530 - beta: 0.3014 - val_loss: 0.3334 - val_reco_loss: 0.2776 - val_kl_loss: 0.0557 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3276 - reco_loss: 0.2769 - kl_loss: 0.0498 - beta: 0.3556 - val_loss: 0.3236 - val_reco_loss: 0.2671 - val_kl_loss: 0.0565 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3126 - reco_loss: 0.2644 - kl_loss: 0.0474 - beta: 0.4097 - val_loss: 0.3109 - val_reco_loss: 0.2533 - val_kl_loss: 0.0576 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2936 - reco_loss: 0.2480 - kl_loss: 0.0447 - beta: 0.4638 - val_loss: 0.2934 - val_reco_loss: 0.2455 - val_kl_loss: 0.0479 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2751 - reco_loss: 0.2328 - kl_loss: 0.0415 - beta: 0.5179 - val_loss: 0.2764 - val_reco_loss: 0.2252 - val_kl_loss: 0.0512 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2527 - reco_loss: 0.2142 - kl_loss: 0.0375 - beta: 0.5710\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2526 - reco_loss: 0.2141 - kl_loss: 0.0375 - beta: 0.5720 - val_loss: 0.2436 - val_reco_loss: 0.2004 - val_kl_loss: 0.0433 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2340 - reco_loss: 0.1990 - kl_loss: 0.0333 - beta: 0.6259 - val_loss: 0.2225 - val_reco_loss: 0.1861 - val_kl_loss: 0.0364 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2076 - reco_loss: 0.1783 - kl_loss: 0.0282 - beta: 0.6800 - val_loss: 0.2012 - val_reco_loss: 0.1678 - val_kl_loss: 0.0334 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2385 - reco_loss: 0.2154 - kl_loss: 0.0258 - beta: 0.1337 - val_loss: 0.3630 - val_reco_loss: 0.3226 - val_kl_loss: 0.0404 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3531 - reco_loss: 0.3094 - kl_loss: 0.0467 - beta: 0.1878 - val_loss: 0.3428 - val_reco_loss: 0.2866 - val_kl_loss: 0.0562 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3463 - reco_loss: 0.2936 - kl_loss: 0.0533 - beta: 0.2420 - val_loss: 0.3493 - val_reco_loss: 0.2895 - val_kl_loss: 0.0598 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3333 - reco_loss: 0.2805 - kl_loss: 0.0529 - beta: 0.2962 - val_loss: 0.3372 - val_reco_loss: 0.2807 - val_kl_loss: 0.0565 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3268 - reco_loss: 0.2752 - kl_loss: 0.0506 - beta: 0.3503 - val_loss: 0.3266 - val_reco_loss: 0.2735 - val_kl_loss: 0.0531 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3113 - reco_loss: 0.2625 - kl_loss: 0.0481 - beta: 0.4045 - val_loss: 0.3030 - val_reco_loss: 0.2502 - val_kl_loss: 0.0528 - val_beta: 0.4045 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2956 - reco_loss: 0.2489 - kl_loss: 0.0458 - beta: 0.4586 - val_loss: 0.2883 - val_reco_loss: 0.2354 - val_kl_loss: 0.0529 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.2741 - reco_loss: 0.2307 - kl_loss: 0.0425 - beta: 0.5121\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2741 - reco_loss: 0.2307 - kl_loss: 0.0425 - beta: 0.5127 - val_loss: 0.2662 - val_reco_loss: 0.2195 - val_kl_loss: 0.0467 - val_beta: 0.5127 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.8939 - reco_loss: 0.8794 - kl_loss: 0.0239 - beta: 0.1546 - val_loss: 0.6300 - val_reco_loss: 0.5851 - val_kl_loss: 0.0449 - val_beta: 0.1546 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5637 - reco_loss: 0.5156 - kl_loss: 0.0515 - beta: 0.2085 - val_loss: 0.4926 - val_reco_loss: 0.4315 - val_kl_loss: 0.0611 - val_beta: 0.2085 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4860 - reco_loss: 0.4303 - kl_loss: 0.0554 - beta: 0.2628 - val_loss: 0.4411 - val_reco_loss: 0.3802 - val_kl_loss: 0.0609 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4427 - reco_loss: 0.3894 - kl_loss: 0.0517 - beta: 0.3170 - val_loss: 0.4036 - val_reco_loss: 0.3511 - val_kl_loss: 0.0525 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3936 - reco_loss: 0.3464 - kl_loss: 0.0460 - beta: 0.3712 - val_loss: 0.3602 - val_reco_loss: 0.3105 - val_kl_loss: 0.0497 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3569 - reco_loss: 0.3145 - kl_loss: 0.0416 - beta: 0.4254 - val_loss: 0.3372 - val_reco_loss: 0.2960 - val_kl_loss: 0.0412 - val_beta: 0.4254 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3372 - reco_loss: 0.2972 - kl_loss: 0.0387 - beta: 0.4794 - val_loss: 0.3046 - val_reco_loss: 0.2637 - val_kl_loss: 0.0409 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3053 - reco_loss: 0.2692 - kl_loss: 0.0351 - beta: 0.5336 - val_loss: 0.2891 - val_reco_loss: 0.2527 - val_kl_loss: 0.0364 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2725 - reco_loss: 0.2408 - kl_loss: 0.0308 - beta: 0.5877 - val_loss: 0.2493 - val_reco_loss: 0.2175 - val_kl_loss: 0.0318 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2445 - reco_loss: 0.2169 - kl_loss: 0.0263 - beta: 0.6418 - val_loss: 0.2252 - val_reco_loss: 0.1959 - val_kl_loss: 0.0293 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2128 - reco_loss: 0.1897 - kl_loss: 0.0219 - beta: 0.6958 - val_loss: 0.1944 - val_reco_loss: 0.1689 - val_kl_loss: 0.0255 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3512 - reco_loss: 0.3255 - kl_loss: 0.0368 - beta: 0.1490 - val_loss: 0.4044 - val_reco_loss: 0.3558 - val_kl_loss: 0.0485 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3798 - reco_loss: 0.3289 - kl_loss: 0.0517 - beta: 0.2033 - val_loss: 0.3772 - val_reco_loss: 0.3165 - val_kl_loss: 0.0607 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3675 - reco_loss: 0.3138 - kl_loss: 0.0536 - beta: 0.2576 - val_loss: 0.3761 - val_reco_loss: 0.3226 - val_kl_loss: 0.0535 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3555 - reco_loss: 0.3034 - kl_loss: 0.0517 - beta: 0.3120 - val_loss: 0.3506 - val_reco_loss: 0.2918 - val_kl_loss: 0.0588 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3377 - reco_loss: 0.2887 - kl_loss: 0.0484 - beta: 0.3662 - val_loss: 0.3372 - val_reco_loss: 0.2847 - val_kl_loss: 0.0524 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3178 - reco_loss: 0.2722 - kl_loss: 0.0452 - beta: 0.4204 - val_loss: 0.3317 - val_reco_loss: 0.2845 - val_kl_loss: 0.0473 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3005 - reco_loss: 0.2576 - kl_loss: 0.0417 - beta: 0.4745 - val_loss: 0.3043 - val_reco_loss: 0.2613 - val_kl_loss: 0.0430 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2805 - reco_loss: 0.2417 - kl_loss: 0.0378 - beta: 0.5286 - val_loss: 0.2724 - val_reco_loss: 0.2278 - val_kl_loss: 0.0446 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2586 - reco_loss: 0.2234 - kl_loss: 0.0338 - beta: 0.5827 - val_loss: 0.2452 - val_reco_loss: 0.2105 - val_kl_loss: 0.0346 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2311 - reco_loss: 0.2011 - kl_loss: 0.0289 - beta: 0.6366\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2310 - reco_loss: 0.2011 - kl_loss: 0.0289 - beta: 0.6368 - val_loss: 0.2281 - val_reco_loss: 0.1943 - val_kl_loss: 0.0338 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2041 - reco_loss: 0.1785 - kl_loss: 0.0245 - beta: 0.6905 - val_loss: 0.1960 - val_reco_loss: 0.1671 - val_kl_loss: 0.0289 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2884 - reco_loss: 0.2640 - kl_loss: 0.0337 - beta: 0.1438 - val_loss: 0.3660 - val_reco_loss: 0.3142 - val_kl_loss: 0.0518 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3584 - reco_loss: 0.3084 - kl_loss: 0.0515 - beta: 0.1981 - val_loss: 0.3624 - val_reco_loss: 0.3048 - val_kl_loss: 0.0575 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3525 - reco_loss: 0.2981 - kl_loss: 0.0541 - beta: 0.2524 - val_loss: 0.3470 - val_reco_loss: 0.2883 - val_kl_loss: 0.0587 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3419 - reco_loss: 0.2882 - kl_loss: 0.0531 - beta: 0.3066 - val_loss: 0.3475 - val_reco_loss: 0.2826 - val_kl_loss: 0.0649 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 0.3302 - reco_loss: 0.2794 - kl_loss: 0.0501 - beta: 0.3609 - val_loss: 0.3244 - val_reco_loss: 0.2694 - val_kl_loss: 0.0550 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3122 - reco_loss: 0.2645 - kl_loss: 0.0472 - beta: 0.4150 - val_loss: 0.3083 - val_reco_loss: 0.2576 - val_kl_loss: 0.0507 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2947 - reco_loss: 0.2503 - kl_loss: 0.0437 - beta: 0.4691 - val_loss: 0.2849 - val_reco_loss: 0.2391 - val_kl_loss: 0.0458 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.2761 - reco_loss: 0.2349 - kl_loss: 0.0403 - beta: 0.5232 - val_loss: 0.2717 - val_reco_loss: 0.2282 - val_kl_loss: 0.0435 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2547 - reco_loss: 0.2174 - kl_loss: 0.0361 - beta: 0.5756\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2545 - reco_loss: 0.2172 - kl_loss: 0.0361 - beta: 0.5773 - val_loss: 0.2467 - val_reco_loss: 0.2066 - val_kl_loss: 0.0401 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2318 - reco_loss: 0.1993 - kl_loss: 0.0312 - beta: 0.6311 - val_loss: 0.2304 - val_reco_loss: 0.1943 - val_kl_loss: 0.0361 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2059 - reco_loss: 0.1779 - kl_loss: 0.0272 - beta: 0.6852 - val_loss: 0.2003 - val_reco_loss: 0.1661 - val_kl_loss: 0.0342 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2602 - reco_loss: 0.2353 - kl_loss: 0.0316 - beta: 0.1387 - val_loss: 0.3541 - val_reco_loss: 0.3061 - val_kl_loss: 0.0480 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3508 - reco_loss: 0.3016 - kl_loss: 0.0510 - beta: 0.1929 - val_loss: 0.3482 - val_reco_loss: 0.2919 - val_kl_loss: 0.0562 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3462 - reco_loss: 0.2928 - kl_loss: 0.0541 - beta: 0.2471 - val_loss: 0.3491 - val_reco_loss: 0.2879 - val_kl_loss: 0.0613 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3392 - reco_loss: 0.2853 - kl_loss: 0.0533 - beta: 0.3014 - val_loss: 0.3379 - val_reco_loss: 0.2794 - val_kl_loss: 0.0585 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3281 - reco_loss: 0.2758 - kl_loss: 0.0512 - beta: 0.3556 - val_loss: 0.3234 - val_reco_loss: 0.2655 - val_kl_loss: 0.0579 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3142 - reco_loss: 0.2649 - kl_loss: 0.0483 - beta: 0.4097 - val_loss: 0.3144 - val_reco_loss: 0.2604 - val_kl_loss: 0.0540 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2961 - reco_loss: 0.2503 - kl_loss: 0.0451 - beta: 0.4638 - val_loss: 0.2958 - val_reco_loss: 0.2495 - val_kl_loss: 0.0462 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2744 - reco_loss: 0.2320 - kl_loss: 0.0419 - beta: 0.5177\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2744 - reco_loss: 0.2320 - kl_loss: 0.0419 - beta: 0.5179 - val_loss: 0.2756 - val_reco_loss: 0.2262 - val_kl_loss: 0.0495 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 10ms/step - loss: 0.9442 - reco_loss: 0.9272 - kl_loss: 0.0281 - beta: 0.1545 - val_loss: 0.6066 - val_reco_loss: 0.5592 - val_kl_loss: 0.0474 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5897 - reco_loss: 0.5445 - kl_loss: 0.0465 - beta: 0.2086 - val_loss: 0.5132 - val_reco_loss: 0.4596 - val_kl_loss: 0.0536 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.4971 - reco_loss: 0.4475 - kl_loss: 0.0509 - beta: 0.2629 - val_loss: 0.4624 - val_reco_loss: 0.4039 - val_kl_loss: 0.0586 - val_beta: 0.2629 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4348 - reco_loss: 0.3842 - kl_loss: 0.0496 - beta: 0.3171 - val_loss: 0.3873 - val_reco_loss: 0.3299 - val_kl_loss: 0.0574 - val_beta: 0.3171 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3963 - reco_loss: 0.3505 - kl_loss: 0.0448 - beta: 0.3711 - val_loss: 0.3565 - val_reco_loss: 0.3069 - val_kl_loss: 0.0496 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3577 - reco_loss: 0.3165 - kl_loss: 0.0406 - beta: 0.4253 - val_loss: 0.3335 - val_reco_loss: 0.2834 - val_kl_loss: 0.0502 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3296 - reco_loss: 0.2912 - kl_loss: 0.0376 - beta: 0.4794 - val_loss: 0.3086 - val_reco_loss: 0.2665 - val_kl_loss: 0.0421 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3013 - reco_loss: 0.2665 - kl_loss: 0.0339 - beta: 0.5337 - val_loss: 0.2851 - val_reco_loss: 0.2442 - val_kl_loss: 0.0409 - val_beta: 0.5337 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2704 - reco_loss: 0.2401 - kl_loss: 0.0295 - beta: 0.5877 - val_loss: 0.2554 - val_reco_loss: 0.2230 - val_kl_loss: 0.0324 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2428 - reco_loss: 0.2166 - kl_loss: 0.0249 - beta: 0.6417 - val_loss: 0.2252 - val_reco_loss: 0.1983 - val_kl_loss: 0.0269 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2135 - reco_loss: 0.1921 - kl_loss: 0.0207 - beta: 0.6959 - val_loss: 0.1946 - val_reco_loss: 0.1682 - val_kl_loss: 0.0264 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3551 - reco_loss: 0.3305 - kl_loss: 0.0359 - beta: 0.1489 - val_loss: 0.3966 - val_reco_loss: 0.3452 - val_kl_loss: 0.0515 - val_beta: 0.1489 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.3878 - reco_loss: 0.3368 - kl_loss: 0.0523 - beta: 0.2033 - val_loss: 0.3687 - val_reco_loss: 0.3105 - val_kl_loss: 0.0582 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3746 - reco_loss: 0.3204 - kl_loss: 0.0539 - beta: 0.2576 - val_loss: 0.3604 - val_reco_loss: 0.2984 - val_kl_loss: 0.0620 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3595 - reco_loss: 0.3069 - kl_loss: 0.0519 - beta: 0.3120 - val_loss: 0.3474 - val_reco_loss: 0.2917 - val_kl_loss: 0.0557 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3377 - reco_loss: 0.2887 - kl_loss: 0.0483 - beta: 0.3662 - val_loss: 0.3268 - val_reco_loss: 0.2689 - val_kl_loss: 0.0579 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3232 - reco_loss: 0.2764 - kl_loss: 0.0455 - beta: 0.4204 - val_loss: 0.3196 - val_reco_loss: 0.2569 - val_kl_loss: 0.0627 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3033 - reco_loss: 0.2602 - kl_loss: 0.0418 - beta: 0.4745 - val_loss: 0.2916 - val_reco_loss: 0.2427 - val_kl_loss: 0.0489 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2825 - reco_loss: 0.2428 - kl_loss: 0.0380 - beta: 0.5286 - val_loss: 0.2778 - val_reco_loss: 0.2420 - val_kl_loss: 0.0358 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2590 - reco_loss: 0.2238 - kl_loss: 0.0335 - beta: 0.5827 - val_loss: 0.2526 - val_reco_loss: 0.2117 - val_kl_loss: 0.0409 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.2324 - reco_loss: 0.2020 - kl_loss: 0.0289 - beta: 0.6359\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2323 - reco_loss: 0.2019 - kl_loss: 0.0288 - beta: 0.6368 - val_loss: 0.2246 - val_reco_loss: 0.1952 - val_kl_loss: 0.0295 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2049 - reco_loss: 0.1800 - kl_loss: 0.0241 - beta: 0.6905 - val_loss: 0.1939 - val_reco_loss: 0.1661 - val_kl_loss: 0.0278 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2907 - reco_loss: 0.2658 - kl_loss: 0.0341 - beta: 0.1438 - val_loss: 0.3519 - val_reco_loss: 0.2988 - val_kl_loss: 0.0531 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3592 - reco_loss: 0.3085 - kl_loss: 0.0519 - beta: 0.1981 - val_loss: 0.3577 - val_reco_loss: 0.3012 - val_kl_loss: 0.0565 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3481 - reco_loss: 0.2940 - kl_loss: 0.0543 - beta: 0.2524 - val_loss: 0.3448 - val_reco_loss: 0.2839 - val_kl_loss: 0.0610 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3431 - reco_loss: 0.2895 - kl_loss: 0.0530 - beta: 0.3067 - val_loss: 0.3422 - val_reco_loss: 0.2795 - val_kl_loss: 0.0627 - val_beta: 0.3067 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3290 - reco_loss: 0.2786 - kl_loss: 0.0497 - beta: 0.3609 - val_loss: 0.3286 - val_reco_loss: 0.2739 - val_kl_loss: 0.0546 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3131 - reco_loss: 0.2657 - kl_loss: 0.0468 - beta: 0.4150 - val_loss: 0.3137 - val_reco_loss: 0.2575 - val_kl_loss: 0.0563 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2956 - reco_loss: 0.2515 - kl_loss: 0.0435 - beta: 0.4691 - val_loss: 0.2855 - val_reco_loss: 0.2353 - val_kl_loss: 0.0502 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2770 - reco_loss: 0.2358 - kl_loss: 0.0399 - beta: 0.5232 - val_loss: 0.2711 - val_reco_loss: 0.2251 - val_kl_loss: 0.0460 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2548 - reco_loss: 0.2177 - kl_loss: 0.0357 - beta: 0.5773 - val_loss: 0.2490 - val_reco_loss: 0.2085 - val_kl_loss: 0.0405 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.2319 - reco_loss: 0.1999 - kl_loss: 0.0309 - beta: 0.6312\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2318 - reco_loss: 0.1998 - kl_loss: 0.0309 - beta: 0.6314 - val_loss: 0.2274 - val_reco_loss: 0.1899 - val_kl_loss: 0.0375 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2068 - reco_loss: 0.1793 - kl_loss: 0.0265 - beta: 0.6852 - val_loss: 0.1993 - val_reco_loss: 0.1683 - val_kl_loss: 0.0309 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2587 - reco_loss: 0.2343 - kl_loss: 0.0310 - beta: 0.1387 - val_loss: 0.3569 - val_reco_loss: 0.3058 - val_kl_loss: 0.0510 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3526 - reco_loss: 0.3032 - kl_loss: 0.0512 - beta: 0.1929 - val_loss: 0.3553 - val_reco_loss: 0.3010 - val_kl_loss: 0.0543 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3484 - reco_loss: 0.2942 - kl_loss: 0.0544 - beta: 0.2472 - val_loss: 0.3428 - val_reco_loss: 0.2797 - val_kl_loss: 0.0631 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3381 - reco_loss: 0.2839 - kl_loss: 0.0537 - beta: 0.3014 - val_loss: 0.3399 - val_reco_loss: 0.2787 - val_kl_loss: 0.0612 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3258 - reco_loss: 0.2739 - kl_loss: 0.0510 - beta: 0.3556 - val_loss: 0.3194 - val_reco_loss: 0.2598 - val_kl_loss: 0.0596 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3127 - reco_loss: 0.2640 - kl_loss: 0.0478 - beta: 0.4097 - val_loss: 0.3057 - val_reco_loss: 0.2492 - val_kl_loss: 0.0564 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2949 - reco_loss: 0.2486 - kl_loss: 0.0450 - beta: 0.4638 - val_loss: 0.2945 - val_reco_loss: 0.2449 - val_kl_loss: 0.0497 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2750 - reco_loss: 0.2325 - kl_loss: 0.0414 - beta: 0.5179 - val_loss: 0.2715 - val_reco_loss: 0.2246 - val_kl_loss: 0.0469 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2538 - reco_loss: 0.2153 - kl_loss: 0.0375 - beta: 0.5716\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2537 - reco_loss: 0.2152 - kl_loss: 0.0375 - beta: 0.5720 - val_loss: 0.2541 - val_reco_loss: 0.2122 - val_kl_loss: 0.0419 - val_beta: 0.5720 - lr: 4.9000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2332 - reco_loss: 0.1997 - kl_loss: 0.0328 - beta: 0.6259 - val_loss: 0.2288 - val_reco_loss: 0.1949 - val_kl_loss: 0.0339 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2099 - reco_loss: 0.1799 - kl_loss: 0.0286 - beta: 0.6800 - val_loss: 0.2013 - val_reco_loss: 0.1712 - val_kl_loss: 0.0301 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2393 - reco_loss: 0.2152 - kl_loss: 0.0276 - beta: 0.1337 - val_loss: 0.3601 - val_reco_loss: 0.3166 - val_kl_loss: 0.0435 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3525 - reco_loss: 0.3055 - kl_loss: 0.0493 - beta: 0.1878 - val_loss: 0.3498 - val_reco_loss: 0.2898 - val_kl_loss: 0.0599 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3454 - reco_loss: 0.2915 - kl_loss: 0.0543 - beta: 0.2420 - val_loss: 0.3496 - val_reco_loss: 0.2895 - val_kl_loss: 0.0602 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3392 - reco_loss: 0.2847 - kl_loss: 0.0538 - beta: 0.2962 - val_loss: 0.3405 - val_reco_loss: 0.2791 - val_kl_loss: 0.0614 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3252 - reco_loss: 0.2739 - kl_loss: 0.0508 - beta: 0.3503 - val_loss: 0.3247 - val_reco_loss: 0.2696 - val_kl_loss: 0.0551 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3139 - reco_loss: 0.2646 - kl_loss: 0.0483 - beta: 0.4044 - val_loss: 0.3098 - val_reco_loss: 0.2592 - val_kl_loss: 0.0505 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2957 - reco_loss: 0.2492 - kl_loss: 0.0457 - beta: 0.4585 - val_loss: 0.2862 - val_reco_loss: 0.2326 - val_kl_loss: 0.0536 - val_beta: 0.4585 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "309/320 [===========================>..] - ETA: 0s - loss: 0.2775 - reco_loss: 0.2341 - kl_loss: 0.0426 - beta: 0.5108\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2773 - reco_loss: 0.2340 - kl_loss: 0.0425 - beta: 0.5127 - val_loss: 0.2724 - val_reco_loss: 0.2279 - val_kl_loss: 0.0445 - val_beta: 0.5127 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 10ms/step - loss: 0.9238 - reco_loss: 0.9004 - kl_loss: 0.0323 - beta: 0.1544 - val_loss: 0.6347 - val_reco_loss: 0.5870 - val_kl_loss: 0.0477 - val_beta: 0.1544 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5791 - reco_loss: 0.5300 - kl_loss: 0.0506 - beta: 0.2086 - val_loss: 0.5188 - val_reco_loss: 0.4633 - val_kl_loss: 0.0555 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4811 - reco_loss: 0.4292 - kl_loss: 0.0520 - beta: 0.2628 - val_loss: 0.4216 - val_reco_loss: 0.3638 - val_kl_loss: 0.0578 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4380 - reco_loss: 0.3871 - kl_loss: 0.0501 - beta: 0.3171 - val_loss: 0.3938 - val_reco_loss: 0.3413 - val_kl_loss: 0.0526 - val_beta: 0.3171 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3944 - reco_loss: 0.3471 - kl_loss: 0.0463 - beta: 0.3712 - val_loss: 0.3678 - val_reco_loss: 0.3159 - val_kl_loss: 0.0519 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3634 - reco_loss: 0.3194 - kl_loss: 0.0428 - beta: 0.4253 - val_loss: 0.3375 - val_reco_loss: 0.2918 - val_kl_loss: 0.0458 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3335 - reco_loss: 0.2931 - kl_loss: 0.0395 - beta: 0.4795 - val_loss: 0.3135 - val_reco_loss: 0.2683 - val_kl_loss: 0.0452 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3043 - reco_loss: 0.2684 - kl_loss: 0.0349 - beta: 0.5337 - val_loss: 0.2880 - val_reco_loss: 0.2462 - val_kl_loss: 0.0419 - val_beta: 0.5337 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2750 - reco_loss: 0.2432 - kl_loss: 0.0308 - beta: 0.5877 - val_loss: 0.2583 - val_reco_loss: 0.2250 - val_kl_loss: 0.0333 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2479 - reco_loss: 0.2199 - kl_loss: 0.0269 - beta: 0.6418 - val_loss: 0.2262 - val_reco_loss: 0.1969 - val_kl_loss: 0.0293 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2162 - reco_loss: 0.1932 - kl_loss: 0.0221 - beta: 0.6958 - val_loss: 0.1903 - val_reco_loss: 0.1677 - val_kl_loss: 0.0226 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3583 - reco_loss: 0.3337 - kl_loss: 0.0353 - beta: 0.1490 - val_loss: 0.3867 - val_reco_loss: 0.3352 - val_kl_loss: 0.0515 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3826 - reco_loss: 0.3315 - kl_loss: 0.0525 - beta: 0.2033 - val_loss: 0.3723 - val_reco_loss: 0.3138 - val_kl_loss: 0.0585 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3671 - reco_loss: 0.3124 - kl_loss: 0.0545 - beta: 0.2576 - val_loss: 0.3637 - val_reco_loss: 0.3036 - val_kl_loss: 0.0600 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3532 - reco_loss: 0.2990 - kl_loss: 0.0535 - beta: 0.3119 - val_loss: 0.3568 - val_reco_loss: 0.2977 - val_kl_loss: 0.0591 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3347 - reco_loss: 0.2841 - kl_loss: 0.0498 - beta: 0.3661 - val_loss: 0.3297 - val_reco_loss: 0.2738 - val_kl_loss: 0.0560 - val_beta: 0.3661 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3167 - reco_loss: 0.2696 - kl_loss: 0.0463 - beta: 0.4204 - val_loss: 0.3180 - val_reco_loss: 0.2637 - val_kl_loss: 0.0543 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2983 - reco_loss: 0.2544 - kl_loss: 0.0428 - beta: 0.4745 - val_loss: 0.3090 - val_reco_loss: 0.2651 - val_kl_loss: 0.0440 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2775 - reco_loss: 0.2374 - kl_loss: 0.0388 - beta: 0.5287 - val_loss: 0.2659 - val_reco_loss: 0.2253 - val_kl_loss: 0.0406 - val_beta: 0.5287 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2537 - reco_loss: 0.2180 - kl_loss: 0.0346 - beta: 0.5827 - val_loss: 0.2467 - val_reco_loss: 0.2113 - val_kl_loss: 0.0354 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2316 - reco_loss: 0.2008 - kl_loss: 0.0298 - beta: 0.6353\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2314 - reco_loss: 0.2006 - kl_loss: 0.0297 - beta: 0.6368 - val_loss: 0.2282 - val_reco_loss: 0.2011 - val_kl_loss: 0.0271 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2044 - reco_loss: 0.1788 - kl_loss: 0.0251 - beta: 0.6905 - val_loss: 0.1963 - val_reco_loss: 0.1720 - val_kl_loss: 0.0243 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2874 - reco_loss: 0.2624 - kl_loss: 0.0337 - beta: 0.1438 - val_loss: 0.3555 - val_reco_loss: 0.3022 - val_kl_loss: 0.0533 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3556 - reco_loss: 0.3048 - kl_loss: 0.0522 - beta: 0.1980 - val_loss: 0.3521 - val_reco_loss: 0.2899 - val_kl_loss: 0.0623 - val_beta: 0.1980 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3466 - reco_loss: 0.2915 - kl_loss: 0.0551 - beta: 0.2523 - val_loss: 0.3411 - val_reco_loss: 0.2756 - val_kl_loss: 0.0655 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3404 - reco_loss: 0.2858 - kl_loss: 0.0539 - beta: 0.3066 - val_loss: 0.3351 - val_reco_loss: 0.2748 - val_kl_loss: 0.0603 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.3260 - reco_loss: 0.2745 - kl_loss: 0.0509 - beta: 0.3609 - val_loss: 0.3210 - val_reco_loss: 0.2684 - val_kl_loss: 0.0526 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3104 - reco_loss: 0.2616 - kl_loss: 0.0481 - beta: 0.4150 - val_loss: 0.3089 - val_reco_loss: 0.2566 - val_kl_loss: 0.0523 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2981 - reco_loss: 0.2522 - kl_loss: 0.0450 - beta: 0.4691 - val_loss: 0.2825 - val_reco_loss: 0.2333 - val_kl_loss: 0.0492 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2756 - reco_loss: 0.2335 - kl_loss: 0.0412 - beta: 0.5232 - val_loss: 0.2730 - val_reco_loss: 0.2296 - val_kl_loss: 0.0434 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.2544 - reco_loss: 0.2165 - kl_loss: 0.0368 - beta: 0.5760\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2542 - reco_loss: 0.2164 - kl_loss: 0.0367 - beta: 0.5773 - val_loss: 0.2460 - val_reco_loss: 0.2058 - val_kl_loss: 0.0403 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2314 - reco_loss: 0.1979 - kl_loss: 0.0324 - beta: 0.6311 - val_loss: 0.2243 - val_reco_loss: 0.1855 - val_kl_loss: 0.0388 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2070 - reco_loss: 0.1784 - kl_loss: 0.0272 - beta: 0.6852 - val_loss: 0.1962 - val_reco_loss: 0.1676 - val_kl_loss: 0.0286 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2584 - reco_loss: 0.2341 - kl_loss: 0.0303 - beta: 0.1387 - val_loss: 0.3559 - val_reco_loss: 0.3082 - val_kl_loss: 0.0476 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3529 - reco_loss: 0.3040 - kl_loss: 0.0513 - beta: 0.1929 - val_loss: 0.3424 - val_reco_loss: 0.2854 - val_kl_loss: 0.0570 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3462 - reco_loss: 0.2912 - kl_loss: 0.0553 - beta: 0.2471 - val_loss: 0.3406 - val_reco_loss: 0.2803 - val_kl_loss: 0.0604 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3373 - reco_loss: 0.2823 - kl_loss: 0.0549 - beta: 0.3014 - val_loss: 0.3420 - val_reco_loss: 0.2849 - val_kl_loss: 0.0572 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3294 - reco_loss: 0.2767 - kl_loss: 0.0517 - beta: 0.3555 - val_loss: 0.3216 - val_reco_loss: 0.2674 - val_kl_loss: 0.0543 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3117 - reco_loss: 0.2616 - kl_loss: 0.0493 - beta: 0.4097 - val_loss: 0.3037 - val_reco_loss: 0.2510 - val_kl_loss: 0.0527 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2926 - reco_loss: 0.2465 - kl_loss: 0.0456 - beta: 0.4638 - val_loss: 0.2940 - val_reco_loss: 0.2443 - val_kl_loss: 0.0496 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2777 - reco_loss: 0.2340 - kl_loss: 0.0424 - beta: 0.5169\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2775 - reco_loss: 0.2339 - kl_loss: 0.0424 - beta: 0.5179 - val_loss: 0.2746 - val_reco_loss: 0.2279 - val_kl_loss: 0.0468 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 7s 9ms/step - loss: 1.0018 - reco_loss: 0.9879 - kl_loss: 0.0236 - beta: 0.1545 - val_loss: 0.6447 - val_reco_loss: 0.6008 - val_kl_loss: 0.0439 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5932 - reco_loss: 0.5472 - kl_loss: 0.0493 - beta: 0.2085 - val_loss: 0.5089 - val_reco_loss: 0.4483 - val_kl_loss: 0.0606 - val_beta: 0.2085 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4750 - reco_loss: 0.4210 - kl_loss: 0.0536 - beta: 0.2628 - val_loss: 0.4200 - val_reco_loss: 0.3570 - val_kl_loss: 0.0630 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4282 - reco_loss: 0.3765 - kl_loss: 0.0508 - beta: 0.3171 - val_loss: 0.3905 - val_reco_loss: 0.3293 - val_kl_loss: 0.0612 - val_beta: 0.3171 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3997 - reco_loss: 0.3527 - kl_loss: 0.0466 - beta: 0.3711 - val_loss: 0.3511 - val_reco_loss: 0.2969 - val_kl_loss: 0.0542 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3639 - reco_loss: 0.3201 - kl_loss: 0.0429 - beta: 0.4253 - val_loss: 0.3385 - val_reco_loss: 0.2876 - val_kl_loss: 0.0509 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3302 - reco_loss: 0.2897 - kl_loss: 0.0394 - beta: 0.4795 - val_loss: 0.3105 - val_reco_loss: 0.2677 - val_kl_loss: 0.0428 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3068 - reco_loss: 0.2705 - kl_loss: 0.0354 - beta: 0.5336 - val_loss: 0.2795 - val_reco_loss: 0.2399 - val_kl_loss: 0.0396 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2793 - reco_loss: 0.2470 - kl_loss: 0.0317 - beta: 0.5877 - val_loss: 0.2553 - val_reco_loss: 0.2237 - val_kl_loss: 0.0315 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2395 - reco_loss: 0.2120 - kl_loss: 0.0265 - beta: 0.6419 - val_loss: 0.2248 - val_reco_loss: 0.1967 - val_kl_loss: 0.0280 - val_beta: 0.6419 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2204 - reco_loss: 0.1969 - kl_loss: 0.0222 - beta: 0.6959 - val_loss: 0.2012 - val_reco_loss: 0.1776 - val_kl_loss: 0.0236 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3692 - reco_loss: 0.3442 - kl_loss: 0.0358 - beta: 0.1490 - val_loss: 0.3731 - val_reco_loss: 0.3202 - val_kl_loss: 0.0529 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3865 - reco_loss: 0.3363 - kl_loss: 0.0515 - beta: 0.2033 - val_loss: 0.3675 - val_reco_loss: 0.3045 - val_kl_loss: 0.0630 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3779 - reco_loss: 0.3251 - kl_loss: 0.0528 - beta: 0.2577 - val_loss: 0.3564 - val_reco_loss: 0.2987 - val_kl_loss: 0.0577 - val_beta: 0.2577 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3684 - reco_loss: 0.3161 - kl_loss: 0.0516 - beta: 0.3120 - val_loss: 0.3471 - val_reco_loss: 0.2867 - val_kl_loss: 0.0603 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3437 - reco_loss: 0.2948 - kl_loss: 0.0483 - beta: 0.3661 - val_loss: 0.3289 - val_reco_loss: 0.2747 - val_kl_loss: 0.0542 - val_beta: 0.3661 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3247 - reco_loss: 0.2789 - kl_loss: 0.0452 - beta: 0.4203 - val_loss: 0.3172 - val_reco_loss: 0.2634 - val_kl_loss: 0.0539 - val_beta: 0.4203 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3040 - reco_loss: 0.2613 - kl_loss: 0.0417 - beta: 0.4744 - val_loss: 0.2994 - val_reco_loss: 0.2544 - val_kl_loss: 0.0450 - val_beta: 0.4744 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2808 - reco_loss: 0.2419 - kl_loss: 0.0383 - beta: 0.5286 - val_loss: 0.2702 - val_reco_loss: 0.2228 - val_kl_loss: 0.0474 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2594 - reco_loss: 0.2239 - kl_loss: 0.0344 - beta: 0.5826 - val_loss: 0.2503 - val_reco_loss: 0.2111 - val_kl_loss: 0.0392 - val_beta: 0.5826 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2351 - reco_loss: 0.2049 - kl_loss: 0.0290 - beta: 0.6358\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2349 - reco_loss: 0.2047 - kl_loss: 0.0290 - beta: 0.6368 - val_loss: 0.2237 - val_reco_loss: 0.1888 - val_kl_loss: 0.0348 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2061 - reco_loss: 0.1808 - kl_loss: 0.0243 - beta: 0.6905 - val_loss: 0.1935 - val_reco_loss: 0.1625 - val_kl_loss: 0.0309 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2905 - reco_loss: 0.2658 - kl_loss: 0.0335 - beta: 0.1438 - val_loss: 0.3550 - val_reco_loss: 0.3025 - val_kl_loss: 0.0526 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3616 - reco_loss: 0.3127 - kl_loss: 0.0503 - beta: 0.1981 - val_loss: 0.3583 - val_reco_loss: 0.2923 - val_kl_loss: 0.0659 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3527 - reco_loss: 0.2999 - kl_loss: 0.0529 - beta: 0.2524 - val_loss: 0.3397 - val_reco_loss: 0.2786 - val_kl_loss: 0.0611 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3457 - reco_loss: 0.2931 - kl_loss: 0.0523 - beta: 0.3066 - val_loss: 0.3355 - val_reco_loss: 0.2716 - val_kl_loss: 0.0638 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3285 - reco_loss: 0.2781 - kl_loss: 0.0495 - beta: 0.3608 - val_loss: 0.3321 - val_reco_loss: 0.2777 - val_kl_loss: 0.0545 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3125 - reco_loss: 0.2652 - kl_loss: 0.0468 - beta: 0.4150 - val_loss: 0.3063 - val_reco_loss: 0.2555 - val_kl_loss: 0.0508 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2963 - reco_loss: 0.2518 - kl_loss: 0.0436 - beta: 0.4691 - val_loss: 0.2878 - val_reco_loss: 0.2392 - val_kl_loss: 0.0485 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2760 - reco_loss: 0.2351 - kl_loss: 0.0401 - beta: 0.5232 - val_loss: 0.2724 - val_reco_loss: 0.2260 - val_kl_loss: 0.0464 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2550 - reco_loss: 0.2182 - kl_loss: 0.0359 - beta: 0.5773 - val_loss: 0.2596 - val_reco_loss: 0.2198 - val_kl_loss: 0.0398 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2307 - reco_loss: 0.1987 - kl_loss: 0.0311 - beta: 0.6307\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2306 - reco_loss: 0.1986 - kl_loss: 0.0311 - beta: 0.6314 - val_loss: 0.2226 - val_reco_loss: 0.1847 - val_kl_loss: 0.0379 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2044 - reco_loss: 0.1772 - kl_loss: 0.0263 - beta: 0.6852 - val_loss: 0.1999 - val_reco_loss: 0.1706 - val_kl_loss: 0.0293 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2598 - reco_loss: 0.2358 - kl_loss: 0.0300 - beta: 0.1387 - val_loss: 0.3601 - val_reco_loss: 0.3106 - val_kl_loss: 0.0495 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3534 - reco_loss: 0.3066 - kl_loss: 0.0485 - beta: 0.1929 - val_loss: 0.3487 - val_reco_loss: 0.2907 - val_kl_loss: 0.0580 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3454 - reco_loss: 0.2934 - kl_loss: 0.0526 - beta: 0.2471 - val_loss: 0.3443 - val_reco_loss: 0.2837 - val_kl_loss: 0.0606 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3362 - reco_loss: 0.2837 - kl_loss: 0.0523 - beta: 0.3014 - val_loss: 0.3386 - val_reco_loss: 0.2763 - val_kl_loss: 0.0623 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3254 - reco_loss: 0.2744 - kl_loss: 0.0506 - beta: 0.3555 - val_loss: 0.3192 - val_reco_loss: 0.2637 - val_kl_loss: 0.0554 - val_beta: 0.3555 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3103 - reco_loss: 0.2617 - kl_loss: 0.0479 - beta: 0.4097 - val_loss: 0.3058 - val_reco_loss: 0.2505 - val_kl_loss: 0.0553 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2945 - reco_loss: 0.2487 - kl_loss: 0.0450 - beta: 0.4638 - val_loss: 0.2876 - val_reco_loss: 0.2380 - val_kl_loss: 0.0496 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2743 - reco_loss: 0.2319 - kl_loss: 0.0419 - beta: 0.5179 - val_loss: 0.2704 - val_reco_loss: 0.2247 - val_kl_loss: 0.0457 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2544 - reco_loss: 0.2159 - kl_loss: 0.0375 - beta: 0.5716\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2544 - reco_loss: 0.2158 - kl_loss: 0.0375 - beta: 0.5720 - val_loss: 0.2512 - val_reco_loss: 0.2052 - val_kl_loss: 0.0460 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2297 - reco_loss: 0.1961 - kl_loss: 0.0326 - beta: 0.6259 - val_loss: 0.2384 - val_reco_loss: 0.1854 - val_kl_loss: 0.0530 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2093 - reco_loss: 0.1795 - kl_loss: 0.0288 - beta: 0.6800 - val_loss: 0.2083 - val_reco_loss: 0.1781 - val_kl_loss: 0.0302 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2387 - reco_loss: 0.2138 - kl_loss: 0.0283 - beta: 0.1337 - val_loss: 0.3506 - val_reco_loss: 0.3030 - val_kl_loss: 0.0476 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3506 - reco_loss: 0.3055 - kl_loss: 0.0473 - beta: 0.1878 - val_loss: 0.3609 - val_reco_loss: 0.3097 - val_kl_loss: 0.0511 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3443 - reco_loss: 0.2936 - kl_loss: 0.0519 - beta: 0.2420 - val_loss: 0.3410 - val_reco_loss: 0.2816 - val_kl_loss: 0.0594 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3376 - reco_loss: 0.2844 - kl_loss: 0.0525 - beta: 0.2962 - val_loss: 0.3412 - val_reco_loss: 0.2761 - val_kl_loss: 0.0651 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3252 - reco_loss: 0.2740 - kl_loss: 0.0509 - beta: 0.3503 - val_loss: 0.3250 - val_reco_loss: 0.2652 - val_kl_loss: 0.0598 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3112 - reco_loss: 0.2614 - kl_loss: 0.0490 - beta: 0.4045 - val_loss: 0.3128 - val_reco_loss: 0.2565 - val_kl_loss: 0.0562 - val_beta: 0.4045 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2955 - reco_loss: 0.2481 - kl_loss: 0.0463 - beta: 0.4585 - val_loss: 0.3034 - val_reco_loss: 0.2495 - val_kl_loss: 0.0539 - val_beta: 0.4585 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2772 - reco_loss: 0.2324 - kl_loss: 0.0440 - beta: 0.5123\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2771 - reco_loss: 0.2324 - kl_loss: 0.0439 - beta: 0.5126 - val_loss: 0.2700 - val_reco_loss: 0.2200 - val_kl_loss: 0.0500 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 9ms/step - loss: 0.9732 - reco_loss: 0.9578 - kl_loss: 0.0263 - beta: 0.1545 - val_loss: 0.6320 - val_reco_loss: 0.5871 - val_kl_loss: 0.0449 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5755 - reco_loss: 0.5293 - kl_loss: 0.0477 - beta: 0.2086 - val_loss: 0.5005 - val_reco_loss: 0.4470 - val_kl_loss: 0.0535 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4979 - reco_loss: 0.4472 - kl_loss: 0.0511 - beta: 0.2627 - val_loss: 0.4355 - val_reco_loss: 0.3774 - val_kl_loss: 0.0581 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4244 - reco_loss: 0.3738 - kl_loss: 0.0503 - beta: 0.3171 - val_loss: 0.3870 - val_reco_loss: 0.3316 - val_kl_loss: 0.0554 - val_beta: 0.3171 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3779 - reco_loss: 0.3302 - kl_loss: 0.0472 - beta: 0.3711 - val_loss: 0.3672 - val_reco_loss: 0.3160 - val_kl_loss: 0.0512 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3491 - reco_loss: 0.3045 - kl_loss: 0.0439 - beta: 0.4253 - val_loss: 0.3214 - val_reco_loss: 0.2734 - val_kl_loss: 0.0480 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3258 - reco_loss: 0.2844 - kl_loss: 0.0402 - beta: 0.4795 - val_loss: 0.3080 - val_reco_loss: 0.2617 - val_kl_loss: 0.0463 - val_beta: 0.4795 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2964 - reco_loss: 0.2587 - kl_loss: 0.0366 - beta: 0.5335 - val_loss: 0.2813 - val_reco_loss: 0.2404 - val_kl_loss: 0.0409 - val_beta: 0.5335 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2649 - reco_loss: 0.2317 - kl_loss: 0.0324 - beta: 0.5877 - val_loss: 0.2538 - val_reco_loss: 0.2164 - val_kl_loss: 0.0374 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2363 - reco_loss: 0.2072 - kl_loss: 0.0280 - beta: 0.6419 - val_loss: 0.2287 - val_reco_loss: 0.1961 - val_kl_loss: 0.0326 - val_beta: 0.6419 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2114 - reco_loss: 0.1869 - kl_loss: 0.0233 - beta: 0.6958 - val_loss: 0.1950 - val_reco_loss: 0.1672 - val_kl_loss: 0.0279 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3442 - reco_loss: 0.3200 - kl_loss: 0.0346 - beta: 0.1490 - val_loss: 0.3631 - val_reco_loss: 0.3093 - val_kl_loss: 0.0538 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3736 - reco_loss: 0.3225 - kl_loss: 0.0526 - beta: 0.2033 - val_loss: 0.3626 - val_reco_loss: 0.2998 - val_kl_loss: 0.0627 - val_beta: 0.2033 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3627 - reco_loss: 0.3073 - kl_loss: 0.0549 - beta: 0.2576 - val_loss: 0.3546 - val_reco_loss: 0.2964 - val_kl_loss: 0.0582 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3473 - reco_loss: 0.2936 - kl_loss: 0.0528 - beta: 0.3120 - val_loss: 0.3515 - val_reco_loss: 0.2887 - val_kl_loss: 0.0627 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3343 - reco_loss: 0.2846 - kl_loss: 0.0489 - beta: 0.3662 - val_loss: 0.3316 - val_reco_loss: 0.2735 - val_kl_loss: 0.0581 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3150 - reco_loss: 0.2690 - kl_loss: 0.0455 - beta: 0.4203 - val_loss: 0.3198 - val_reco_loss: 0.2678 - val_kl_loss: 0.0519 - val_beta: 0.4203 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2999 - reco_loss: 0.2561 - kl_loss: 0.0425 - beta: 0.4745 - val_loss: 0.2939 - val_reco_loss: 0.2445 - val_kl_loss: 0.0493 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2763 - reco_loss: 0.2361 - kl_loss: 0.0394 - beta: 0.5286 - val_loss: 0.2658 - val_reco_loss: 0.2213 - val_kl_loss: 0.0445 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2525 - reco_loss: 0.2162 - kl_loss: 0.0351 - beta: 0.5827 - val_loss: 0.2457 - val_reco_loss: 0.2040 - val_kl_loss: 0.0418 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2311 - reco_loss: 0.1992 - kl_loss: 0.0303 - beta: 0.6361\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2310 - reco_loss: 0.1992 - kl_loss: 0.0303 - beta: 0.6368 - val_loss: 0.2179 - val_reco_loss: 0.1843 - val_kl_loss: 0.0337 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2023 - reco_loss: 0.1760 - kl_loss: 0.0257 - beta: 0.6905 - val_loss: 0.1938 - val_reco_loss: 0.1612 - val_kl_loss: 0.0326 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2891 - reco_loss: 0.2638 - kl_loss: 0.0331 - beta: 0.1439 - val_loss: 0.3597 - val_reco_loss: 0.3064 - val_kl_loss: 0.0533 - val_beta: 0.1439 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3553 - reco_loss: 0.3046 - kl_loss: 0.0522 - beta: 0.1981 - val_loss: 0.3534 - val_reco_loss: 0.2938 - val_kl_loss: 0.0597 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3488 - reco_loss: 0.2934 - kl_loss: 0.0551 - beta: 0.2524 - val_loss: 0.3542 - val_reco_loss: 0.2876 - val_kl_loss: 0.0666 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3385 - reco_loss: 0.2846 - kl_loss: 0.0533 - beta: 0.3067 - val_loss: 0.3390 - val_reco_loss: 0.2775 - val_kl_loss: 0.0615 - val_beta: 0.3067 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3266 - reco_loss: 0.2761 - kl_loss: 0.0495 - beta: 0.3609 - val_loss: 0.3305 - val_reco_loss: 0.2731 - val_kl_loss: 0.0574 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3115 - reco_loss: 0.2640 - kl_loss: 0.0465 - beta: 0.4150 - val_loss: 0.3091 - val_reco_loss: 0.2577 - val_kl_loss: 0.0514 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2921 - reco_loss: 0.2478 - kl_loss: 0.0436 - beta: 0.4691 - val_loss: 0.2903 - val_reco_loss: 0.2401 - val_kl_loss: 0.0502 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2720 - reco_loss: 0.2313 - kl_loss: 0.0400 - beta: 0.5232 - val_loss: 0.2665 - val_reco_loss: 0.2176 - val_kl_loss: 0.0490 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2537 - reco_loss: 0.2166 - kl_loss: 0.0361 - beta: 0.5773 - val_loss: 0.2467 - val_reco_loss: 0.2047 - val_kl_loss: 0.0420 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2285 - reco_loss: 0.1962 - kl_loss: 0.0314 - beta: 0.6297\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2283 - reco_loss: 0.1961 - kl_loss: 0.0312 - beta: 0.6314 - val_loss: 0.2249 - val_reco_loss: 0.1891 - val_kl_loss: 0.0358 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2043 - reco_loss: 0.1763 - kl_loss: 0.0271 - beta: 0.6852 - val_loss: 0.1961 - val_reco_loss: 0.1618 - val_kl_loss: 0.0343 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2565 - reco_loss: 0.2326 - kl_loss: 0.0298 - beta: 0.1388 - val_loss: 0.3544 - val_reco_loss: 0.3040 - val_kl_loss: 0.0504 - val_beta: 0.1388 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3528 - reco_loss: 0.3048 - kl_loss: 0.0499 - beta: 0.1929 - val_loss: 0.3487 - val_reco_loss: 0.2883 - val_kl_loss: 0.0604 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3458 - reco_loss: 0.2923 - kl_loss: 0.0539 - beta: 0.2471 - val_loss: 0.3447 - val_reco_loss: 0.2761 - val_kl_loss: 0.0687 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3379 - reco_loss: 0.2843 - kl_loss: 0.0530 - beta: 0.3013 - val_loss: 0.3430 - val_reco_loss: 0.2814 - val_kl_loss: 0.0617 - val_beta: 0.3013 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3236 - reco_loss: 0.2726 - kl_loss: 0.0504 - beta: 0.3556 - val_loss: 0.3254 - val_reco_loss: 0.2660 - val_kl_loss: 0.0595 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3106 - reco_loss: 0.2624 - kl_loss: 0.0475 - beta: 0.4097 - val_loss: 0.3136 - val_reco_loss: 0.2590 - val_kl_loss: 0.0545 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2921 - reco_loss: 0.2474 - kl_loss: 0.0443 - beta: 0.4638 - val_loss: 0.2904 - val_reco_loss: 0.2388 - val_kl_loss: 0.0516 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2711 - reco_loss: 0.2298 - kl_loss: 0.0409 - beta: 0.5179 - val_loss: 0.2726 - val_reco_loss: 0.2215 - val_kl_loss: 0.0511 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2530 - reco_loss: 0.2143 - kl_loss: 0.0375 - beta: 0.5710\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2529 - reco_loss: 0.2143 - kl_loss: 0.0375 - beta: 0.5720 - val_loss: 0.2489 - val_reco_loss: 0.2066 - val_kl_loss: 0.0423 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2313 - reco_loss: 0.1972 - kl_loss: 0.0331 - beta: 0.6259 - val_loss: 0.2195 - val_reco_loss: 0.1809 - val_kl_loss: 0.0386 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2068 - reco_loss: 0.1772 - kl_loss: 0.0286 - beta: 0.6800 - val_loss: 0.1988 - val_reco_loss: 0.1686 - val_kl_loss: 0.0302 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2385 - reco_loss: 0.2144 - kl_loss: 0.0272 - beta: 0.1337 - val_loss: 0.3538 - val_reco_loss: 0.3080 - val_kl_loss: 0.0458 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3493 - reco_loss: 0.3038 - kl_loss: 0.0483 - beta: 0.1878 - val_loss: 0.3497 - val_reco_loss: 0.2917 - val_kl_loss: 0.0580 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3453 - reco_loss: 0.2923 - kl_loss: 0.0534 - beta: 0.2420 - val_loss: 0.3426 - val_reco_loss: 0.2814 - val_kl_loss: 0.0612 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3350 - reco_loss: 0.2817 - kl_loss: 0.0534 - beta: 0.2962 - val_loss: 0.3377 - val_reco_loss: 0.2798 - val_kl_loss: 0.0578 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3229 - reco_loss: 0.2714 - kl_loss: 0.0510 - beta: 0.3503 - val_loss: 0.3217 - val_reco_loss: 0.2627 - val_kl_loss: 0.0591 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3100 - reco_loss: 0.2619 - kl_loss: 0.0478 - beta: 0.4044 - val_loss: 0.3128 - val_reco_loss: 0.2587 - val_kl_loss: 0.0541 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2934 - reco_loss: 0.2474 - kl_loss: 0.0454 - beta: 0.4586 - val_loss: 0.2923 - val_reco_loss: 0.2378 - val_kl_loss: 0.0546 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2749 - reco_loss: 0.2322 - kl_loss: 0.0421 - beta: 0.5120\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2749 - reco_loss: 0.2321 - kl_loss: 0.0421 - beta: 0.5126 - val_loss: 0.2698 - val_reco_loss: 0.2197 - val_kl_loss: 0.0501 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 11ms/step - loss: 0.8882 - reco_loss: 0.8706 - kl_loss: 0.0314 - beta: 0.1544 - val_loss: 0.5961 - val_reco_loss: 0.5449 - val_kl_loss: 0.0513 - val_beta: 0.1544 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5500 - reco_loss: 0.4961 - kl_loss: 0.0552 - beta: 0.2087 - val_loss: 0.4768 - val_reco_loss: 0.4147 - val_kl_loss: 0.0620 - val_beta: 0.2087 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4791 - reco_loss: 0.4227 - kl_loss: 0.0558 - beta: 0.2627 - val_loss: 0.3952 - val_reco_loss: 0.3346 - val_kl_loss: 0.0606 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4091 - reco_loss: 0.3562 - kl_loss: 0.0518 - beta: 0.3170 - val_loss: 0.3763 - val_reco_loss: 0.3206 - val_kl_loss: 0.0558 - val_beta: 0.3170 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3791 - reco_loss: 0.3306 - kl_loss: 0.0471 - beta: 0.3712 - val_loss: 0.3473 - val_reco_loss: 0.2922 - val_kl_loss: 0.0551 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3485 - reco_loss: 0.3048 - kl_loss: 0.0430 - beta: 0.4253 - val_loss: 0.3247 - val_reco_loss: 0.2717 - val_kl_loss: 0.0530 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3195 - reco_loss: 0.2791 - kl_loss: 0.0397 - beta: 0.4796 - val_loss: 0.2996 - val_reco_loss: 0.2509 - val_kl_loss: 0.0487 - val_beta: 0.4796 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2940 - reco_loss: 0.2569 - kl_loss: 0.0357 - beta: 0.5337 - val_loss: 0.2792 - val_reco_loss: 0.2344 - val_kl_loss: 0.0447 - val_beta: 0.5337 - lr: 0.0010\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2675 - reco_loss: 0.2349 - kl_loss: 0.0314 - beta: 0.5877 - val_loss: 0.2518 - val_reco_loss: 0.2159 - val_kl_loss: 0.0359 - val_beta: 0.5877 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2436 - reco_loss: 0.2157 - kl_loss: 0.0268 - beta: 0.6417 - val_loss: 0.2225 - val_reco_loss: 0.1876 - val_kl_loss: 0.0349 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2129 - reco_loss: 0.1888 - kl_loss: 0.0228 - beta: 0.6958 - val_loss: 0.1972 - val_reco_loss: 0.1684 - val_kl_loss: 0.0288 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3491 - reco_loss: 0.3228 - kl_loss: 0.0375 - beta: 0.1490 - val_loss: 0.3728 - val_reco_loss: 0.3229 - val_kl_loss: 0.0499 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3846 - reco_loss: 0.3327 - kl_loss: 0.0529 - beta: 0.2032 - val_loss: 0.3609 - val_reco_loss: 0.2978 - val_kl_loss: 0.0632 - val_beta: 0.2032 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3711 - reco_loss: 0.3167 - kl_loss: 0.0543 - beta: 0.2576 - val_loss: 0.3531 - val_reco_loss: 0.2908 - val_kl_loss: 0.0622 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3563 - reco_loss: 0.3038 - kl_loss: 0.0522 - beta: 0.3119 - val_loss: 0.3338 - val_reco_loss: 0.2781 - val_kl_loss: 0.0557 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3427 - reco_loss: 0.2930 - kl_loss: 0.0485 - beta: 0.3662 - val_loss: 0.3294 - val_reco_loss: 0.2728 - val_kl_loss: 0.0567 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3198 - reco_loss: 0.2740 - kl_loss: 0.0451 - beta: 0.4204 - val_loss: 0.3050 - val_reco_loss: 0.2521 - val_kl_loss: 0.0529 - val_beta: 0.4204 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3025 - reco_loss: 0.2593 - kl_loss: 0.0423 - beta: 0.4745 - val_loss: 0.2859 - val_reco_loss: 0.2330 - val_kl_loss: 0.0529 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2788 - reco_loss: 0.2395 - kl_loss: 0.0382 - beta: 0.5286 - val_loss: 0.2693 - val_reco_loss: 0.2237 - val_kl_loss: 0.0456 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2561 - reco_loss: 0.2202 - kl_loss: 0.0347 - beta: 0.5827 - val_loss: 0.2507 - val_reco_loss: 0.2095 - val_kl_loss: 0.0412 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.2336 - reco_loss: 0.2021 - kl_loss: 0.0300 - beta: 0.6364\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2335 - reco_loss: 0.2021 - kl_loss: 0.0300 - beta: 0.6368 - val_loss: 0.2263 - val_reco_loss: 0.1919 - val_kl_loss: 0.0344 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2085 - reco_loss: 0.1821 - kl_loss: 0.0253 - beta: 0.6905 - val_loss: 0.1976 - val_reco_loss: 0.1664 - val_kl_loss: 0.0312 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2929 - reco_loss: 0.2679 - kl_loss: 0.0331 - beta: 0.1439 - val_loss: 0.3574 - val_reco_loss: 0.3037 - val_kl_loss: 0.0537 - val_beta: 0.1439 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3569 - reco_loss: 0.3069 - kl_loss: 0.0515 - beta: 0.1981 - val_loss: 0.3571 - val_reco_loss: 0.2976 - val_kl_loss: 0.0595 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3568 - reco_loss: 0.3025 - kl_loss: 0.0546 - beta: 0.2523 - val_loss: 0.3463 - val_reco_loss: 0.2813 - val_kl_loss: 0.0651 - val_beta: 0.2523 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3457 - reco_loss: 0.2912 - kl_loss: 0.0534 - beta: 0.3066 - val_loss: 0.3333 - val_reco_loss: 0.2776 - val_kl_loss: 0.0557 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3319 - reco_loss: 0.2809 - kl_loss: 0.0500 - beta: 0.3608 - val_loss: 0.3211 - val_reco_loss: 0.2628 - val_kl_loss: 0.0583 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3152 - reco_loss: 0.2678 - kl_loss: 0.0468 - beta: 0.4150 - val_loss: 0.3042 - val_reco_loss: 0.2503 - val_kl_loss: 0.0540 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2968 - reco_loss: 0.2521 - kl_loss: 0.0439 - beta: 0.4691 - val_loss: 0.2870 - val_reco_loss: 0.2343 - val_kl_loss: 0.0528 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2765 - reco_loss: 0.2354 - kl_loss: 0.0400 - beta: 0.5232 - val_loss: 0.2664 - val_reco_loss: 0.2235 - val_kl_loss: 0.0429 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "310/320 [============================>.] - ETA: 0s - loss: 0.2562 - reco_loss: 0.2191 - kl_loss: 0.0360 - beta: 0.5756\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2560 - reco_loss: 0.2189 - kl_loss: 0.0359 - beta: 0.5773 - val_loss: 0.2474 - val_reco_loss: 0.2067 - val_kl_loss: 0.0407 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2316 - reco_loss: 0.1988 - kl_loss: 0.0318 - beta: 0.6311 - val_loss: 0.2166 - val_reco_loss: 0.1777 - val_kl_loss: 0.0389 - val_beta: 0.6311 - lr: 4.9000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2065 - reco_loss: 0.1784 - kl_loss: 0.0273 - beta: 0.6852 - val_loss: 0.1910 - val_reco_loss: 0.1624 - val_kl_loss: 0.0287 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2606 - reco_loss: 0.2367 - kl_loss: 0.0302 - beta: 0.1387 - val_loss: 0.3466 - val_reco_loss: 0.2959 - val_kl_loss: 0.0507 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3525 - reco_loss: 0.3035 - kl_loss: 0.0510 - beta: 0.1929 - val_loss: 0.3401 - val_reco_loss: 0.2816 - val_kl_loss: 0.0585 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3491 - reco_loss: 0.2946 - kl_loss: 0.0548 - beta: 0.2471 - val_loss: 0.3349 - val_reco_loss: 0.2720 - val_kl_loss: 0.0629 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3447 - reco_loss: 0.2896 - kl_loss: 0.0543 - beta: 0.3014 - val_loss: 0.3280 - val_reco_loss: 0.2675 - val_kl_loss: 0.0605 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3301 - reco_loss: 0.2780 - kl_loss: 0.0510 - beta: 0.3556 - val_loss: 0.3146 - val_reco_loss: 0.2573 - val_kl_loss: 0.0573 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3125 - reco_loss: 0.2641 - kl_loss: 0.0477 - beta: 0.4097 - val_loss: 0.3046 - val_reco_loss: 0.2500 - val_kl_loss: 0.0547 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2960 - reco_loss: 0.2507 - kl_loss: 0.0447 - beta: 0.4638 - val_loss: 0.2938 - val_reco_loss: 0.2393 - val_kl_loss: 0.0545 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2772 - reco_loss: 0.2351 - kl_loss: 0.0412 - beta: 0.5179 - val_loss: 0.2732 - val_reco_loss: 0.2228 - val_kl_loss: 0.0503 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2569 - reco_loss: 0.2186 - kl_loss: 0.0373 - beta: 0.5720 - val_loss: 0.2461 - val_reco_loss: 0.1987 - val_kl_loss: 0.0474 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2327 - reco_loss: 0.1986 - kl_loss: 0.0327 - beta: 0.6254\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2326 - reco_loss: 0.1985 - kl_loss: 0.0326 - beta: 0.6261 - val_loss: 0.2241 - val_reco_loss: 0.1870 - val_kl_loss: 0.0372 - val_beta: 0.6261 - lr: 4.9000e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2077 - reco_loss: 0.1787 - kl_loss: 0.0280 - beta: 0.6800 - val_loss: 0.1989 - val_reco_loss: 0.1642 - val_kl_loss: 0.0347 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2391 - reco_loss: 0.2153 - kl_loss: 0.0273 - beta: 0.1337 - val_loss: 0.3561 - val_reco_loss: 0.3110 - val_kl_loss: 0.0451 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3537 - reco_loss: 0.3078 - kl_loss: 0.0487 - beta: 0.1878 - val_loss: 0.3411 - val_reco_loss: 0.2835 - val_kl_loss: 0.0575 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3430 - reco_loss: 0.2890 - kl_loss: 0.0547 - beta: 0.2420 - val_loss: 0.3339 - val_reco_loss: 0.2706 - val_kl_loss: 0.0633 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3397 - reco_loss: 0.2841 - kl_loss: 0.0548 - beta: 0.2962 - val_loss: 0.3351 - val_reco_loss: 0.2707 - val_kl_loss: 0.0645 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3274 - reco_loss: 0.2749 - kl_loss: 0.0518 - beta: 0.3503 - val_loss: 0.3151 - val_reco_loss: 0.2543 - val_kl_loss: 0.0608 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3125 - reco_loss: 0.2638 - kl_loss: 0.0484 - beta: 0.4045 - val_loss: 0.2991 - val_reco_loss: 0.2407 - val_kl_loss: 0.0585 - val_beta: 0.4045 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2987 - reco_loss: 0.2515 - kl_loss: 0.0459 - beta: 0.4586 - val_loss: 0.2862 - val_reco_loss: 0.2321 - val_kl_loss: 0.0540 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2764 - reco_loss: 0.2337 - kl_loss: 0.0424 - beta: 0.5126 - val_loss: 0.2735 - val_reco_loss: 0.2236 - val_kl_loss: 0.0499 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 53/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.2581 - reco_loss: 0.2180 - kl_loss: 0.0390 - beta: 0.5657\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2580 - reco_loss: 0.2179 - kl_loss: 0.0390 - beta: 0.5667 - val_loss: 0.2483 - val_reco_loss: 0.2015 - val_kl_loss: 0.0468 - val_beta: 0.5667 - lr: 3.4300e-04\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2350 - reco_loss: 0.1996 - kl_loss: 0.0344 - beta: 0.6207 - val_loss: 0.2254 - val_reco_loss: 0.1865 - val_kl_loss: 0.0388 - val_beta: 0.6207 - lr: 2.4010e-04\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2098 - reco_loss: 0.1792 - kl_loss: 0.0302 - beta: 0.6748 - val_loss: 0.1996 - val_reco_loss: 0.1638 - val_kl_loss: 0.0358 - val_beta: 0.6748 - lr: 2.4010e-04\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2259 - reco_loss: 0.2005 - kl_loss: 0.0251 - beta: 0.1286 - val_loss: 0.3542 - val_reco_loss: 0.3122 - val_kl_loss: 0.0420 - val_beta: 0.1286 - lr: 2.4010e-04\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3569 - reco_loss: 0.3142 - kl_loss: 0.0465 - beta: 0.1827 - val_loss: 0.3501 - val_reco_loss: 0.2918 - val_kl_loss: 0.0583 - val_beta: 0.1827 - lr: 2.4010e-04\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3458 - reco_loss: 0.2924 - kl_loss: 0.0542 - beta: 0.2369 - val_loss: 0.3430 - val_reco_loss: 0.2830 - val_kl_loss: 0.0599 - val_beta: 0.2369 - lr: 2.4010e-04\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3396 - reco_loss: 0.2845 - kl_loss: 0.0547 - beta: 0.2910 - val_loss: 0.3315 - val_reco_loss: 0.2691 - val_kl_loss: 0.0623 - val_beta: 0.2910 - lr: 2.4010e-04\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3253 - reco_loss: 0.2725 - kl_loss: 0.0523 - beta: 0.3451 - val_loss: 0.3137 - val_reco_loss: 0.2549 - val_kl_loss: 0.0588 - val_beta: 0.3451 - lr: 2.4010e-04\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3110 - reco_loss: 0.2609 - kl_loss: 0.0496 - beta: 0.3993 - val_loss: 0.3136 - val_reco_loss: 0.2576 - val_kl_loss: 0.0560 - val_beta: 0.3993 - lr: 2.4010e-04\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2998 - reco_loss: 0.2523 - kl_loss: 0.0467 - beta: 0.4533 - val_loss: 0.2898 - val_reco_loss: 0.2382 - val_kl_loss: 0.0516 - val_beta: 0.4533 - lr: 2.4010e-04\n",
      "Epoch 63/100\n",
      "309/320 [===========================>..] - ETA: 0s - loss: 0.2799 - reco_loss: 0.2353 - kl_loss: 0.0438 - beta: 0.5056\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2797 - reco_loss: 0.2351 - kl_loss: 0.0436 - beta: 0.5074 - val_loss: 0.2752 - val_reco_loss: 0.2243 - val_kl_loss: 0.0509 - val_beta: 0.5074 - lr: 2.4010e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 7s 9ms/step - loss: 0.9945 - reco_loss: 0.9832 - kl_loss: 0.0202 - beta: 0.1545 - val_loss: 0.6583 - val_reco_loss: 0.6206 - val_kl_loss: 0.0377 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5562 - reco_loss: 0.5145 - kl_loss: 0.0455 - beta: 0.2086 - val_loss: 0.5119 - val_reco_loss: 0.4598 - val_kl_loss: 0.0521 - val_beta: 0.2086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4738 - reco_loss: 0.4232 - kl_loss: 0.0504 - beta: 0.2628 - val_loss: 0.4422 - val_reco_loss: 0.3878 - val_kl_loss: 0.0544 - val_beta: 0.2628 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4322 - reco_loss: 0.3833 - kl_loss: 0.0483 - beta: 0.3169 - val_loss: 0.3884 - val_reco_loss: 0.3365 - val_kl_loss: 0.0519 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3817 - reco_loss: 0.3358 - kl_loss: 0.0456 - beta: 0.3712 - val_loss: 0.3522 - val_reco_loss: 0.2995 - val_kl_loss: 0.0526 - val_beta: 0.3712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3581 - reco_loss: 0.3134 - kl_loss: 0.0431 - beta: 0.4252 - val_loss: 0.3348 - val_reco_loss: 0.2892 - val_kl_loss: 0.0456 - val_beta: 0.4252 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3238 - reco_loss: 0.2830 - kl_loss: 0.0400 - beta: 0.4794 - val_loss: 0.3009 - val_reco_loss: 0.2544 - val_kl_loss: 0.0465 - val_beta: 0.4794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2968 - reco_loss: 0.2600 - kl_loss: 0.0356 - beta: 0.5336 - val_loss: 0.2784 - val_reco_loss: 0.2393 - val_kl_loss: 0.0391 - val_beta: 0.5336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2695 - reco_loss: 0.2366 - kl_loss: 0.0314 - beta: 0.5876 - val_loss: 0.2542 - val_reco_loss: 0.2192 - val_kl_loss: 0.0349 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2436 - reco_loss: 0.2156 - kl_loss: 0.0267 - beta: 0.6417 - val_loss: 0.2203 - val_reco_loss: 0.1917 - val_kl_loss: 0.0285 - val_beta: 0.6417 - lr: 0.0010\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2106 - reco_loss: 0.1874 - kl_loss: 0.0222 - beta: 0.6959 - val_loss: 0.1938 - val_reco_loss: 0.1705 - val_kl_loss: 0.0233 - val_beta: 0.6959 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3527 - reco_loss: 0.3287 - kl_loss: 0.0354 - beta: 0.1490 - val_loss: 0.3674 - val_reco_loss: 0.3142 - val_kl_loss: 0.0532 - val_beta: 0.1490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3785 - reco_loss: 0.3267 - kl_loss: 0.0529 - beta: 0.2032 - val_loss: 0.3551 - val_reco_loss: 0.2934 - val_kl_loss: 0.0617 - val_beta: 0.2032 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3735 - reco_loss: 0.3181 - kl_loss: 0.0553 - beta: 0.2576 - val_loss: 0.3436 - val_reco_loss: 0.2819 - val_kl_loss: 0.0617 - val_beta: 0.2576 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3564 - reco_loss: 0.3027 - kl_loss: 0.0525 - beta: 0.3120 - val_loss: 0.3342 - val_reco_loss: 0.2714 - val_kl_loss: 0.0628 - val_beta: 0.3120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3422 - reco_loss: 0.2924 - kl_loss: 0.0487 - beta: 0.3662 - val_loss: 0.3194 - val_reco_loss: 0.2634 - val_kl_loss: 0.0560 - val_beta: 0.3662 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3219 - reco_loss: 0.2751 - kl_loss: 0.0458 - beta: 0.4203 - val_loss: 0.3100 - val_reco_loss: 0.2616 - val_kl_loss: 0.0484 - val_beta: 0.4203 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3062 - reco_loss: 0.2631 - kl_loss: 0.0419 - beta: 0.4745 - val_loss: 0.2791 - val_reco_loss: 0.2321 - val_kl_loss: 0.0469 - val_beta: 0.4745 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2814 - reco_loss: 0.2420 - kl_loss: 0.0381 - beta: 0.5286 - val_loss: 0.2705 - val_reco_loss: 0.2238 - val_kl_loss: 0.0467 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2545 - reco_loss: 0.2200 - kl_loss: 0.0337 - beta: 0.5827 - val_loss: 0.2533 - val_reco_loss: 0.2162 - val_kl_loss: 0.0371 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2314 - reco_loss: 0.2013 - kl_loss: 0.0292 - beta: 0.6368\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.2314 - reco_loss: 0.2013 - kl_loss: 0.0292 - beta: 0.6368 - val_loss: 0.2244 - val_reco_loss: 0.1943 - val_kl_loss: 0.0301 - val_beta: 0.6368 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2063 - reco_loss: 0.1805 - kl_loss: 0.0249 - beta: 0.6905 - val_loss: 0.1913 - val_reco_loss: 0.1636 - val_kl_loss: 0.0277 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2909 - reco_loss: 0.2673 - kl_loss: 0.0323 - beta: 0.1438 - val_loss: 0.3388 - val_reco_loss: 0.2869 - val_kl_loss: 0.0520 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3566 - reco_loss: 0.3057 - kl_loss: 0.0524 - beta: 0.1981 - val_loss: 0.3413 - val_reco_loss: 0.2785 - val_kl_loss: 0.0627 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3512 - reco_loss: 0.2960 - kl_loss: 0.0553 - beta: 0.2524 - val_loss: 0.3305 - val_reco_loss: 0.2666 - val_kl_loss: 0.0639 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3439 - reco_loss: 0.2891 - kl_loss: 0.0542 - beta: 0.3066 - val_loss: 0.3227 - val_reco_loss: 0.2611 - val_kl_loss: 0.0617 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3267 - reco_loss: 0.2756 - kl_loss: 0.0502 - beta: 0.3609 - val_loss: 0.3146 - val_reco_loss: 0.2569 - val_kl_loss: 0.0577 - val_beta: 0.3609 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3140 - reco_loss: 0.2657 - kl_loss: 0.0472 - beta: 0.4151 - val_loss: 0.3000 - val_reco_loss: 0.2403 - val_kl_loss: 0.0597 - val_beta: 0.4151 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2975 - reco_loss: 0.2519 - kl_loss: 0.0441 - beta: 0.4691 - val_loss: 0.2821 - val_reco_loss: 0.2319 - val_kl_loss: 0.0502 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2752 - reco_loss: 0.2342 - kl_loss: 0.0402 - beta: 0.5232 - val_loss: 0.2641 - val_reco_loss: 0.2172 - val_kl_loss: 0.0469 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2555 - reco_loss: 0.2186 - kl_loss: 0.0354 - beta: 0.5773 - val_loss: 0.2514 - val_reco_loss: 0.2094 - val_kl_loss: 0.0421 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "311/320 [============================>.] - ETA: 0s - loss: 0.2310 - reco_loss: 0.1992 - kl_loss: 0.0308 - beta: 0.6299\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2308 - reco_loss: 0.1990 - kl_loss: 0.0307 - beta: 0.6314 - val_loss: 0.2199 - val_reco_loss: 0.1851 - val_kl_loss: 0.0348 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2050 - reco_loss: 0.1775 - kl_loss: 0.0263 - beta: 0.6852 - val_loss: 0.1963 - val_reco_loss: 0.1659 - val_kl_loss: 0.0304 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2579 - reco_loss: 0.2345 - kl_loss: 0.0298 - beta: 0.1387 - val_loss: 0.3431 - val_reco_loss: 0.2922 - val_kl_loss: 0.0509 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3497 - reco_loss: 0.3007 - kl_loss: 0.0512 - beta: 0.1929 - val_loss: 0.3341 - val_reco_loss: 0.2745 - val_kl_loss: 0.0596 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3455 - reco_loss: 0.2904 - kl_loss: 0.0554 - beta: 0.2471 - val_loss: 0.3309 - val_reco_loss: 0.2642 - val_kl_loss: 0.0667 - val_beta: 0.2471 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3384 - reco_loss: 0.2832 - kl_loss: 0.0544 - beta: 0.3014 - val_loss: 0.3231 - val_reco_loss: 0.2633 - val_kl_loss: 0.0598 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3269 - reco_loss: 0.2743 - kl_loss: 0.0521 - beta: 0.3556 - val_loss: 0.3117 - val_reco_loss: 0.2540 - val_kl_loss: 0.0577 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3146 - reco_loss: 0.2643 - kl_loss: 0.0492 - beta: 0.4097 - val_loss: 0.2946 - val_reco_loss: 0.2446 - val_kl_loss: 0.0500 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2949 - reco_loss: 0.2488 - kl_loss: 0.0453 - beta: 0.4638 - val_loss: 0.2799 - val_reco_loss: 0.2268 - val_kl_loss: 0.0530 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2769 - reco_loss: 0.2340 - kl_loss: 0.0418 - beta: 0.5179 - val_loss: 0.2738 - val_reco_loss: 0.2237 - val_kl_loss: 0.0501 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.2550 - reco_loss: 0.2163 - kl_loss: 0.0373 - beta: 0.5708\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2549 - reco_loss: 0.2162 - kl_loss: 0.0373 - beta: 0.5720 - val_loss: 0.2426 - val_reco_loss: 0.1965 - val_kl_loss: 0.0460 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2337 - reco_loss: 0.1987 - kl_loss: 0.0334 - beta: 0.6259 - val_loss: 0.2146 - val_reco_loss: 0.1785 - val_kl_loss: 0.0360 - val_beta: 0.6259 - lr: 3.4300e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2064 - reco_loss: 0.1770 - kl_loss: 0.0289 - beta: 0.6800 - val_loss: 0.1989 - val_reco_loss: 0.1685 - val_kl_loss: 0.0304 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2394 - reco_loss: 0.2152 - kl_loss: 0.0265 - beta: 0.1337 - val_loss: 0.3444 - val_reco_loss: 0.2971 - val_kl_loss: 0.0472 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3518 - reco_loss: 0.3054 - kl_loss: 0.0492 - beta: 0.1878 - val_loss: 0.3392 - val_reco_loss: 0.2795 - val_kl_loss: 0.0597 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3472 - reco_loss: 0.2935 - kl_loss: 0.0541 - beta: 0.2420 - val_loss: 0.3286 - val_reco_loss: 0.2690 - val_kl_loss: 0.0595 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3357 - reco_loss: 0.2814 - kl_loss: 0.0539 - beta: 0.2962 - val_loss: 0.3234 - val_reco_loss: 0.2679 - val_kl_loss: 0.0555 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3242 - reco_loss: 0.2714 - kl_loss: 0.0520 - beta: 0.3503 - val_loss: 0.3084 - val_reco_loss: 0.2476 - val_kl_loss: 0.0608 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3131 - reco_loss: 0.2632 - kl_loss: 0.0491 - beta: 0.4044 - val_loss: 0.3023 - val_reco_loss: 0.2496 - val_kl_loss: 0.0527 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.2944 - reco_loss: 0.2478 - kl_loss: 0.0464 - beta: 0.4586 - val_loss: 0.2917 - val_reco_loss: 0.2375 - val_kl_loss: 0.0542 - val_beta: 0.4586 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.2785 - reco_loss: 0.2346 - kl_loss: 0.0430 - beta: 0.5120\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2784 - reco_loss: 0.2345 - kl_loss: 0.0429 - beta: 0.5126 - val_loss: 0.2634 - val_reco_loss: 0.2156 - val_kl_loss: 0.0478 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 10ms/step - loss: 1.0548 - reco_loss: 1.0348 - kl_loss: 0.0281 - beta: 0.1545 - val_loss: 0.6803 - val_reco_loss: 0.6401 - val_kl_loss: 0.0402 - val_beta: 0.1545 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.6091 - reco_loss: 0.5699 - kl_loss: 0.0414 - beta: 0.2087 - val_loss: 0.5468 - val_reco_loss: 0.4952 - val_kl_loss: 0.0516 - val_beta: 0.2087 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.5242 - reco_loss: 0.4744 - kl_loss: 0.0511 - beta: 0.2627 - val_loss: 0.4458 - val_reco_loss: 0.3907 - val_kl_loss: 0.0551 - val_beta: 0.2627 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.4535 - reco_loss: 0.4020 - kl_loss: 0.0511 - beta: 0.3169 - val_loss: 0.4049 - val_reco_loss: 0.3467 - val_kl_loss: 0.0582 - val_beta: 0.3169 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3943 - reco_loss: 0.3459 - kl_loss: 0.0475 - beta: 0.3711 - val_loss: 0.3574 - val_reco_loss: 0.3005 - val_kl_loss: 0.0569 - val_beta: 0.3711 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3619 - reco_loss: 0.3178 - kl_loss: 0.0431 - beta: 0.4253 - val_loss: 0.3397 - val_reco_loss: 0.2926 - val_kl_loss: 0.0471 - val_beta: 0.4253 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3375 - reco_loss: 0.2979 - kl_loss: 0.0391 - beta: 0.4793 - val_loss: 0.3204 - val_reco_loss: 0.2792 - val_kl_loss: 0.0411 - val_beta: 0.4793 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3017 - reco_loss: 0.2660 - kl_loss: 0.0349 - beta: 0.5337 - val_loss: 0.2868 - val_reco_loss: 0.2424 - val_kl_loss: 0.0444 - val_beta: 0.5337 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2788 - reco_loss: 0.2465 - kl_loss: 0.0309 - beta: 0.5876 - val_loss: 0.2566 - val_reco_loss: 0.2212 - val_kl_loss: 0.0354 - val_beta: 0.5876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2441 - reco_loss: 0.2172 - kl_loss: 0.0261 - beta: 0.6418 - val_loss: 0.2294 - val_reco_loss: 0.1973 - val_kl_loss: 0.0321 - val_beta: 0.6418 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2158 - reco_loss: 0.1930 - kl_loss: 0.0217 - beta: 0.6958 - val_loss: 0.2067 - val_reco_loss: 0.1836 - val_kl_loss: 0.0231 - val_beta: 0.6958 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3587 - reco_loss: 0.3342 - kl_loss: 0.0361 - beta: 0.1489 - val_loss: 0.3826 - val_reco_loss: 0.3242 - val_kl_loss: 0.0584 - val_beta: 0.1489 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3844 - reco_loss: 0.3320 - kl_loss: 0.0533 - beta: 0.2032 - val_loss: 0.3778 - val_reco_loss: 0.3178 - val_kl_loss: 0.0600 - val_beta: 0.2032 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3713 - reco_loss: 0.3161 - kl_loss: 0.0552 - beta: 0.2577 - val_loss: 0.3568 - val_reco_loss: 0.2930 - val_kl_loss: 0.0638 - val_beta: 0.2577 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3557 - reco_loss: 0.3018 - kl_loss: 0.0532 - beta: 0.3119 - val_loss: 0.3536 - val_reco_loss: 0.2980 - val_kl_loss: 0.0557 - val_beta: 0.3119 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3451 - reco_loss: 0.2945 - kl_loss: 0.0496 - beta: 0.3661 - val_loss: 0.3353 - val_reco_loss: 0.2819 - val_kl_loss: 0.0534 - val_beta: 0.3661 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3237 - reco_loss: 0.2767 - kl_loss: 0.0461 - beta: 0.4203 - val_loss: 0.3108 - val_reco_loss: 0.2576 - val_kl_loss: 0.0533 - val_beta: 0.4203 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3040 - reco_loss: 0.2598 - kl_loss: 0.0435 - beta: 0.4744 - val_loss: 0.2898 - val_reco_loss: 0.2461 - val_kl_loss: 0.0437 - val_beta: 0.4744 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2793 - reco_loss: 0.2388 - kl_loss: 0.0395 - beta: 0.5286 - val_loss: 0.2665 - val_reco_loss: 0.2228 - val_kl_loss: 0.0437 - val_beta: 0.5286 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2579 - reco_loss: 0.2217 - kl_loss: 0.0350 - beta: 0.5827 - val_loss: 0.2497 - val_reco_loss: 0.2129 - val_kl_loss: 0.0368 - val_beta: 0.5827 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.2344 - reco_loss: 0.2038 - kl_loss: 0.0291 - beta: 0.6359\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2342 - reco_loss: 0.2037 - kl_loss: 0.0290 - beta: 0.6367 - val_loss: 0.2227 - val_reco_loss: 0.1918 - val_kl_loss: 0.0309 - val_beta: 0.6367 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2066 - reco_loss: 0.1814 - kl_loss: 0.0241 - beta: 0.6905 - val_loss: 0.1929 - val_reco_loss: 0.1653 - val_kl_loss: 0.0276 - val_beta: 0.6905 - lr: 7.0000e-04\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2896 - reco_loss: 0.2647 - kl_loss: 0.0341 - beta: 0.1438 - val_loss: 0.3621 - val_reco_loss: 0.3093 - val_kl_loss: 0.0529 - val_beta: 0.1438 - lr: 7.0000e-04\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3636 - reco_loss: 0.3120 - kl_loss: 0.0524 - beta: 0.1981 - val_loss: 0.3595 - val_reco_loss: 0.3003 - val_kl_loss: 0.0592 - val_beta: 0.1981 - lr: 7.0000e-04\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3484 - reco_loss: 0.2945 - kl_loss: 0.0544 - beta: 0.2524 - val_loss: 0.3567 - val_reco_loss: 0.3000 - val_kl_loss: 0.0567 - val_beta: 0.2524 - lr: 7.0000e-04\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3441 - reco_loss: 0.2908 - kl_loss: 0.0526 - beta: 0.3066 - val_loss: 0.3376 - val_reco_loss: 0.2782 - val_kl_loss: 0.0593 - val_beta: 0.3066 - lr: 7.0000e-04\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3318 - reco_loss: 0.2811 - kl_loss: 0.0499 - beta: 0.3608 - val_loss: 0.3248 - val_reco_loss: 0.2680 - val_kl_loss: 0.0568 - val_beta: 0.3608 - lr: 7.0000e-04\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3167 - reco_loss: 0.2680 - kl_loss: 0.0479 - beta: 0.4150 - val_loss: 0.3008 - val_reco_loss: 0.2467 - val_kl_loss: 0.0541 - val_beta: 0.4150 - lr: 7.0000e-04\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2964 - reco_loss: 0.2505 - kl_loss: 0.0449 - beta: 0.4691 - val_loss: 0.2886 - val_reco_loss: 0.2422 - val_kl_loss: 0.0463 - val_beta: 0.4691 - lr: 7.0000e-04\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2750 - reco_loss: 0.2334 - kl_loss: 0.0409 - beta: 0.5232 - val_loss: 0.2675 - val_reco_loss: 0.2192 - val_kl_loss: 0.0482 - val_beta: 0.5232 - lr: 7.0000e-04\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2556 - reco_loss: 0.2180 - kl_loss: 0.0366 - beta: 0.5773 - val_loss: 0.2485 - val_reco_loss: 0.2071 - val_kl_loss: 0.0414 - val_beta: 0.5773 - lr: 7.0000e-04\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2322 - reco_loss: 0.1994 - kl_loss: 0.0318 - beta: 0.6314\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2322 - reco_loss: 0.1994 - kl_loss: 0.0318 - beta: 0.6314 - val_loss: 0.2336 - val_reco_loss: 0.1996 - val_kl_loss: 0.0340 - val_beta: 0.6314 - lr: 7.0000e-04\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2091 - reco_loss: 0.1812 - kl_loss: 0.0266 - beta: 0.6852 - val_loss: 0.1902 - val_reco_loss: 0.1592 - val_kl_loss: 0.0311 - val_beta: 0.6852 - lr: 4.9000e-04\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2625 - reco_loss: 0.2387 - kl_loss: 0.0300 - beta: 0.1387 - val_loss: 0.3554 - val_reco_loss: 0.3047 - val_kl_loss: 0.0507 - val_beta: 0.1387 - lr: 4.9000e-04\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3557 - reco_loss: 0.3063 - kl_loss: 0.0506 - beta: 0.1929 - val_loss: 0.3553 - val_reco_loss: 0.3001 - val_kl_loss: 0.0552 - val_beta: 0.1929 - lr: 4.9000e-04\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3497 - reco_loss: 0.2960 - kl_loss: 0.0538 - beta: 0.2472 - val_loss: 0.3480 - val_reco_loss: 0.2836 - val_kl_loss: 0.0644 - val_beta: 0.2472 - lr: 4.9000e-04\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3397 - reco_loss: 0.2861 - kl_loss: 0.0532 - beta: 0.3014 - val_loss: 0.3397 - val_reco_loss: 0.2799 - val_kl_loss: 0.0598 - val_beta: 0.3014 - lr: 4.9000e-04\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3276 - reco_loss: 0.2759 - kl_loss: 0.0510 - beta: 0.3556 - val_loss: 0.3158 - val_reco_loss: 0.2564 - val_kl_loss: 0.0593 - val_beta: 0.3556 - lr: 4.9000e-04\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3140 - reco_loss: 0.2644 - kl_loss: 0.0487 - beta: 0.4097 - val_loss: 0.2994 - val_reco_loss: 0.2451 - val_kl_loss: 0.0544 - val_beta: 0.4097 - lr: 4.9000e-04\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2940 - reco_loss: 0.2480 - kl_loss: 0.0456 - beta: 0.4638 - val_loss: 0.2884 - val_reco_loss: 0.2382 - val_kl_loss: 0.0502 - val_beta: 0.4638 - lr: 4.9000e-04\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2756 - reco_loss: 0.2324 - kl_loss: 0.0420 - beta: 0.5179 - val_loss: 0.2781 - val_reco_loss: 0.2304 - val_kl_loss: 0.0478 - val_beta: 0.5179 - lr: 4.9000e-04\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2562 - reco_loss: 0.2171 - kl_loss: 0.0378 - beta: 0.5720 - val_loss: 0.2475 - val_reco_loss: 0.2082 - val_kl_loss: 0.0393 - val_beta: 0.5720 - lr: 4.9000e-04\n",
      "Epoch 43/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.2332 - reco_loss: 0.1989 - kl_loss: 0.0328 - beta: 0.6249\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2331 - reco_loss: 0.1988 - kl_loss: 0.0328 - beta: 0.6261 - val_loss: 0.2271 - val_reco_loss: 0.1899 - val_kl_loss: 0.0372 - val_beta: 0.6261 - lr: 4.9000e-04\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2084 - reco_loss: 0.1791 - kl_loss: 0.0283 - beta: 0.6800 - val_loss: 0.2001 - val_reco_loss: 0.1663 - val_kl_loss: 0.0337 - val_beta: 0.6800 - lr: 3.4300e-04\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2428 - reco_loss: 0.2186 - kl_loss: 0.0272 - beta: 0.1337 - val_loss: 0.3603 - val_reco_loss: 0.3132 - val_kl_loss: 0.0472 - val_beta: 0.1337 - lr: 3.4300e-04\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3536 - reco_loss: 0.3056 - kl_loss: 0.0500 - beta: 0.1878 - val_loss: 0.3529 - val_reco_loss: 0.2957 - val_kl_loss: 0.0572 - val_beta: 0.1878 - lr: 3.4300e-04\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3479 - reco_loss: 0.2938 - kl_loss: 0.0543 - beta: 0.2420 - val_loss: 0.3389 - val_reco_loss: 0.2783 - val_kl_loss: 0.0606 - val_beta: 0.2420 - lr: 3.4300e-04\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3392 - reco_loss: 0.2847 - kl_loss: 0.0538 - beta: 0.2962 - val_loss: 0.3356 - val_reco_loss: 0.2757 - val_kl_loss: 0.0598 - val_beta: 0.2962 - lr: 3.4300e-04\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3274 - reco_loss: 0.2751 - kl_loss: 0.0514 - beta: 0.3503 - val_loss: 0.3216 - val_reco_loss: 0.2633 - val_kl_loss: 0.0583 - val_beta: 0.3503 - lr: 3.4300e-04\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3136 - reco_loss: 0.2636 - kl_loss: 0.0494 - beta: 0.4044 - val_loss: 0.3055 - val_reco_loss: 0.2519 - val_kl_loss: 0.0535 - val_beta: 0.4044 - lr: 3.4300e-04\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2970 - reco_loss: 0.2495 - kl_loss: 0.0469 - beta: 0.4585 - val_loss: 0.2960 - val_reco_loss: 0.2476 - val_kl_loss: 0.0484 - val_beta: 0.4585 - lr: 3.4300e-04\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2763 - reco_loss: 0.2321 - kl_loss: 0.0434 - beta: 0.5126 - val_loss: 0.2729 - val_reco_loss: 0.2226 - val_kl_loss: 0.0503 - val_beta: 0.5126 - lr: 3.4300e-04\n",
      "Epoch 53/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.2568 - reco_loss: 0.2162 - kl_loss: 0.0398 - beta: 0.5659\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2567 - reco_loss: 0.2161 - kl_loss: 0.0397 - beta: 0.5667 - val_loss: 0.2566 - val_reco_loss: 0.2119 - val_kl_loss: 0.0447 - val_beta: 0.5667 - lr: 3.4300e-04\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2340 - reco_loss: 0.1979 - kl_loss: 0.0352 - beta: 0.6207 - val_loss: 0.2230 - val_reco_loss: 0.1841 - val_kl_loss: 0.0389 - val_beta: 0.6207 - lr: 2.4010e-04\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2109 - reco_loss: 0.1792 - kl_loss: 0.0306 - beta: 0.6748 - val_loss: 0.2041 - val_reco_loss: 0.1729 - val_kl_loss: 0.0312 - val_beta: 0.6748 - lr: 2.4010e-04\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2254 - reco_loss: 0.2002 - kl_loss: 0.0242 - beta: 0.1286 - val_loss: 0.3614 - val_reco_loss: 0.3212 - val_kl_loss: 0.0403 - val_beta: 0.1286 - lr: 2.4010e-04\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3526 - reco_loss: 0.3097 - kl_loss: 0.0465 - beta: 0.1827 - val_loss: 0.3477 - val_reco_loss: 0.2925 - val_kl_loss: 0.0552 - val_beta: 0.1827 - lr: 2.4010e-04\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3482 - reco_loss: 0.2965 - kl_loss: 0.0522 - beta: 0.2369 - val_loss: 0.3442 - val_reco_loss: 0.2831 - val_kl_loss: 0.0611 - val_beta: 0.2369 - lr: 2.4010e-04\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3354 - reco_loss: 0.2825 - kl_loss: 0.0528 - beta: 0.2910 - val_loss: 0.3361 - val_reco_loss: 0.2769 - val_kl_loss: 0.0592 - val_beta: 0.2910 - lr: 2.4010e-04\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3262 - reco_loss: 0.2739 - kl_loss: 0.0517 - beta: 0.3451 - val_loss: 0.3190 - val_reco_loss: 0.2614 - val_kl_loss: 0.0575 - val_beta: 0.3451 - lr: 2.4010e-04\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.3161 - reco_loss: 0.2654 - kl_loss: 0.0499 - beta: 0.3993 - val_loss: 0.3035 - val_reco_loss: 0.2512 - val_kl_loss: 0.0523 - val_beta: 0.3993 - lr: 2.4010e-04\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2979 - reco_loss: 0.2500 - kl_loss: 0.0475 - beta: 0.4534 - val_loss: 0.2919 - val_reco_loss: 0.2375 - val_kl_loss: 0.0544 - val_beta: 0.4534 - lr: 2.4010e-04\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2806 - reco_loss: 0.2351 - kl_loss: 0.0446 - beta: 0.5074\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2806 - reco_loss: 0.2351 - kl_loss: 0.0446 - beta: 0.5074 - val_loss: 0.2827 - val_reco_loss: 0.2342 - val_kl_loss: 0.0485 - val_beta: 0.5074 - lr: 2.4010e-04\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,30):\n",
    "    T2A_enc = Qmake_encoder_set_weights(Topo_2A.shape[1],32,16,3)\n",
    "    T2A_dec = Qmake_decoder_set_weights(Topo_2A.shape[1],32,16,3)\n",
    "    steps_per_epoch = Topo_2A_test_L1failed.shape[0] // BATCH_SIZE\n",
    "    T2A = VAE_Model(T2A_enc, T2A_dec, steps_per_epoch=steps_per_epoch, min_beta=0.1, max_beta=0.7)\n",
    "    # T2A.set_beta(beta)\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    T2A.compile(optimizer=opt,weighted_metrics=[weighted_mse]) #,weighted_metrics=[weighted_mse]\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "    callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    history = T2A.fit(x=Topo_2A_test_L1failed, validation_split=0.1, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, shuffle=True)#, sample_weight=Topo_t_weights\n",
    "    T2A.save_weights(filepath='/eos/user/h/hjia/trained_models/L1_models/Repeat_Testing/2A_FDL_{}/'.format(i), save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909946a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
